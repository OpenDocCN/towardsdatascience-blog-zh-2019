<html>
<head>
<title>Creating a TensorFlow CNN in C++ (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 C++创建 TensorFlow CNN(第 2 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-tensorflow-cnn-in-c-part-2-eea0de9dcada?source=collection_archive---------6-----------------------#2019-06-10">https://towardsdatascience.com/creating-a-tensorflow-cnn-in-c-part-2-eea0de9dcada?source=collection_archive---------6-----------------------#2019-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="77c0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">在这篇文章中，我将展示如何使用 TensorFlow C++ API 创建、训练和测试一个卷积神经网络</em></h2></div><h1 id="5b1d" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">背景</h1><p id="4411" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">最近两年，谷歌的 TensorFlow 越来越受欢迎。它是迄今为止最受欢迎的深度学习框架，与 Keras <a class="ae lu" rel="noopener" target="_blank" href="/deep-learning-framework-power-scores-2018-23607ddf297a">一起，它是最主要的</a>框架。</p><p id="9814" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">现在有了版本 2，TensorFlow 包含了 Keras 构建的内容。</p><p id="6872" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然而，当谈到 C++ API 时，你真的找不到太多关于使用它的信息。大多数代码示例和文档都是用 Python 编写的。正如我在以前的帖子中提到的，我希望允许 C++用户，比如我自己，使用 TensorFlow C++ API，这是一个低级 API，这实际上意味着您必须投入更多的工作来实现它。我的帖子是来帮助你的。</p><p id="c819" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">就像我过去写的，我喜欢 C++。我并不反对 Python，但是我希望能够用 C++来构建我的模型，并且拥有工具生态系统来帮助我调试和优化它。</p><p id="2873" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我阅读了文档，并寻找将向我展示如何创建卷积神经网络的代码示例。有几个例子，这里的<a class="ae lu" href="https://medium.com/@htmbx6/build-and-train-neural-network-with-tensorflow-c-f13f22d3c5b6" rel="noopener"/>和这里的<a class="ae lu" href="https://matrices.io/training-a-deep-neural-network-using-only-tensorflow-c/" rel="noopener ugc nofollow" target="_blank"/>启发了我。仅此而已！</p><p id="7e10" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我必须对一些 API 进行逆向工程，经历了大量的试验和错误，直到它工作为止。</p><p id="3ccd" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我希望这篇文章能够帮助那些想开始使用 C++ API 的人。</p><p id="0d64" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我在 MacOS 上使用 XCode，但我试图以一种在 Windows 或 Linux 上也能工作的方式构建代码。我没有测试过，所以如果你有任何改变的建议，请告诉我。</p><h1 id="513f" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">设置</h1><p id="558f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我假设您已经安装了 TensorFlow，并且有一个 XCode 项目可以使用它。如果你需要这方面的帮助，请阅读并遵循我的指示<a class="ae lu" href="https://itnext.io/how-to-use-your-c-muscle-using-tensorflow-2-0-and-xcode-without-using-bazel-builds-9dc82d5e7f80" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="7367" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">正如我在<a class="ae lu" href="https://itnext.io/creating-a-tensorflow-dnn-in-c-part-1-54ce69bbd586" rel="noopener ugc nofollow" target="_blank">第 1 部分</a>中所写的，我们的目标是实现 Arden Dertat 著名文章系列第 4 部分中的 AlexNet 缩减版。</p><p id="6954" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我还假设你知道卷积网络的术语，如果没有，我建议你阅读 Arden 的文章。</p><p id="8b60" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了获得训练数据，您需要从<a class="ae lu" href="https://www.kaggle.com/c/dogs-vs-cats" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载图像。</p><p id="3365" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">从<a class="ae lu" href="https://s3.amazonaws.com/img-datasets/cats_and_dogs_small.zip" rel="noopener ugc nofollow" target="_blank">这里</a>下载小版本。那里有足够的图像供我们使用。</p><p id="c807" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">提取文件，并将它们放在项目文件夹下的数据文件夹中。</p><p id="c494" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">它应该是有组织的，所以你有三个子文件夹用于训练，验证和测试。</p><h1 id="4218" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">密码</h1><p id="1e63" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这篇文章的代码可以在<a class="ae lu" href="https://github.com/bennyfri/TFMacCpp" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="710b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">有一个驱动执行的 main.cpp 和两个类文件 CatDogCNN.cpp 和 CatDogCNN.h，它们是网络本身的实现。</p><p id="e29e" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">mainV1.cpp 是前面的文章代码。</p><p id="ebce" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">通常，在为 TensorFlow 编写代码时，将图形的创建与其实际运行分开是明智的。这是由于一个简单的事实，即您通常创建一次图表，然后用不同的输入运行多次。即使你不改变图的变量(如权重)，也没有必要在每次运行图时重新创建图，除非它非常简单，并且分离的努力是无用的。</p><h1 id="ab17" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">完成数据准备</h1><p id="b453" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">CreateGraphForImage 是一个创建类似于我在<a class="ae lu" href="https://itnext.io/creating-a-tensorflow-dnn-in-c-part-1-54ce69bbd586" rel="noopener ugc nofollow" target="_blank">第一部分</a>中展示的图形的方法。</p><p id="5c9f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">它接受是否拆分图像的布尔值。当您只想加载一个图像时调用 false，当您想加载一批图像时调用 true。这是因为堆叠批次时会增加一个额外的尺寸。但是，当你想运行 CNN 只有一个图像，你需要有所有 4 个维度。</p><p id="653f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">请注意，当从拆分更改为堆叠时，您必须重新创建图形。</p><p id="b94b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">ReadTensorFromImageFile 负责运行由前面的方法创建的图形。你输入一个文件的完整路径名，得到一个 3 或 4 维张量。</p><p id="2f64" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这两种方法的代码几乎与 mainV1.cpp(文章第 1 部分)中的代码相同。</p><h2 id="7c9f" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">处理文件夹和路径</h2><p id="9642" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ReadFileTensors 处理文件夹和文件。它接受一个基本文件夹字符串和一个向量对[子文件夹，标签值]。</p><p id="0d43" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">如果你从 Kaggle 下载了图片，你可能会注意到在 train 下有两个子文件夹 cats 和 dogs。用一个数字标记它们中的每一个，并将这些对作为输入进行传递。</p><p id="02b9" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">返回的是一对向量，每一对向量都是一个张量(图像的)和一个标签。</p><p id="e7f6" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这里有一种说法:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="1b0a" class="ma kh iq mr b gy mv mw l mx my">base_folder = "/Users/bennyfriedman/Code/TF2example/TF2example/data/cats_and_dogs_small/train";</span><span id="3bf6" class="ma kh iq mr b gy mz mw l mx my">vector&lt;pair&lt;Tensor, float&gt;&gt; all_files_tensors;</span><span id="a7bb" class="ma kh iq mr b gy mz mw l mx my">model.ReadFileTensors(base_folder, {make_pair("cats", 0), make_pair("dogs", 1)}, all_files_tensors);</span></pre><p id="4918" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们需要打开一个目录，读取其中的文件，然后一个一个地检查。</p><p id="186e" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">要连接两个路径字符串，请使用 io::JoinPath(包括 tensorflow/core/lib/io/path.h)</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="5484" class="ma kh iq mr b gy mv mw l mx my">string folder_name = io::JoinPath(base_folder_name, “cats”);</span></pre><p id="05ae" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">要与文件系统交互，请使用“Env”。这是一个实用程序类(没有真正的文档记录),它为您提供了类似于 C++17 std::filesystem 的便利。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="b1d9" class="ma kh iq mr b gy mv mw l mx my">Env* penv = Env::Default();</span><span id="6ad6" class="ma kh iq mr b gy mz mw l mx my">TF_RETURN_IF_ERROR(penv-&gt;IsDirectory(folder_name));</span><span id="e6ac" class="ma kh iq mr b gy mz mw l mx my">vector&lt;string&gt; file_names;</span><span id="e83c" class="ma kh iq mr b gy mz mw l mx my">TF_RETURN_IF_ERROR(penv-&gt;GetChildren(folder_name, &amp;file_names));</span><span id="fc4b" class="ma kh iq mr b gy mz mw l mx my">for(string file: file_names)</span><span id="6020" class="ma kh iq mr b gy mz mw l mx my">{</span><span id="aa0f" class="ma kh iq mr b gy mz mw l mx my">…</span><span id="a683" class="ma kh iq mr b gy mz mw l mx my">}</span></pre><p id="706e" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">ReadFileTensors 还会打乱矢量中的图像，这样我们就可以在训练时输入不同的图像(你不会想先喂所有的猫，然后再喂所有的狗)。</p><h2 id="732e" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">创建批处理</h2><p id="6e2d" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ReadBatches 封装了所有的逻辑 main 需求。你给它一个基本文件夹，一对子文件夹和标签的向量，以及一个批处理的大小。作为回报，你得到两个张量向量，一个用于图像，一个用于标签。每个张量都是按照你传递的大小一批图像/标签。</p><p id="ef64" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">首先，它将文件夹及其子文件夹的内容读入一个向量。接下来，它会计算如何拆分批次。然后，它断开张量和标签对以创建两个输入向量，其中张量向量中的每个第 n 个元素匹配标签向量中的第 n 个元素。</p><p id="f82d" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了堆叠这两个向量，我们当场创建一个小图，并在每次迭代中运行它。</p><p id="f659" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">结果被添加到输出向量中。</p><p id="910f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">注意堆栈操作是如何需要得到一个要堆栈的图像张量的输入列表的。最简单的方法是创建一个 vector(或另一个容器)并用它实例化 InputList。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="1e89" class="ma kh iq mr b gy mv mw l mx my">vector&lt;Input&gt; one_batch_image;</span><span id="8b99" class="ma kh iq mr b gy mz mw l mx my">one_batch_image.push_back(Input(tensor));</span><span id="c91f" class="ma kh iq mr b gy mz mw l mx my">//Add more tensors</span><span id="9ab9" class="ma kh iq mr b gy mz mw l mx my">InputList one_batch_inputs(one_batch_image);</span><span id="e649" class="ma kh iq mr b gy mz mw l mx my">Scope root = Scope::NewRootScope();</span><span id="5027" class="ma kh iq mr b gy mz mw l mx my">auto stacked_images = Stack(root, one_batch_inputs);</span><span id="678e" class="ma kh iq mr b gy mz mw l mx my">ClientSession session(root);</span><span id="5637" class="ma kh iq mr b gy mz mw l mx my">vector&lt;Tensor&gt; out_tensors;</span><span id="5590" class="ma kh iq mr b gy mz mw l mx my">TF_CHECK_OK(session.Run({}, {stacked_images}, &amp;out_tensors));</span><span id="fe37" class="ma kh iq mr b gy mz mw l mx my">//use out_tensors[0]</span></pre><p id="257a" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">如上所述，张量以三维张量的形式出现，而创建的批次是四维的。</p><h1 id="197e" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">CNN 图表</h1><p id="0a30" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">现在有趣的部分来了。</p><p id="0dcb" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们想创建一个类似于 AlexNet 的模型。</p><h2 id="0ca8" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">投入</h2><p id="739e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">首先，我们想要定义图形的输入:我们已经知道我们需要输入一批图像:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="31d7" class="ma kh iq mr b gy mv mw l mx my">input_batch_var = Placeholder(t_root.WithOpName("input"), DT_FLOAT);</span></pre><p id="c832" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">占位符类似于函数参数。您指定了它的名称和元素类型，但此时它的形状未知。</p><p id="f56b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">从占位符获取结果的变量是 CatDogCNN 类类型输出的成员。</p><p id="c73b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">首先，我们在图中使用它作为第一层的输入，稍后我们将需要在 ClientSession 运行命令中指定它及其值(批处理张量)。</p><p id="a25c" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">接下来有几个占位符，我稍后会解释。</p><p id="9c7d" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">与通常的 Python Keras 网络不同，C++层是操作的组合(Google 称之为低级 API)。为了知道每个操作属于哪一层，我们为每一层创建一个子范围。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="55f6" class="ma kh iq mr b gy mv mw l mx my">Scope scope_conv1 = t_root.NewSubScope("Conv1_layer");</span></pre><p id="3d6a" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">将使用此范围对象创建操作。</p><h2 id="99f3" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">盘旋</h2><p id="226e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">第一层是卷积层，所以我们需要定义 4 个参数:过滤器高度和宽度以及进出通道。此外，我们还有激活函数(Relu)和后面的 MaxPool 操作。</p><p id="cef1" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们有 4 个 Conv 层，所以我创建了一个函数来创建一个包含这些操作的通用层:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="96e2" class="ma kh iq mr b gy mv mw l mx my">Input CatDogCNN::AddConvLayer(string idx, Scope scope, int in_channels, int out_channels, int filter_side, Input input)</span><span id="4ada" class="ma kh iq mr b gy mz mw l mx my">{</span><span id="f147" class="ma kh iq mr b gy mz mw l mx my">TensorShape sp({filter_side, filter_side, in_channels, out_channels});</span><span id="9e41" class="ma kh iq mr b gy mz mw l mx my">m_vars["W"+idx] = Variable(scope.WithOpName("W"), sp, DT_FLOAT);</span><span id="1275" class="ma kh iq mr b gy mz mw l mx my">m_shapes["W"+idx] = sp;</span><span id="8cc0" class="ma kh iq mr b gy mz mw l mx my">m_assigns["W"+idx+"_assign"] = Assign(scope.WithOpName("W_assign"), m_vars["W"+idx], XavierInit(scope, in_channels, out_channels, filter_side));</span><span id="02eb" class="ma kh iq mr b gy mz mw l mx my">sp = {out_channels};</span><span id="e144" class="ma kh iq mr b gy mz mw l mx my">m_vars["B"+idx] = Variable(scope.WithOpName("B"), sp, DT_FLOAT);</span><span id="16b7" class="ma kh iq mr b gy mz mw l mx my">m_shapes["B"+idx] = sp;</span><span id="960c" class="ma kh iq mr b gy mz mw l mx my">m_assigns["B"+idx+"_assign"] = Assign(scope.WithOpName("B_assign"), m_vars["B"+idx], Input::Initializer(0.f, sp));</span><span id="ff1f" class="ma kh iq mr b gy mz mw l mx my">auto conv = Conv2D(scope.WithOpName("Conv"), input, m_vars["W"+idx], {1, 1, 1, 1}, "SAME");</span><span id="ef79" class="ma kh iq mr b gy mz mw l mx my">auto bias = BiasAdd(scope.WithOpName("Bias"), conv, m_vars["B"+idx]);</span><span id="074b" class="ma kh iq mr b gy mz mw l mx my">auto relu = Relu(scope.WithOpName("Relu"), bias);</span><span id="83bd" class="ma kh iq mr b gy mz mw l mx my">return MaxPool(scope.WithOpName("Pool"), relu, {1, 2, 2, 1}, {1, 2, 2, 1}, "SAME");</span><span id="2b8e" class="ma kh iq mr b gy mz mw l mx my">}</span></pre><p id="4cb0" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">让我们回顾一下代码:</p><p id="8b24" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">AddConvLayer 获取一个索引字符串(用于区分层)、子范围、输入和输出通道、过滤器大小(我们假设高度和宽度相同)和输入 Input。</p><p id="f00a" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">通道中的第一层是图像的颜色数(3 种颜色)，输入是图像张量。</p><p id="7250" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">Conv2D 操作需要一个张量变量来保存不同的滤波器(第一层中的 32 个)。当网络在训练时，这个变量将在每一步内改变。</p><p id="9390" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">出于这个原因，有一个成员映射 m_vars 保存这些变量以及偏差。此外，我们需要存储这些变量的形状(m_shapes map)，我们还需要用值初始化这些变量(类似于 Python 变量初始化器)——这些操作存储在 m_assigns 中。Xavier 初始化现在很流行，所以我为 Conv 和 Dense 实现了 XavierInit。</p><p id="c468" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在 Conv2D 之后，调用 BiasAdd 来添加偏置(初始化为 0)。</p><p id="6afe" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">接下来是对 Relu 的调用，然后是对 MaxPool 的调用。</p><p id="7ef0" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">请注意，对于 Python Keras 版本中的 MaxPool，您只需指定窗口大小及其两个维度(例如 2，2)。这里我们需要提供两个四维的形状(窗口大小和跨度)。要将每层中的图像大小减半，必须在窗口大小和步幅中输入 1，2，2，1。</p><p id="6379" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">还要注意，在 CreateGraphForCNN 函数中，我跟踪了进出通道的大小，因为它们必须在层之间匹配。</p><p id="ce96" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">此外，由于没有办法从运算中得到张量的形状(只有在运行时才知道)，我们必须在每一步中计算图像的大小。</p><h2 id="b8c0" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">平的</h2><p id="3344" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">扁平化意味着我们将只有两个维度，批处理和平面数据。</p><p id="6deb" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为此，我们需要重塑张量。因为我不想硬编码批处理大小(我不知道它是否会被批处理)，所以我必须知道平面数据的大小。这就是为什么我在这些层中做这些计算，直到我们得到 flat_len。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="0156" class="ma kh iq mr b gy mv mw l mx my">auto flat = Reshape(flatten, pool4, {-1, flat_len});</span></pre><p id="6b2f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在 Reshape 中，您可以在其中一个维度中传递-1，因此它将被自动计算。整形不会添加数据，只会改变数据的组织方式。</p><h2 id="f364" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">拒绝传统社会的人</h2><p id="6db8" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这一层负责丢弃随机的神经元，这样网络就不会过度适应。</p><p id="c250" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们创建一个具有相同形状的新张量，并根据丢弃率随机填充 0 或 1，然后用它乘以我们的数据。</p><p id="bff1" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然而，当你想要验证或预测时，你不想放弃神经元。</p><p id="b8ef" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">实现这一点的逻辑方法是在图中放置一个条件。有一些操作以一种非常麻烦的方式支持它(切换和合并)，但是在 C++中它们不支持反向传播，所以我们不能使用它们。</p><p id="e44c" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">相反，我向网络 drop_rate 和 skip_drop 引入了另外两个输入参数，例如，如果您分别传递 0.4 和 0，就会得到 40%的丢弃。如果你通过 1 和 1，就不会有水滴。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="b624" class="ma kh iq mr b gy mv mw l mx my">Scope dropout = t_root.NewSubScope("Dropout_layer");</span><span id="e209" class="ma kh iq mr b gy mz mw l mx my">auto rand = RandomUniform(dropout, Shape(dropout, flat), DT_FLOAT);</span><span id="aa26" class="ma kh iq mr b gy mz mw l mx my">//binary = floor(rand + (1 - drop_rate) + skip_drop)</span><span id="4e51" class="ma kh iq mr b gy mz mw l mx my">auto binary = Floor(dropout, Add(dropout, rand, Add(dropout, Sub(dropout, 1.f, drop_rate_var), skip_drop_var)));</span><span id="b9fe" class="ma kh iq mr b gy mz mw l mx my">auto after_drop = Multiply(dropout.WithOpName("dropout"), Div(dropout, flat, drop_rate_var), binary)</span></pre><p id="d37b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">丢弃时，我们通过除以丢弃率来增加剩余神经元的值。</p><p id="b809" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">注意，当 skip_drop 为 1 时，floor 会将“二进制”变为全 1。</p><h2 id="dcf9" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">完全连接(密集)</h2><p id="1656" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">接下来是三个致密层。</p><p id="0349" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">密集是基于乘以权重并加上偏差。我们将变量保存在地图中，对形状和赋值也是如此。</p><p id="9eb8" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们还用 Xavier init 初始化权重，用 0 初始化偏差。</p><p id="70ce" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">注意，在最后一个密集层中，我们需要跳过 Relu 激活(为此我们有细菌培养)。</p><h2 id="6f79" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">二元分类</h2><p id="a4fc" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">最后的致密层将尺寸减小到 1(超过批量尺寸)。这就是所谓的逻辑。</p><p id="b30f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了使逻辑值为 0(代表猫)或 1(代表狗),我们调用 Sigmoid 并返回这个结果。</p><p id="2520" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这就是打开 TensorBoard 时网络的样子(详见第 1 部分):</p><figure class="mm mn mo mp gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi na"><img src="../Images/f463f803856a7307a2483a4d1fb75417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6INLxmJU9ALePGUAYuMNQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">The CNN before we add optimization</figcaption></figure><p id="4ac8" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我打开了其中一个子范围，这样你就可以看到第四个卷积层中的低级操作。</p><h2 id="ba75" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">优化图(反向传播)</h2><p id="4302" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这封装在 CreateOptimizationGraph 函数中。它不是一个单独的图，而是同一个图中的附加节点(同一个 t_root 主作用域)。</p><p id="bebd" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们从标签的占位符开始。如果图像张量是 x，这是 y。</p><p id="24e5" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">接下来我们计算损失。这是一个分类问题，所以我们应该使用交叉熵，但是我不知道如何使用 SoftmaxCrossEntropyWithLogits 操作，也找不到任何有意义的信息，所以我必须使用常规的均方 diff 方法。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="f5d4" class="ma kh iq mr b gy mv mw l mx my">input_labels_var = Placeholder(t_root.WithOpName("inputL"), DT_FLOAT);</span><span id="41b1" class="ma kh iq mr b gy mz mw l mx my">Scope scope_loss = t_root.NewSubScope("Loss_scope");</span><span id="3c57" class="ma kh iq mr b gy mz mw l mx my">out_loss_var = Mean(scope_loss.WithOpName("Loss"), SquaredDifference(scope_loss, out_classification, input_labels_var), {0});</span><span id="e0fd" class="ma kh iq mr b gy mz mw l mx my">TF_CHECK_OK(scope_loss.status());</span></pre><p id="6be2" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">接下来，我收集所有的权重和偏差，并将它们和损失一起发送给神奇的 API 调用 AddSymbolicGradients。这个神奇的功能不是手术。它获取一个图(通过其相关范围)，添加所有相关的反向传播操作，并返回一个梯度向量，其大小与权重和偏差的数量相同。</p><p id="8831" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然后，我们对权重和偏差中的每个变量使用 ApplyAdam 及其各自的梯度。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="306f" class="ma kh iq mr b gy mv mw l mx my">auto adam = ApplyAdam(t_root, i.second, m_var, v_var, 0.f, 0.f, learning_rate, 0.9f, 0.999f, 0.00000001f, {grad_outputs[index]});</span><span id="ec69" class="ma kh iq mr b gy mz mw l mx my">v_out_grads.push_back(adam.operation);</span></pre><p id="035f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">出于某种原因，m_var 和 v_var 必须是变量(它们不能是常数)。</p><p id="c955" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">传递给 ApplyAdam 的最重要的变量是学习率。我怎么强调这个价值的重要性都不为过。我从 0.001(来自 python 版本)开始，无法停止对为什么损失不收敛的困惑。最终我意识到优化函数在两个峰值之间跳得太长了。仅仅过了几天，当我把它改成 0.0001 时，它就开始工作了。您可以尝试不同的值，看看它在您的情况下是如何工作的。</p><p id="15f9" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">你也可以改变 ApplyAdam 得到的其他值，尽管我不确定这会有什么影响。</p><p id="ee44" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">现在，张量板图像看起来“有点”不同:</p><figure class="mm mn mo mp gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nm"><img src="../Images/410b2e94364a6296b968a5878266f726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LwH9Ap0jZH1YgrpjJzDMjA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">The CNN with optimization</figcaption></figure><h2 id="6da3" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">初始化</h2><p id="c657" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我已经提到了用赋值操作初始化所有变量的需要。</p><p id="7e8f" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们将所有 m_assigns 元素(也是我们为 ApplyAdam 添加的元素)收集到一个 vector 中，并在创建的会话中运行它们。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="1212" class="ma kh iq mr b gy mv mw l mx my">vector&lt;Output&gt; ops_to_run;</span><span id="8edc" class="ma kh iq mr b gy mz mw l mx my">for(pair&lt;string, Output&gt; i: m_assigns)</span><span id="1e06" class="ma kh iq mr b gy mz mw l mx my">ops_to_run.push_back(i.second);</span><span id="2931" class="ma kh iq mr b gy mz mw l mx my">t_session = unique_ptr&lt;ClientSession&gt;(new ClientSession(t_root));</span><span id="e723" class="ma kh iq mr b gy mz mw l mx my">TF_CHECK_OK(t_session-&gt;Run(ops_to_run, nullptr));</span></pre><p id="1bf1" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">保留摘要文件编写器代码周围的注释，仅当您想要为 TensorBoard 可视化生成新图形时才使用它。</p><h1 id="19cc" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">培养</h1><p id="ae87" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">让我们回到 main:我们构造了 CatDogCNN 类的一个实例，创建了图形，加载了图像并运行了初始化。</p><p id="df3d" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">现在是主历元/步长循环的时间。</p><p id="10a7" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">一个历元是贯穿所有训练数据的一次运行。一个步骤是一批图像的一次运行。</p><p id="8475" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们定义历元的数量，遍历它们，然后遍历批。</p><p id="7bd4" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在每次迭代中，我们调用 TrainCNN，我们调用 ValidateCNN，我们做一些计算来检查网络的性能。</p><p id="83b9" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">TrainCNN 得到一批图像，一批标签(对应这些图像)并返回结果和损失。</p><p id="c06b" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">该函数首先运行批处理:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="6190" class="ma kh iq mr b gy mv mw l mx my">vector&lt;Tensor&gt; out_tensors;</span><span id="2fb3" class="ma kh iq mr b gy mz mw l mx my">//Inputs: batch of images, labels, drop rate and do not skip drop.</span><span id="617b" class="ma kh iq mr b gy mz mw l mx my">//Extract: Loss and result. Run also: Apply Adam commands</span><span id="aa93" class="ma kh iq mr b gy mz mw l mx my">TF_CHECK_OK(t_session-&gt;Run({{input_batch_var, image_batch}, {input_labels_var, label_batch}, {drop_rate_var, 0.5f}, {skip_drop_var, 0.f}}, {out_loss_var, out_classification}, v_out_grads, &amp;out_tensors));</span></pre><p id="5b03" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然后它计算精确度。注意使用张量方法来提取数据:out_tensors[0]。标量<float> ()(0)得到一个标量和 out_tensors[1]。matrix <float>()得到一个矩阵(几乎就像向量的向量)。</float></float></p><h2 id="c57b" class="ma kh iq bd ki mb mc dn km md me dp kq lh mf mg ks ll mh mi ku lp mj mk kw ml bi translated">确认</h2><p id="2a59" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">验证是重要的，因为事实上我们运行的网络图像，网络从未见过。如果在每一个时期我们都有更好的表现，我们就不会过度适应。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="d323" class="ma kh iq mr b gy mv mw l mx my">vector&lt;Tensor&gt; out_tensors;</span><span id="58c9" class="ma kh iq mr b gy mz mw l mx my">//Inputs: batch of images, drop rate 1 and skip drop.</span><span id="b691" class="ma kh iq mr b gy mz mw l mx my">TF_CHECK_OK(t_session-&gt;Run({{input_batch_var, image_batch}, {drop_rate_var, 1.f}, {skip_drop_var, 1.f}}, {out_classification}, &amp;out_tensors));</span></pre><p id="4f56" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">请注意不同之处:我们跳过了漏失(见上面的解释)，我们不评估损失，我们不运行梯度。</p><p id="ffe9" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">输出控制台如下所示:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="a39d" class="ma kh iq mr b gy mv mw l mx my">Epoch 1/20:....................................................................................................</span><span id="b708" class="ma kh iq mr b gy mz mw l mx my">Validation:..................................................</span><span id="5978" class="ma kh iq mr b gy mz mw l mx my">Time: 74 seconds Loss: 0.243231 Results accuracy: 0.561 Validation accuracy: 0.642</span><span id="834a" class="ma kh iq mr b gy mz mw l mx my">Epoch 2/20:....................................................................................................</span><span id="6a9f" class="ma kh iq mr b gy mz mw l mx my">Validation:..................................................</span><span id="0026" class="ma kh iq mr b gy mz mw l mx my">Time: 72 seconds Loss: 0.203312 Results accuracy: 0.6875 Validation accuracy: 0.692</span><span id="a09b" class="ma kh iq mr b gy mz mw l mx my">***</span><span id="689c" class="ma kh iq mr b gy mz mw l mx my">Epoch 20/20:....................................................................................................</span><span id="c35b" class="ma kh iq mr b gy mz mw l mx my">Validation:..................................................</span><span id="52e2" class="ma kh iq mr b gy mz mw l mx my">Time: 73 seconds Loss: 0.041021 Results accuracy: 0.956 Validation accuracy: 0.742</span></pre><p id="d707" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">损失在持续下降，结果准确率将达到 95%，验证准确率将达到 75%。</p><h1 id="220b" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">测试</h1><p id="19d4" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们来测试一下训练好的网络。</p><p id="9a56" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为此，我们需要重新创建负载图像图，这样它就不会散开。</p><p id="b6dc" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然后我们调用 ReadFileTensors 来加载 test 子文件夹中的图像。最后，我们运行其中几个的循环，以查看网络的性能。</p><p id="7ae7" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">预测类似于验证，尽管它运行单个图像。</p><p id="9bab" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">输出控制台如下所示:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="7e52" class="ma kh iq mr b gy mv mw l mx my">Test number: 1 predicted: 0 actual is: 0</span><span id="0629" class="ma kh iq mr b gy mz mw l mx my">Test number: 2 predicted: 1 actual is: 1</span><span id="588c" class="ma kh iq mr b gy mz mw l mx my">***</span><span id="98c9" class="ma kh iq mr b gy mz mw l mx my">Test number: 20 predicted: 0 actual is: 0</span><span id="2a38" class="ma kh iq mr b gy mz mw l mx my">total successes: 16 out of 20</span></pre><p id="a768" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">80%的准确率。有一些改进的空间，但是我们比 Arden 在他的网络上得到更好的结果。</p><h1 id="21e2" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">摘要</h1><p id="7d80" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们看到了如何只用 C++和 TensorFlow API 实现、训练和测试 CNN。</p><p id="c75a" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们看到了如何准备数据(用于训练、验证和测试的图像)以及如何对它们进行批处理，以便我们可以将这些批处理提供给 TensorFlow 低级 API。</p><p id="eece" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们实现了梯度和其他优化方法。</p><p id="c078" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们取得了良好的结果，但还有更多工作要做。</p><p id="c1b4" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">接下来我打算做一些改进。</p><p id="b37e" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">正如你在控制台输出中看到的，我正在我的本地 MacBook Pro CPU 上运行，它需要很长时间才能运行…</p><p id="0f17" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我打算实现冻结模型功能和 GPU 的使用，以加快速度。</p><p id="142e" class="pw-post-body-paragraph ky kz iq la b lb lv jr ld le lw ju lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">此外，我会看看我是否可以做一些图像增强，为培训创建更多的数据。</p></div></div>    
</body>
</html>