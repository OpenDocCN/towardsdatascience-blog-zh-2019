# 我在训练测试中犯的 6 个业余错误

> 原文：<https://towardsdatascience.com/6-amateur-mistakes-ive-made-working-with-train-test-splits-916fabb421bb?source=collection_archive---------2----------------------->

![](img/6dd4af0dc36bb6d56e324a049952d64a.png)

## 细节决定成败

在过去的几周里，他一起踏上了关于推荐系统的旅程。我们看到了对主题的一个温和的[介绍，以及对围绕主题的最重要的相似性度量](/a-gentle-introduction-to-recommendation-systems-eaddcbde07ce)的一个[介绍(请记住，关于推荐系统和其他项目的整个知识库总是可以在我的](/similarity-measures-in-recommendation-systems-535b83d89587) [GitHub 个人资料](https://github.com/gonzaferreiro)中找到)。是的，我知道，围绕这个话题还有很多其他的东西，所以我们会简单地回到这个话题。但本周我决定打破僵局，谈论数据科学中一个非常基础的话题，当我刚开始研究建模和机器学习时，这给我带来了一些头疼的问题:**训练测试分割**。

没有人生来就知道，所以如果你还不知道什么是火车测试分裂，不要担心。然而，这是该领域中的一个基本概念，因此在本文中，我将尝试简要介绍这个主题，并告诉您我个人在开始处理列车测试分割时所犯的一些错误。希望你能从我费时的业余错误中学到一些东西:)

# 什么是列车测试分离，我们为什么需要它？

为了了解什么是训练测试分割，我们需要首先理解什么是“测试组”,以及为什么我们在进行 ML 建模时需要一个测试组。

简而言之，当我们试图预测任何类型的输出时，我们将使用数据集来“训练”机器学习模型。这个模型将尝试从数据中学习尽可能多的东西，以便做出准确的预测。同样，也许我们的模型会从中学到太多东西，以至于它只能预测我们给他的一堆数据，而不能预测任何其他数据。

![](img/58ef1186392f11784c7a4a0253c52e83.png)

这个潜在的问题或风险是我们通常在机器学习中应用的几个工具和概念的启动点:

*   偏差-方差权衡，简而言之，就是我们的模型应该从我们的训练数据中学习多少。如果它学习得太多，我们会说它有“高方差”，它会“过度拟合”我们的数据。相反，如果它学习得太少，它就会有“高偏差”，并且模型会“不适合”我们的训练数据。

![](img/9bb11a589f2356b9cf1fb6c0abef23fa.png)

*   当谈到所有这些时，正则化的概念也很方便，因为这是一种允许我们控制我们的模型从我们的数据中学习多少的技术。这个概念并不简单，但是可以很容易地用 Python 来应用。如果你想了解更多，我强烈推荐 Josh Starmer 的 StatQuest 的[这个](https://www.youtube.com/watch?v=Q81RR3yKn30)和[这个](https://www.youtube.com/watch?v=NGf0voTMlcs)基本视频。
*   除了控制我们的模型从数据中学习多少的任何一种技术之外，一个成熟的实践是分割我们的数据来评估我们的模型，因此我们可以确保它在不同的元素上表现良好。这里是**测试分割**概念最终出现的地方！我们的想法是将原始数据分成两组:不出意外，训练组将用于训练我们的模型。虽然我们会留下一堆数据，所以一旦我们已经训练了我们的模型，并且我们对它的性能感到满意，我们就可以用一堆全新的数据来评估它，以检查模型是否一致。这将是我们的测试组。如果我们在测试集上获得的分数比在训练组中获得的分数差得多，那么我们很可能过度拟合了训练数据。通常，80-20 或 70-30%的列车测试分割被认为是合理的。

![](img/1f2dcb9b7e3fb5310d271b78a47d1868.png)

*   最后，我们还可以讨论在评估我们模型的性能时进行[交叉验证](https://en.wikipedia.org/wiki/Cross-validation_(statistics))的概念，但这将不得不等到另一篇文章:)

# 我们如何用 Python 进行适当的训练测试分割？

像往常一样，Sklearn 让我们的一切变得如此简单，它有一个漂亮的救命库，这对于执行训练测试分割来说非常方便:

```
from sklearn.model_selection import train_test_split
```

[文档](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)非常清楚，但是无论如何让我们看一个简单的例子:

```
X_train, X_test, y_train, y_test = train_test_split(your_data, y, test_size=0.2, random_state=123)
```

现在，下一步将是…哦，等等，就这些！

关于如何实现这个库的内容真的不多。非常简单，现在您将有 4 组不同的数据:

1.  X_train:这将是你的训练组
2.  X_test:这将是你的测试组
3.  Y_train:这将是您的培训组的目标
4.  Y_test:可以想象，这将是您的测试组的目标

然而，尽管听起来很容易，但是如果您第一次使用该库，即使您已经使用过几次，也可能会面临一些风险或问题。让我们看看它们，这样你就不会像以前发生在我身上的那样掉进兔子洞了。

![](img/b59612066c3a6aa42ec9ccf3381b02bb.png)

# 我在训练测试中犯的 6 个业余错误

1.  **乱写你的火车测试分割码**

是的，虽然听起来很傻，但它有可能成为一个巨大的难题。想象一下，现在是凌晨，你整晚都在处理一个数据集。清理、合并数据、做一些功能工程……很平常的事情。该是你进行火车测试拆分的时候了，这样你可以在睡觉前尝试一个简单的模型。你写你的代码，但不是写:

```
X_train, X_test, y_train, y_test
```

例如，您写道:

```
X_test, X_train, y_test, y_train
```

听起来很傻？数据科学中最重要的规则之一是，在你对自己的训练/交叉验证分数感到满意之前，不应该透露你的测试分数。但是请记住，您无序地编写了您的训练测试分割代码，因此您得到的分数不是您的训练，而是您的测试分数。你可能会花上几个小时试图理解为什么你的训练数据得到这么低的值。或者更糟糕的是，你可能会因为这样糟糕的表现而放弃你的项目。在任何情况下，这都是一个错误，一旦犯了，就很难发现，这可能会导致花几个小时深入代码，试图解决这个愚蠢的错误。

**2。错误输入测试组的大小**

您应该指定的参数之一是“train_size”或“test_size”。您应该只使用其中一种，但更重要的是，一定不要混淆它们。否则，您可能只设置了 20–30%的训练集。这可能会导致几个问题。从没有足够的数据来训练适当的模型，到获得太好或太差的结果，这些结果可能会导致您进行一些耗时的进一步分析。

**3。除了您的训练数据之外，标准化您的测试组**

标准化是将在不同尺度上测量的值调整到一个公共尺度的过程。假设你正试图预测一个人是男是女，给定一组特征，如身高、体重和心率。在这种情况下，所有要素的比例都不同。例如，身高可以用厘米表示，而体重可以用公斤表示。在这种情况下，强烈建议对数据进行归一化处理，以一个通用的比例来表示所有数据。

Sklearn 提供了一个非常友好的库来做这件事，调用:

```
from sklearn.preprocessing import StandardScaler
```

归一化过程采用每个要素的平均值和标准偏差，并调整其比例，使其介于-1 和 1 之间，平均值为 0。一旦我们导入了库，我们就可以创建一个对象 StandardScaler，继续进行规范化:

```
scaler = StandardScaler()
```

然而，如果我们将数据分成训练组和测试组，我们应该首先使用我们的训练组来适应我们的 StandardScaler 对象，然后使用相同的对象来转换我们的测试组。例如:

```
scaler.fit(X_train)X_train = scaler.transform(X_train)X_test = scaler.transform(X_test)
```

为什么我们必须以这种方式规范化数据？请记住，我们将使用我们的数据来训练我们的模型，因此我们希望我们的 StandardScaler 对象注册并继续处理我们的训练集的平均值和标准差，并使用它来转换我们的测试组。否则，我们会做两个不同的变换，取两个不同的平均值和两个不同的标准差。将本应相同的数据视为不同的数据。

**4。需要时不打乱数据，反之亦然**

我们的 Sklearn train_test_split 的另一个参数是‘shuffle’。让我们保留前面的例子，假设我们的数据集由 1000 个元素组成，其中前 500 个对应于男性，后 500 个对应于女性。此参数的默认值为“True ”,但如果我们由于错误或疏忽将其设置为“False ”,并且我们将数据分成 80-20 份，我们将最终使用包含 500 名男性和 300 名女性的数据集来训练我们的模型，并使用其中仅包含 200 名女性的数据集来测试它。

考虑到缺省值是‘True’，所以如果到了你不想打乱数据的时候，别忘了指定它；)

**5。不明智地使用“分层”参数**

“分层”参数派上了用场，这样我们的测试组中产生的样本中的值的比例将与提供给参数分层的值的比例相同。这在处理分类问题时特别有用，因为如果我们不为这个参数提供一个类似数组的对象，我们可能会以测试组中目标类的非代表性分布结束。

通常，通过像这样传递目标变量来使用该参数:

```
X_train, X_test, y_train, y_test = train_test_split(your_data, y, test_size=0.2, ***stratify=y***, random_state=123, shuffle=True)
```

**6。忘记设置“随机状态”参数**

最后，这是我们可以在 Sklearn 的几个工具中找到的东西，文档对它的工作原理非常清楚:

> 如果 int，random_state 是随机数生成器使用的种子；如果是 RandomState 实例，random_state 是随机数生成器；如果没有，随机数生成器就是 np.random 使用的 RandomState 实例。

换句话说:如果你没有指定一个 number 或者 RandomState 对象实例，train_test_split 的每次迭代都会给你不同的组，因为用于进行随机分割的种子是不同的。如果出于某种原因我们必须运行我们的代码，并且我们开始获得不同的结果，这可能会导致混乱。

我的朋友们，这是我在使用火车测试分割时犯的 6 个错误，由于业余爱好者的错误，这些错误使我花费了数小时进行解码和调试。如果你不幸遇到了其他人，我很想听听。一如既往，**欢迎任何建设性的批评或建议通过评论区**:)

此外，不要忘记查看我上一篇关于 5 分钟内[网络抓取的文章](/web-scraping-in-5-minutes-1caceca13b6c)以及我的[作者简介](https://towardsdatascience.com/@g.ferreiro.volpi)中关于数据科学的更多内容。如果你喜欢这篇文章，不要忘了关注我，**如果你想直接在你的邮箱里收到我的最新文章，就订阅我的时事通讯吧:)**

[![](img/d4f959281d0a4358adc1c1b726954de9.png)](https://gmail.us3.list-manage.com/subscribe?u=8190cded0d5e26657d9bc54d7&id=3e942158a2)

感谢阅读！