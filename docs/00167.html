<html>
<head>
<title>The Learning Process: Logistic Regression for Facial Recognition– Take 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习过程:面部识别的逻辑回归——第 2 课</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-learning-process-logistic-regression-for-facial-recognition-take-2-6a1fef4ebe21?source=collection_archive---------28-----------------------#2019-01-07">https://towardsdatascience.com/the-learning-process-logistic-regression-for-facial-recognition-take-2-6a1fef4ebe21?source=collection_archive---------28-----------------------#2019-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="831c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用新的视角重新审视之前的项目。</h2></div><p id="d00b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">你们中的一些人可能读过“<a class="ae lc" rel="noopener" target="_blank" href="/logistic-regression-for-facial-recognition-ab051acf6e4">面部识别的逻辑回归</a>”，这是我大约 3 周前在这里发表的。从那以后，我加深了对机器学习的理解。现在，我正在写这篇文章(并保持旧文章在线),努力记录学习数据科学的道路。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/21e9ed366284d6fc7a3772071208eeff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*fol8489liEf8GMB8qUxtsw.png"/></div></figure><p id="dda4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">本着我最喜欢的数据科学家之一 Brandon Rohrer 的精神，我欢迎你们所有人都承认我们将不完美的项目推向世界，并且接受它们的不完美是通往成功之路的最重要的一步。</p><h1 id="95ff" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">反馈过程</h1><p id="3241" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">一位才华横溢的数据科学家最近加入了我们熨斗学校的数据科学教师团队。她的名字叫<a class="ae lc" href="https://www.linkedin.com/in/fangfang-lee/" rel="noopener ugc nofollow" target="_blank">芳芳李</a>，毫无疑问，她是一个名副其实的坏蛋。热门提示:总是请比你聪明得多的人来评论你的工作。</p><p id="fa69" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在向芳芳展示了我创建模型的第一次尝试(并一次又一次地展示了她的后续迭代——并阅读了大量博客)之后，我准备好了下一次尝试的待办事项列表。</p><h1 id="69ce" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">软经验教训</h1><ul class=""><li id="4e05" class="mi mj iq ki b kj md km me kp mk kt ml kx mm lb mn mo mp mq bi translated"><strong class="ki ir">始终让你试图用你的模型回答的问题足够清晰— </strong>如果你的听众不知道你试图解决的问题，他们为什么要关心你的解决方案？</li><li id="5cdb" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated"><strong class="ki ir">让您对结果的解释同样清晰— </strong>任何人都可以读出分类报告的结果。解释你的结果<em class="mw">意味着什么</em>以及为什么它们对你的观众很重要，这使得数据科学家对每个行业的企业和利益相关者来说都是无价的。</li></ul><h1 id="9d68" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">吸取的惨痛教训</h1><ul class=""><li id="297a" class="mi mj iq ki b kj md km me kp mk kt ml kx mm lb mn mo mp mq bi translated"><strong class="ki ir">您不需要在逻辑回归中对数据进行归一化</strong>-在类似线性回归的过程中对要素进行归一化的要点是，由系数指示的每个单位增量都被视为所有要素的“单一单位”，而不管它们最初是如何测量的，也不管它们的比例如何。然而，在<em class="mw">逻辑</em>回归中，我们感兴趣的是每个特征与因变量的相对位置。换句话说，我们感兴趣的是<em class="mw">数量</em>增加或减少成功几率的对数。因此，没有必要对“单元”的含义进行标准化。更多信息见这个<a class="ae lc" href="https://stats.stackexchange.com/questions/48360/is-standardization-needed-before-fitting-logistic-regression" rel="noopener ugc nofollow" target="_blank">伟大的线程</a>。</li><li id="d114" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated"><strong class="ki ir">仅在极端类别不平衡的情况下使用 SMOTE</strong>—SMOTE(合成少数过采样技术)创建合成数据，对数据的少数类别进行过采样。当您的数据严重不平衡时，这是一种非常强大和有用的技术。然而，在我的数据中，有大约 80/20 的皮肤/无皮肤分裂，这样一个强有力的措施是不必要的；我了解到，当你没有其他选择时，你只想使用合成数据。</li><li id="df83" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated"><strong class="ki ir"> K-Fold 交叉验证是真正的 MVP </strong> —虽然初学者数据科学家最适合使用交叉验证的“保持方法”(即在创建机器学习模型时创建单个训练集和单个测试集)，但这种方法可能会出现高方差和数据泄漏，因为它本质上依赖于将哪些数据点放在训练和测试集中。这意味着模型的结果可能会有很大差异，具体取决于将哪些数据放入定型测试集中。另一方面，k-fold 交叉验证是对模型准确性的更严格的测试，因为它实际上是对数据组多次运行这一过程，然后对所有这些小型测试的模型准确性进行平均。(你可以在我关于这个项目的新<a class="ae lc" href="https://github.com/aulorbe/Skin-Segmentation-Logit-Regression" rel="noopener ugc nofollow" target="_blank">自述</a>中读到更多细节。)</li></ul><h1 id="dce2" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">转到第二段</h1><p id="382f" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">考虑到所有这些教训，我重新做了我的第一个模型，没有规范我的值或使用 SMOTE。我还花时间用 k 倍交叉验证(k = 4)评估了我的模型，并使我的代码更加简洁。</p><p id="8bf6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最后，我得到了和我之前的模型差不多的准确度分数(~91%)，但是这个版本无疑更加可信和严谨。</p><p id="484f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我鼓励所有阅读这篇文章的人访问我项目的<a class="ae lc" href="https://github.com/aulorbe/Skin-Segmentation-Logit-Regression" rel="noopener ugc nofollow" target="_blank"> repo </a>来深入了解每一步，可视化，所有结果的解释，以及有关道德的简短讨论。</p></div></div>    
</body>
</html>