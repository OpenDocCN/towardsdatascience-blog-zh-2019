<html>
<head>
<title>Nuances in the usage of Word Embeddings: Semantic and Syntactic Relationships</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单词嵌入用法的细微差别:语义和句法关系</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nuances-in-the-usage-of-word-embeddings-semantic-and-syntactic-relationships-780940fe28f?source=collection_archive---------29-----------------------#2019-11-10">https://towardsdatascience.com/nuances-in-the-usage-of-word-embeddings-semantic-and-syntactic-relationships-780940fe28f?source=collection_archive---------29-----------------------#2019-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ab136502b7ba4a9df7b300c233b799b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b6491i9SZb0EdfmI"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@danielcgold?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Dan Gold</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/></div><div class="ab cl kg kh hx ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="im in io ip iq"><blockquote class="kn ko kp"><p id="a724" class="kq kr ks kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">注:前面是超级短帖。我想只是精神食粮吧？:)</p></blockquote><h1 id="9195" class="lp lq jj bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">介绍</h1><p id="b0f6" class="pw-post-body-paragraph kq kr jj kt b ku mn kw kx ky mo la lb mp mq le lf mr ms li lj mt mu lm ln lo im bi translated">在过去的几周里，我一直在写关于单词嵌入的文章。</p><p id="eac3" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/creating-word-embeddings-for-out-of-vocabulary-oov-words-such-as-singlish-3fe33083d466">我如何为新加坡英语这样的口语语言从头开始创建单词嵌入</a>，以及我如何将其扩展到<a class="ae jg" rel="noopener" target="_blank" href="/using-a-generalised-translation-vector-for-handling-misspellings-and-out-of-vocabulary-oov-words-494cd142cd31">处理拼写错误或带有翻译向量的不在词汇表中的单词</a>。</p><p id="b634" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">在后一篇文章中，我测试了我的实验对下游文本分类准确性的影响。</p><p id="4c8f" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">然而，通过更多的阅读和研究，我开始意识到单词嵌入用法的细微差别及其真正的含义。</p><p id="db3f" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated"><strong class="kt jk">请允许我详细说明。</strong></p><p id="4bfd" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">你看，<strong class="kt jk"> <em class="ks">使用</em> </strong>单词嵌入进行自然语言处理(NLP)是一回事，每个人都可以做到。</p><p id="edd7" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">但是…</p><p id="9bdb" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated"><strong class="kt jk"> <em class="ks">理解</em> </strong>它对下游任务的影响是另一回事。</p><p id="2676" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">为了<strong class="kt jk">理解</strong>它的含义，你首先需要知道所使用的单词嵌入学到了什么语义和句法关系。</p><h1 id="3af4" class="lp lq jj bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">什么是语义和句法关系？</h1><p id="065c" class="pw-post-body-paragraph kq kr jj kt b ku mn kw kx ky mo la lb mp mq le lf mr ms li lj mt mu lm ln lo im bi translated">我想<em class="ks">【什么】</em>在我说到<em class="ks">“为什么”的时候就说清楚了。</em></p><p id="3fb8" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">那么，这有什么关系呢？</p><blockquote class="mv"><p id="c9e6" class="mw mx jj bd my mz na nb nc nd ne lo dk translated">这很重要，因为它以比你想象的更多的方式影响你的语言模型的下游准确性。</p></blockquote><p id="001c" class="pw-post-body-paragraph kq kr jj kt b ku nf kw kx ky ng la lb mp nh le lf mr ni li lj mt nj lm ln lo im bi translated">以情感分析这样的 NLP 任务为例。</p><p id="7226" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">如果所使用的单词嵌入更多地捕捉了单词的<strong class="kt jk">语义</strong>(单词的意思)或它们之间的<strong class="kt jk">句法</strong>(英语语法结构)关系，你的情感模型会更好吗？</p><p id="e2ea" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">斯坦福大学的 Global Vectors (GloVe)等现成的单词嵌入似乎在与语义相关的任务中表现得更好，如他们的研究论文所示。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/8fc2e6f024074006791185472e422029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5w7H-Y3leWU7bBd-4pSmGQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Figure 1 — Example of a Semantic Relationship Task</figcaption></figure><p id="b810" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">另一方面，Google 的 Word2Vec 虽然在大多数自然语言处理任务中表现不如 GloVe，但似乎在与相关的任务中表现更好。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/a2f3b75ccb94d8ae573a99aa91016298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JoI0F0TIM36fk485gzZxCA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Figure 2 — Example of Syntactic Relationship Task</figcaption></figure><p id="72a9" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">话虽如此，<strong class="kt jk">语义和句法关系对于语言模型的良好表现同样重要。</strong></p><blockquote class="mv"><p id="a845" class="mw mx jj bd my mz na nb nc nd ne lo dk translated">唉，这个世界上没有什么是完美的。</p></blockquote><p id="ab35" class="pw-post-body-paragraph kq kr jj kt b ku nf kw kx ky ng la lb mp nh le lf mr ni li lj mt nj lm ln lo im bi translated">没有任何预先训练好的单词嵌入在这两方面都很出色。我个人认为，GloVe 在大多数 NLP 任务中表现出色。</p><p id="115a" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">此外，这个世界似乎已经脱离了预先训练的单词嵌入。</p><p id="27fa" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">注意力模型是现在中的<strong class="kt jk">。</strong></p><p id="7901" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">看看谷歌 10 月 25 日的这篇文章吧，<a class="ae jg" href="https://blog.google/products/search/search-language-understanding-bert" rel="noopener ugc nofollow" target="_blank">比以往更好地理解搜索</a>。</p><p id="fc31" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">谷歌最近实现了他们著名的算法“BERT ”,这是一种注意力模型——注意力模型基本上能够给在不同上下文中使用的<strong class="kt jk">相同单词</strong>赋予<strong class="kt jk">不同的</strong>单词嵌入。</p><p id="ddfb" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">例如:</p><p id="f3b3" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated"><em class="ks">“我去</em> <strong class="kt jk"> <em class="ks">银行</em> </strong> <em class="ks">存工资。它坐落在一条</em> <strong class="kt jk"> <em class="ks">河边</em> </strong> <em class="ks">”</em></p><p id="b27d" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">作为人类，我们知道“银行”这个词的第一个用法是指金融机构，而这个词的最后一个用法是指河流。</p><p id="f254" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">注意模型对单词“银行”给出了不同的单词嵌入，例如金融银行和河岸银行。</p><p id="eccb" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">很酷的东西，是吧？</p><p id="fb33" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">公平地说，我也想指出百度的<a class="ae jg" href="https://arxiv.org/abs/1905.07129" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jk">厄尼</strong> </a>。</p><p id="bb4e" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">厄尼实际上是 NLP 世界中最新最受关注的模型。到目前为止，ERNIE 在所有标准基线 NLP 任务中的表现都超过了 BERT，甚至在普通话方面也是如此。不知道为什么人们不怎么谈论它。</p><p id="e055" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">抱歉，在谈论注意力模型时分心了。</p><p id="c16a" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">让我们回到最初的话题！</p><h1 id="3718" class="lp lq jj bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">结尾注释</h1><p id="652b" class="pw-post-body-paragraph kq kr jj kt b ku mn kw kx ky mo la lb mp mq le lf mr ms li lj mt mu lm ln lo im bi translated">我想我在这篇短文中想要表达的是:</p><blockquote class="mv"><p id="22ed" class="mw mx jj bd my mz na nb nc nd ne lo dk translated">对于所有的 NLP 任务，没有神奇的预训练单词嵌入。</p></blockquote><p id="5e4a" class="pw-post-body-paragraph kq kr jj kt b ku nf kw kx ky ng la lb mp nh le lf mr ni li lj mt nj lm ln lo im bi translated">你必须记住你要解决的 NLP 任务，并训练最适合的单词嵌入类型。</p><p id="201c" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">就拿我的新加坡英语文章来说，我肯定不会用 GloVe 或 Word2Vec。</p><p id="948d" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">记住，单词嵌入最终会影响你下游的准确性。</p><p id="f3ef" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">垃圾进来，垃圾出去。</p><p id="39e5" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">希望这篇关于使用单词嵌入时所涉及的细微差别的短文能给你一些启发！</p><p id="275f" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">下次见，再见！</p><p id="5d69" class="pw-post-body-paragraph kq kr jj kt b ku kv kw kx ky kz la lb mp ld le lf mr lh li lj mt ll lm ln lo im bi translated">LinkedIn 简介:<a class="ae jg" href="https://www.linkedin.com/in/timothy-tan-97587190/" rel="noopener ugc nofollow" target="_blank">蒂莫西·谭</a></p></div></div>    
</body>
</html>