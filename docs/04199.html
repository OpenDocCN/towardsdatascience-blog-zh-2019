<html>
<head>
<title>Predicting Cancer with Logistic Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 中的逻辑回归预测癌症</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-cancer-with-logistic-regression-in-python-7b203ace16bc?source=collection_archive---------18-----------------------#2019-07-01">https://towardsdatascience.com/predicting-cancer-with-logistic-regression-in-python-7b203ace16bc?source=collection_archive---------18-----------------------#2019-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4a31" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解数据，逻辑回归，测试数据，混淆矩阵，ROC 曲线</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/74846fb0aee7fcdebf0f219ed897a8c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0ZXa6TZBiH_-hvoWkhFcg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://unsplash.com/photos/rmWtVQN5RzU" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h1 id="1832" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">简介:</h1><p id="4d8c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我的第一个<a class="ae ky" rel="noopener" target="_blank" href="/univariate-logistic-regression-example-in-python-acbefde8cc14">逻辑回归分析中，</a>我们仅仅触及了表面。讨论的只是高级概念和双变量模型示例。在这一分析中，我们将着眼于更具挑战性的数据，并学习更先进的技术和解释。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="32d3" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">目录:</h1><p id="bcdb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.数据背景</p><p id="d1c6" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">2.数据探索/清理</p><p id="6192" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">3.数据可视化</p><p id="5372" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">4.构建模型</p><p id="bb4b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">5.测试模型</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="7b65" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">数据背景:</h1><p id="e201" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">测量体内某些蛋白质的水平已经被证明可以预测癌症的发展<a class="ae ky" href="https://www.webmd.com/cancer/cea-tests#1" rel="noopener ugc nofollow" target="_blank">。医生可以进行测试来检查这些蛋白质的水平。我们有 255 名患者的样本，希望获得关于 4 种蛋白质及其与癌症生长的潜在关系的信息。</a></p><p id="23c2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><strong class="lt iu">我们知道:</strong></p><ul class=""><li id="6fec" class="ne nf it lt b lu mz lx na ma ng me nh mi ni mm nj nk nl nm bi translated">每位患者测得的每种蛋白质的浓度。</li><li id="319d" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">每个患者是否已经被诊断患有癌症(0 =没有癌症；1=癌症)。</li></ul><blockquote class="ns nt nu"><p id="1254" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated"><strong class="lt iu">我们的目标是:</strong></p><p id="9c05" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated">通过从我们样本中的蛋白质水平和癌症之间的关系中提取信息来预测未来的患者是否患有癌症。</p></blockquote><p id="9f91" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><strong class="lt iu">我们将关注的 4 种蛋白质:</strong></p><p id="f3a6" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">甲胎蛋白</p><p id="e2c2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">癌胚抗原</p><p id="ab6d" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">癌抗原 125</p><p id="3087" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">癌抗原 50</p><p id="56a6" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我从 UAB 的 MBA 项目<a class="nz oa ep" href="https://medium.com/u/4e564d7496d6?source=post_page-----7b203ace16bc--------------------------------" rel="noopener" target="_blank"> @ </a>那里得到了这套用于教育目的的数据。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="7fb0" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">数据探索/清理</h1><p id="03c9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们通过引入数据和导入必要的模块来开始分析。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="1a5a" class="og la it oc b gy oh oi l oj ok">%matplotlib inline<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from sklearn.model_selection import train_test_split<br/>import seaborn as sns<br/>df = pd.read_excel(r"C:\Users\Andrew\Desktop\cea.xlsx")<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/07ce36b3bfc69da055c43af50693d329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*alb8ezu4lkJ621mCXwHxXg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 1</figcaption></figure><p id="7051" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">df.head()为我们提供了数据集的前 5 个特征。每行是一名患者，每列包含一个描述性属性。类别(Y)描述了患者是没有癌症(0)还是患有癌症(1)。接下来的 4 列是在病人血液中发现的蛋白质水平。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ea6a" class="og la it oc b gy oh oi l oj ok">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/43f5743d5ef78d257c1729a4e2b7ef95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-e5STjJnKZrr9NxUAy7DA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 2</figcaption></figure><p id="dc2b" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我们可以从<em class="nv">描述</em>方法中检索关于样本的一些基本信息。该数据集中有 255 行，具有不同的标准差和均值。值得一提的是，与平均值相比，这 4 种蛋白质都具有较低的 50%值。这意味着大多数蛋白质水平很低。这 4 种蛋白质还具有高范围，这意味着存在高值异常值。比如我们看 AFP，均值 4.58，中位数 3.86，最高值 82.26。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="3d3c" class="og la it oc b gy oh oi l oj ok">df.isnull().sum()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/20fd54b86fa8f294ba1bee91959c28e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SIDchagEddRmcZbfzpYSUg.png"/></div></div></figure><p id="083f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">检查数据中是否有空值总是好的。这可以通过多种方式解决。幸运的是，这次我们不用担心空值。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="a8e6" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">数据可视化</h1><p id="6627" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们想象一下我们的每个变量，并根据我们所看到的假设可能会发生什么:</p><h2 id="a638" class="og la it bd lb oo op dn lf oq or dp lj ma os ot ll me ou ov ln mi ow ox lp oy bi translated">目标变量(Y)</h2><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="3426" class="og la it oc b gy oh oi l oj ok">yhist = plt.hist('class (Y)', data = df, color='g')<br/>plt.xlabel('Diagnosis (1) vs no diagnosis (0)')<br/>plt.ylabel('Quantity')<br/>plt.title('Class (Y) Distribution')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/3397f180570b1b4192225942f4d77d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4j68kVXV3LlQsw0dukUkjg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 3</figcaption></figure><p id="06a1" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">这个样本中有更多的无癌患者。如图 2 所示，“类别(Y)”变量的平均值为 0.44。</p><h1 id="2d47" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">菲律宾武装部队；法新社；甲胎蛋白；金融理财师证书</h1><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="1db3" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#setting the axes</strong><br/>axes = plt.axes()<br/>axes.set_xlim([0,(df['AFP'].max())])</span><span id="d389" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#making histogram with 20 bins</strong><br/>plt.hist('AFP', data = df, bins = 20)<br/>plt.xlabel('AFP Level')<br/>plt.ylabel('Quantity')<br/>plt.title('AFP Distribution')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/1b936f274735d31dd23471a80e2b8bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJVIweoR5oHdo_UWcmRSYg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 4</figcaption></figure><p id="fcc1" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">如前所述，甲胎蛋白水平低的患者相对较多。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ac23" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#color palette</strong><br/>pal = sns.color_palette("Set1")</span><span id="1d81" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#setting variable for max level of protein in dataset</strong><br/>lim = df['AFP'].max()</span><span id="92a7" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#setting bin size to be 20</strong><br/>bins = np.linspace(0,lim,(lim/(lim*(1/20))))</span><span id="68d3" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#creating new column in df with bin categories per feature</strong><br/>df['AFP_binned'] = pd.cut(df['AFP'], bins)</span><span id="18fb" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#creating a crosstab stacked bar chart variable</strong><br/>chart = pd.crosstab(df['AFP_binned'],df['class (Y)'])</span><span id="7d36" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#normalizing chart and plotting chart</strong><br/>chart.div(chart.sum(1).astype(float), axis=0).plot(kind='bar', color = pal,stacked=True)<br/>plt.xlabel('Bins')<br/>plt.ylabel('Quantity')<br/>plt.title('Normalized Stacked Bar Chart: AFP vs Class(Y)')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/0c5f487cc3208c9c875a6c19c7953f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gzm7ILXqb5xfXhLE72-77g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 5</figcaption></figure><p id="1817" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">作为分布直方图的补充，上面的堆积条形图显示了随着 AFP 水平的增加，1 与 0 的比例。该图表与分布直方图一样，也分为 20 个区间。结合我们从上述目标变量的分布和比例中获得的知识，我们可以直观地确定从该蛋白质中可能没有获得太多的预测知识。</p><blockquote class="ns nt nu"><p id="0f30" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated">让我们一步一步来。大多数患者的 AFP 值低于 10，如图 4 中的前 2 条所示。因为大多数患者都在前两个柱中，所以图 5 中它们之间 Y 的变化比其他柱中 Y 的变化更重要。</p></blockquote><p id="0a86" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">从柱 1 到柱 2，癌症患者的比例略有增加。癌症患者的比例从第 2 栏下降到第 3 栏。bar 3 之后，剩下来分析的患者少之又少，对趋势影响不大。从这里我们可以看到，目标变量看起来基本上与 AFP 的变化无关。最显著的变化(条 1 到 2)非常轻微，之后的变化不在同一方向。</p><p id="7406" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">让我们看看其他蛋白质是什么样子的。</p><h1 id="aa2f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">成本效益分析(Cost Effectiveness Analysis)</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/2eef01664a2c2ddf58d84e3a055587c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfw6XR7g3KK7ooEKFGrfyg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 6</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/4c22dbd3bd822697e1fef82cd78b4adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gr4oXyVEQMh0khDe16nWKw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 7</figcaption></figure><p id="400f" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">东航似乎有一个不同的故事。图 6 显示了与 AFP 相似的分布形状；然而，图 7 显示了癌症发病率的不同变化。就像 AFP(由于分布形状)一样，柱之间最显著的癌症变化在柱 1 和柱 2 之间。</p><p id="5331" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">从柱 1 到柱 2 的变化从大约 63%的非癌性变为 18%的非癌性(或者换句话说，37%的癌性变为 82%的癌性)。此外，从 bin 2 到 bin 3 的变化是相同的方向，更多的癌症。从具有 100%癌症的 bin 5 开始的异常值加强了较高 CEA 可能指示癌症的趋势。</p><h1 id="3b71" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">CA125</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/b4a792b0add516478bed7ee699b4d96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzX1yhLXSgbTT4qQCjpaOQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 8</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/62f4ef7e2de3bfa1e690b92527223dbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tof_mjmIxo-eoy36tBfM4w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 9</figcaption></figure><p id="62c4" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">CA125 有点棘手。柱 1-2 表明，像癌胚抗原一样，这种蛋白的高水平可能导致癌症。然而，这一次似乎有两种趋势。随着几乎所有的后一类人群变成非癌症人群，这一趋势发生逆转。我们稍后将更详细地研究这个变量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/f7c7dcfb8d26132e4e938f5befa02b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcsZ88KJ4e4o3d7cfVLRMg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 10</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/64b5798b6853b18eb871ab38c2a76e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N5EMM1oj1urDho7O-qqXyg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 11</figcaption></figure><p id="cc3c" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">CA50 看起来没什么前途。前 4 个条柱似乎表明了较高癌症发病率的趋势。然而，趋势看起来在第 7-9 条中发生了逆转。CA50 水平和癌症之间的关系可能很小或可以忽略。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="32ac" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">构建模型</h1><p id="f49a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们把这个模型放在一起，看看回归能告诉我们什么。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="2fd8" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#importing module</strong><br/>import statsmodels.api as sm</span><span id="f86e" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#setting up X and y</strong><br/>cols= [‘AFP’,’CEA’,’CA125',’CA50']<br/>X= df[cols]<br/>y = df[‘class (Y)’]</span><span id="5026" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#filling in the statsmodels Logit method</strong><br/>logit_model = sm.Logit(y,X)<br/>result = logit_model.fit()<br/>print(result.summary())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/8fd8ef7bce88d2d1cd77c64ed15b9eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B6gjtZ9qFwhBcS2xg2eDBQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 12</figcaption></figure><p id="d1dd" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">突出显示的值是本报告中重要的内容:我们的 4 个独立变量及其 p 值。AFP 和 CA50 的 p 值较高。如果我们的α值为 0.05，那么 AFP 和 CA50 的值太高，无法拒绝我们的无效假设(我们的无效假设是蛋白质水平对癌症发病率没有影响)。然而，CEA 和 CA125 通过了测试，并且被确定为显著的。AFP 和 CA50 都是基于我们在堆积条形图上看到的假设而被忽略的，所以这是有道理的。让我们去掉这些变量，再次进行回归分析:</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="bd5f" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#deleted p values above the 0.05 alpha threshold</strong><br/>cols= ['CEA','CA125']<br/>X= df[cols]<br/>y = df['class (Y)']<br/>logit_model = sm.Logit(y,X)<br/>result = logit_model.fit()<br/>print(result.summary())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/01e04160b18f81de9bf794a7627b6ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a_riOe_vwbL_CQdt-JMnFw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 13</figcaption></figure><p id="1267" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">有了我们的最终系数，我们对每个剩余蛋白质和癌症之间的关系有了更多的了解。CEA 的阳性关系比 CA125 的阴性关系强约 3 倍。随着癌胚抗原的增加，癌症的可能性增加。随着 CA125 的增加，癌症的可能性降低。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="ac65" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">测试模型</h1><p id="9bab" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将把样本数据分为训练和测试，以测试我们的回归结果。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="f799" class="og la it oc b gy oh oi l oj ok">from sklearn.linear_model import LogisticRegression<br/>from sklearn import metrics</span><span id="2254" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#shuffling df</strong><br/>df = df.sample(frac=1).reset_index(drop=True)</span><span id="a7e5" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#redefining columns </strong><br/>cols= ['CEA','CA125']<br/>X= df[cols]<br/>y = df['class (Y)']</span><span id="e7de" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Dividing into training(70%) and testing(30%)</strong><br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span><span id="a8c7" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Running new regression on training data</strong><br/>logreg = LogisticRegression()<br/>logreg.fit(X_train, y_train)</span><span id="6c86" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Calculating the accuracy of the training model on the testing data</strong><br/>accuracy = logreg.score(X_test, y_test)<br/>print('The accuracy is: ' + str(accuracy *100) + '%')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/e612c967c23580e8291605ac69adf22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucxO_AkNW33vI336tNKlLA.png"/></div></div></figure><p id="b6eb" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">形象化上面计算的精确度的一个好方法是使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>。下面是混淆矩阵的概念框架。</p><blockquote class="ns nt nu"><p id="deb4" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated">编辑:我和一个生物统计的朋友谈论我的分析，这个领域的惯例是这种疾病被认为是阳性的。我武断地将癌症设定为阴性，因为我当时并不知道这一点。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/32003c4766c200f99900853cc9bd5afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PQzpzwv3h98UGENcWwsPGA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 14</figcaption></figure><p id="4fdc" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">“迷惑”是很多人的关键词。试着一次看一行:第一行是一个好的起点。这一行告诉我们有多少实例被预测为良性的。如果我们查看这些列，我们可以看到该预测中实际值的拆分。请记住，行是预测值，列是实际值。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="1add" class="og la it oc b gy oh oi l oj ok">from sklearn.metrics import confusion_matrix<br/>confusion_matrix = confusion_matrix(y_test, y_pred)<br/>print(confusion_matrix)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/68dde87cf9d06f295104bd9d8f0ce188.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*gKvhyUow9u795AYjtuLIHw.png"/></div></figure><p id="1e57" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">将上面的矩阵与图 14 进行匹配，了解其含义:</p><ul class=""><li id="afd2" class="ne nf it lt b lu mz lx na ma ng me nh mi ni mm nj nk nl nm bi translated"><strong class="lt iu">我们模型的 39 个</strong>猜测是<strong class="lt iu">真阳性</strong>:模型认为病人没有癌症，他们确实没有癌症。</li><li id="dbb6" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">我们的模型的猜测中有 18 个是<strong class="lt iu">真阴性</strong>:模型认为病人患有癌症，他们确实患有癌症。</li><li id="4571" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> 14 </strong>我们的模型的猜测是<strong class="lt iu">假阴性</strong>:模型以为病人得了癌症，但实际上他们并没有得癌症</li><li id="2537" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> 6 </strong>我们的模型的猜测是<strong class="lt iu">假阳性</strong>:模型认为病人没有癌症，但他们实际上患了癌症。</li></ul><p id="66c2" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我们总数据的 30%给了测试组，剩下 255(.3) = 77 个被测试的实例。矩阵的和是 77。将“真实”的数字除以总数，将得到我们模型的精确度:57/77 = 74.03%。</p><blockquote class="ns nt nu"><p id="6e60" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated">请记住，在执行这个测试之前，我们随机打乱了数据。我运行了几次回归，得到了 65%到 85%的准确率。</p></blockquote></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="387e" class="kz la it bd lb lc mu le lf lg mv li lj jz mw ka ll kc mx kd ln kf my kg lp lq bi translated">受试者工作特征曲线</h1><p id="5cdb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们将执行<a class="ae ky" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">接收器操作特性</a> (ROC)分析，作为测试我们模型的另一种方式。该测试的两个目的是</p><ol class=""><li id="1c97" class="ne nf it lt b lu mz lx na ma ng me nh mi ni mm pn nk nl nm bi translated">确定最佳“截止”点在哪里。</li><li id="e549" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm pn nk nl nm bi translated">通过另一个称为“曲线下面积”(AUC)的指标来确定模型的分类效果。</li></ol><p id="7cb6" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我们将从头开始创建我们的 ROC 曲线。以下是用于格式化新数据框架以计算 ROC、截止点和 AUC 的所有代码。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="989a" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#Formatting y_test and y_predicted probabilities for ROC curve</strong><br/>y_pred_prob = pd.DataFrame(y_pred_prob)<br/>y_1_prob = y_pred_prob[1]<br/>y_test_1 = y_test.reset_index()<br/>y_test_1 = y_test_1['class (Y)']</span><span id="feab" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Forming new df for ROC Curve and Accuracy curve</strong><br/>df = pd.DataFrame({ 'y_test': y_test_1, 'model_probability': y_1_prob})<br/>df = df.sort_values('model_probability')</span><span id="1ffb" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Creating 'True Positive', 'False Positive', 'True Negative' and 'False Negative' columns </strong><br/>df['tp'] = (df['y_test'] == int(0)).cumsum()<br/>df['fp'] = (df['y_test'] == int(1)).cumsum()<br/>total_0s = df['y_test'].sum()<br/>total_1s = abs(total_0s - len(df))<br/>df['total_1s'] = total_1s<br/>df['total_0s']= total_0s<br/>df['total_instances'] = df['total_1s'] + df['total_0s']<br/>df['tn'] = df['total_0s'] - df['fp']<br/>df['fn'] = df['total_1s'] - df['tp']<br/>df['fp_rate'] = df['fp'] / df['total_0s']<br/>df['tp_rate'] = df['tp'] / df['total_1s']</span><span id="43f9" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Calculating accuracy column</strong><br/>df['accuracy'] = (df['tp'] + df['tn']) / (df['total_1s'] + df['total_0s'])</span><span id="444a" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Deleting unnecessary columns</strong><br/>df.reset_index(inplace = True)<br/>del df['total_1s']<br/>del df['total_0s']<br/>del df['total_instances']<br/>del df['index']<br/>df</span></pre><p id="7e54" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">为了理解下面的数据框中发生了什么，让我们一行一行地分析它。</p><ul class=""><li id="1dfd" class="ne nf it lt b lu mz lx na ma ng me nh mi ni mm nj nk nl nm bi translated"><strong class="lt iu">索引</strong>:这个数据帧是按照 model_probability 排序的，为了方便起见，我重新编制了索引。</li><li id="4765" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> CA125 和 CEA </strong>:蛋白质水平原始检测数据。</li><li id="0e6d" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> model_probability </strong>:该列来自我们的训练数据的逻辑模型，该模型基于输入的测试蛋白质水平输出其被分类为“1”(癌性)的概率预测。第一行是最不可能被归类为癌症的实例，其 CA125 水平高而 CEA 水平低。</li><li id="6db0" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">y_test :我们用来检查模型性能的测试数据的实际分类。</li></ul><blockquote class="po"><p id="643e" class="pp pq it bd pr ps pt pu pv pw px mm dk translated">其余的专栏仅仅基于“y_test”，而不是我们的模型的预测。把这些值想象成它们自己的混淆矩阵。这些将有助于我们确定以后的最佳分界点。</p></blockquote><ul class=""><li id="5636" class="ne nf it lt b lu py lx pz ma qa me qb mi qc mm nj nk nl nm bi translated"><strong class="lt iu"> tp(真阳性)</strong>:该列从 0 开始。如果 y_test 为‘0’(良性)，则该值增加 1。它是所有潜在真阳性的累积追踪器。第一行就是一个例子。</li><li id="5c39" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> fp(假阳性)</strong>:该列从 0 开始。如果 y_test 为‘1’(癌变)，则该值增加 1。它是所有潜在误报的累积跟踪器。第四行就是一个例子。</li><li id="695d" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> tn(真阴性)</strong>:该列从 32 开始(测试集中 1 的总数)。如果 y_test 为‘1’(癌变)，则该值减少 1。它是所有潜在真阴性的累积追踪器。第四行就是一个例子。</li><li id="9990" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> fn(假阴性)</strong>:该列从 45 开始(测试集中 0 的总数)。如果 y_test 为‘0’(良性)，则该值减少 1。它是所有潜在假阴性的累积跟踪器。第四行就是一个例子。</li><li id="fe92" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu">FP _ Rate(False Positive Rate)</strong>:这是通过获取行的误报计数并除以总的阳性数(在我们的例子中是 45)计算出来的。它让我们知道我们可以通过在该行设置分界点来分类的假阳性的数量。<strong class="lt iu">我们希望尽可能降低成本。</strong></li><li id="b33a" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu"> tp_rate(真阳性率)</strong>:也称为敏感度，计算方法是获取行的真阳性计数，然后除以阳性总数。它让我们知道我们可以通过在那一行设置分界点来分类的真阳性的数量。<strong class="lt iu">我们希望尽可能地保持高水平。</strong></li><li id="78ea" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated"><strong class="lt iu">准确性</strong>:真阳性和真阴性的总和除以总实例数(在我们的例子中是 77)。我们一行一行地计算潜在的精确度，基于我们混淆矩阵的可能性。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/db69cc9cbdabdd347e3022660d82fbfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*XoKHIqSgavV8wcOcJP_OXQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 15</figcaption></figure><p id="4ee5" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我粘贴了整个数据帧，因为它值得研究一段时间，并从所有移动的片段中找出意义。看完之后，试着找出最高的准确率。如果您可以找到它，您可以将其与相应的 model_probability 进行匹配，以发现我们数据的最佳分界点。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="a738" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#Plotting</strong><br/>plt.plot(df['model_probability'],df['accuracy'], color = 'c')<br/>plt.xlabel('Model Probability')<br/>plt.ylabel('Accuracy')<br/>plt.title('Optimal Cutoff')</span><span id="e1a3" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Arrow and Star</strong><br/>plt.plot(0.535612, 0.753247, 'r*')<br/>ax = plt.axes()<br/>ax.arrow(0.41, 0.625, 0.1, 0.1, head_width=0.01, head_length=0.01, fc='k', ec='k')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qe"><img src="../Images/85ffa873d9bbf6596c0791e406283fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQqzaFM-NBXHQ9_xxrUzQw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 16</figcaption></figure><p id="80f9" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">模型概率为 54%,其中精确度最高为 75%。这可能看起来违背直觉，但这意味着如果我们在将患者归类为癌症患者时使用 54%而不是 50%,这实际上会更准确。如果我们想最大限度地提高准确性，我们应该将阈值设置为 54%，但是，由于癌症的极端性质，将阈值降低到 50%以下可能是明智的，以确保无论如何都可以检查出可能患有癌症的患者。换句话说，当涉及到癌症时，假阳性比假阴性更重要！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="2456" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">最后，让我们绘制 ROC 曲线并找出 AUC:</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ab8b" class="og la it oc b gy oh oi l oj ok"><strong class="oc iu">#Calculating AUC</strong><br/>AUC = 1-(np.trapz(df[‘fp_rate’], df[‘tp_rate’]))</span><span id="f129" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Plotting ROC/AUC graph</strong><br/>plt.plot(df[‘fp_rate’], df[‘tp_rate’], color = ‘k’, label=’ROC Curve (AUC = %0.2f)’ % AUC)</span><span id="1dc3" class="og la it oc b gy pa oi l oj ok"><strong class="oc iu">#Plotting AUC=0.5 red line</strong><br/>plt.plot([0, 1], [0, 1],’r — ‘)<br/>plt.xlabel(‘False Positive Rate’)<br/>plt.ylabel(‘True Positive Rate (Sensitivity)’)<br/>plt.title(‘Receiver operating characteristic’)<br/>plt.legend(loc=”lower right”)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/b1d8b6b017ad0691772db983c4eacf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5yEBu26aeZlgYDYBGTfkyg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 17</figcaption></figure><p id="34b0" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">黑色的 ROC 曲线显示了我们的测试数据的真阳性率和假阳性率之间的权衡。穿过图表中心的红色虚线是为了提供一种最坏可能模型看起来像 ROC 曲线的感觉。</p><blockquote class="ns nt nu"><p id="1cc7" class="lr ls nv lt b lu mz ju lw lx na jx lz nw nb mc md nx nc mg mh ny nd mk ml mm im bi translated">ROC 线越靠近左上方，我们的模型越有预测性。它越像红色虚线，预测性就越低。</p></blockquote><p id="f62c" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">这就是曲线下面积(AUC)的由来。AUC，顾名思义，是 ROC 曲线下的空间面积。直观上，这个值越接近 1，我们的分类模型就越好。虚线的 AUC 是 0.5。完美模型的 AUC 应该是 1。我们的 AUC 为 0.82，相当不错。</p><p id="2726" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated"><strong class="lt iu">如果您觉得这很有帮助，请订阅。</strong></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="9b53" class="pw-post-body-paragraph lr ls it lt b lu mz ju lw lx na jx lz ma nb mc md me nc mg mh mi nd mk ml mm im bi translated">我的其他文章，如果你想了解更多:</p><h2 id="5c8d" class="og la it bd lb oo op dn lf oq or dp lj ma os ot ll me ou ov ln mi ow ox lp oy bi translated">点击了解多项式回归<a class="ae ky" rel="noopener" target="_blank" href="/linear-vs-polynomial-regression-walk-through-83ca4f2363a3"/></h2><h2 id="34f4" class="og la it bd lb oo op dn lf oq or dp lj ma os ot ll me ou ov ln mi ow ox lp oy bi translated">点击了解有关 rsquared <a class="ae ky" rel="noopener" target="_blank" href="/r-squared-recipe-5814995fa39a">的信息:</a></h2></div></div>    
</body>
</html>