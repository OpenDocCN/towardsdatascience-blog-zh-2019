<html>
<head>
<title>A brief intro to the Central Limit Theorem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">中心极限定理简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-brief-intro-to-the-central-limit-theorem-ccbd2b661b32?source=collection_archive---------26-----------------------#2019-11-09">https://towardsdatascience.com/a-brief-intro-to-the-central-limit-theorem-ccbd2b661b32?source=collection_archive---------26-----------------------#2019-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e53c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">他们说你不可能成为一名数据科学家，如果你不知道…</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f948075c58a91e727603bb31592aa926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1rpwV1qd3RPmUyfiTTXPQ.png"/></div></div></figure><p id="330a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">根据<a class="ae ln" href="https://en.wikipedia.org/wiki/Central_limit_theorem" rel="noopener ugc nofollow" target="_blank">维基百科</a>。</p><blockquote class="lo lp lq"><p id="dd3b" class="kr ks lr kt b ku kv jr kw kx ky ju kz ls lb lc ld lt lf lg lh lu lj lk ll lm ij bi translated">在<a class="ae ln" href="https://en.wikipedia.org/wiki/Probability_theory" rel="noopener ugc nofollow" target="_blank">概率论</a>中，<strong class="kt ir">中心极限定理</strong> ( <strong class="kt ir"> CLT </strong>)确立了，在某些情况下，当<a class="ae ln" href="https://en.wikipedia.org/wiki/Statistical_independence" rel="noopener ugc nofollow" target="_blank">个独立随机变量</a>相加时，它们的正常归一化和趋向于一个<a class="ae ln" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">正态分布</a>(非正式的一个“<em class="iq">钟形曲线</em>”)，即使原始变量本身不是正态分布。</p></blockquote><p id="3460" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">翻译:</strong>如果从总体中抽取足够多的样本，这些样本的均值将接近正态分布。</p><p id="f171" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">酷的是，这适用于(几乎)任何分布的人群。让我们举一些例子来证明这一点。</p><h1 id="340e" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">生成随机数据</h1><p id="2ceb" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">生成 300 个 0 到 50 之间的随机数。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="9f00" class="mx lw iq mt b gy my mz l na nb">import matplotlib.pyplot as plt<br/>import random</span><span id="c672" class="mx lw iq mt b gy nc mz l na nb">X = []</span><span id="b26d" class="mx lw iq mt b gy nc mz l na nb">for i in range(0,300):<br/>    v = random.randint(0,50)<br/>    X.append(v)</span></pre><p id="6402" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">画出来，这样我们就能看到数据的形状。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="5185" class="mx lw iq mt b gy my mz l na nb">plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})<br/>plt.hist(X, bins = 50)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/8c44cf64177bdffeb164f153898cfc5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KtPWtWgSYuJ9fQLazy4igQ.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Definitely not a normal distribution</figcaption></figure><h1 id="b082" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">取样并计算平均值</h1><p id="ab9d" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">现在取 10，000 个样本，样本大小为 5，计算每个样本的平均值，并绘制平均值的频率。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="48bd" class="mx lw iq mt b gy my mz l na nb">import numpy as np</span><span id="ae66" class="mx lw iq mt b gy nc mz l na nb">means = []</span><span id="9a50" class="mx lw iq mt b gy nc mz l na nb">for i in range(0,10000):<br/>    sample = []<br/>    <br/>    for ii in range(0,5):<br/>        v = random.choice(X)<br/>        sample.append(v)<br/>        <br/>    mean = np.mean(sample)<br/>    means.append(mean)</span></pre><h1 id="6981" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">绘制分布图</h1><p id="0877" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">画出每个样本平均值的频率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/84fb9edd4f99f635a3aec162890d50f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KaxVmBFxKAQrsK3tm_MXA.png"/></div></div></figure><p id="acdb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">看起来有点像正态分布。很酷吧。</p><p id="22ee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们把样本量从 5 个增加到 30 个。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f948075c58a91e727603bb31592aa926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1rpwV1qd3RPmUyfiTTXPQ.png"/></div></div></figure><p id="d0ff" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">更像是正态分布。</p><p id="43ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">尽管原始人口根本不遵循正态分布，这种情况还是发生了。</p><p id="f780" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我生成的数据是随机的。但是几乎任何分布，连续的或离散的，贝塔的，伽马的或均匀的，都能达到完全相同的效果。</p><h1 id="af5c" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">为什么这很重要</h1><p id="0ded" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">如果足够多样本的平均值接近正态分布，我们可以“假装”样本本身的分布也是正态的。在给定一个样本的情况下，对整体人口做出推断时会感觉更舒服。</p><p id="14c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以上是我的理解，但我不是统计学家。所以我想向大众展示一下。为什么中心极限定理对统计学和机器学习如此重要？</p></div></div>    
</body>
</html>