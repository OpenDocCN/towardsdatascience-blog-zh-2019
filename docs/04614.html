<html>
<head>
<title>Building Neural Network Using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ç”¨ PyTorch æ„å»ºç¥ç»ç½‘ç»œ</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/building-neural-network-using-pytorch-84f6e75f9a?source=collection_archive---------2-----------------------#2019-07-15">https://towardsdatascience.com/building-neural-network-using-pytorch-84f6e75f9a?source=collection_archive---------2-----------------------#2019-07-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="4542" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">â€œè®¡ç®—æœºèƒ½å¦æ€è€ƒçš„é—®é¢˜å¹¶ä¸æ¯”æ½œè‰‡èƒ½å¦æ¸¸æ³³çš„é—®é¢˜æ›´æœ‰è¶£ã€‚â€<br/> â€• <strong class="js iu">åŸƒå¾·æ ¼Â·wÂ·è¿ªæ°æ–¯ç‰¹æ‹‰</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/566411b1e847aa9e6766e37b2f055cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFwNcoyJtLbXoJGQ8kRm_A.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">source: <a class="ae le" href="https://deeplizard.com/learn/video/k4jY9L8H89U" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="0392" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ PyTorch ä»å¤´å¼€å§‹å®ç°ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚æˆ‘æ­£åœ¨åˆ†äº«æˆ‘ä»æœ€è¿‘çš„ facebook-udacity å¥–å­¦é‡‘æŒ‘æˆ˜é¡¹ç›®ä¸­å­¦åˆ°çš„ä¸œè¥¿ã€‚æœ¬æ•™ç¨‹å‡è®¾ä½ äº‹å…ˆäº†è§£ç¥ç»ç½‘ç»œå¦‚ä½•å·¥ä½œã€‚</p><p id="df48" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">è™½ç„¶æœ‰å¾ˆå¤šåº“å¯ä»¥ç”¨äºæ·±åº¦å­¦ä¹ ï¼Œä½†æˆ‘æœ€å–œæ¬¢ PyTorchã€‚ä½œä¸ºä¸€å python ç¨‹åºå‘˜ï¼Œæˆ‘å–œæ¬¢ PyTorch çš„ python è¡Œä¸ºæ˜¯èƒŒåçš„åŸå› ä¹‹ä¸€ã€‚å®ƒä¸»è¦ä½¿ç”¨ python çš„é£æ ¼å’ŒåŠŸèƒ½ï¼Œæ˜“äºç†è§£å’Œä½¿ç”¨ã€‚</p><p id="4109" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">py torch çš„æ ¸å¿ƒæä¾›äº†ä¸¤ä¸ªä¸»è¦ç‰¹æ€§:</strong></p><ul class=""><li id="d7c5" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">n ç»´å¼ é‡ï¼Œç±»ä¼¼äº numpyï¼Œä½†å¯ä»¥åœ¨ GPU ä¸Šè¿è¡Œ</li><li id="cad1" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">ç”¨äºå»ºç«‹å’Œè®­ç»ƒç¥ç»ç½‘ç»œçš„è‡ªåŠ¨å¾®åˆ†</li></ul></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><p id="f3bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ</strong></p><p id="5752" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ç¥ç»ç½‘ç»œæ˜¯ä¸€ç»„ç®—æ³•ï¼Œå¤§è‡´æ¨¡ä»¿äººè„‘ï¼Œç”¨äºè¯†åˆ«æ¨¡å¼ã€‚ç½‘ç»œæ˜¯ç”±è¿‘ä¼¼ç¥ç»å…ƒçš„å•ä¸ªéƒ¨åˆ†æ„æˆçš„ï¼Œé€šå¸¸ç§°ä¸ºå•å…ƒæˆ–ç®€ç§°ä¸ºâ€œ<strong class="js iu">ç¥ç»å…ƒ</strong>â€æ¯ä¸ªå•å…ƒéƒ½æœ‰ä¸€äº›åŠ æƒè¾“å…¥ã€‚è¿™äº›åŠ æƒè¾“å…¥ç›¸åŠ åœ¨ä¸€èµ·(çº¿æ€§ç»„åˆ)ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªæ¿€æ´»å‡½æ•°å¾—åˆ°å•å…ƒçš„è¾“å‡ºã€‚</p><h2 id="eb39" class="ma mb it bd mc md me dn mf mg mh dp mi kb mj mk ml kf mm mn mo kj mp mq mr ms bi translated">ç¥ç»ç½‘ç»œä¸­çš„èŠ‚ç‚¹ç±»å‹:</h2><ol class=""><li id="033c" class="lf lg it js b jt mt jx mu kb mv kf mw kj mx kn my ll lm ln bi translated">è¾“å…¥å•å…ƒâ€”å‘ç½‘ç»œæä¾›æ¥è‡ªå¤–éƒ¨ä¸–ç•Œçš„ä¿¡æ¯ï¼Œç»Ÿç§°ä¸ºâ€œè¾“å…¥å±‚â€ã€‚è¿™äº›èŠ‚ç‚¹ä¸æ‰§è¡Œä»»ä½•è®¡ç®—ï¼Œå®ƒä»¬åªæ˜¯å°†ä¿¡æ¯ä¼ é€’ç»™éšè—èŠ‚ç‚¹ã€‚</li><li id="90f9" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn my ll lm ln bi translated">éšè—å•å…ƒâ€”è¿™äº›èŠ‚ç‚¹ä¸å¤–ç•Œæ²¡æœ‰ä»»ä½•ç›´æ¥çš„è”ç³»ã€‚å®ƒä»¬æ‰§è¡Œè®¡ç®—å¹¶å°†ä¿¡æ¯ä»è¾“å…¥èŠ‚ç‚¹ä¼ è¾“åˆ°è¾“å‡ºèŠ‚ç‚¹ã€‚éšè—èŠ‚ç‚¹çš„é›†åˆå½¢æˆäº†â€œéšè—å±‚â€ã€‚è™½ç„¶å‰é¦ˆç½‘ç»œåªæœ‰ä¸€ä¸ªè¾“å…¥å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼Œä½†å®ƒå¯ä»¥æœ‰é›¶ä¸ªæˆ–å¤šä¸ªéšè—å±‚ã€‚</li><li id="f574" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn my ll lm ln bi translated">è¾“å‡ºå•å…ƒ-è¾“å‡ºèŠ‚ç‚¹ç»Ÿç§°ä¸ºâ€œè¾“å‡ºå±‚â€ï¼Œè´Ÿè´£è®¡ç®—å’Œå°†ä¿¡æ¯ä»ç½‘ç»œä¼ è¾“åˆ°å¤–éƒ¨ä¸–ç•Œã€‚</li></ol><p id="2cf8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æ¯å±‚åŒ…æ‹¬ä¸€ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹ã€‚</p></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><p id="4230" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">æ„å»ºç¥ç»ç½‘ç»œ</strong></p><p id="5f72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">PyTorch æä¾›äº†ä¸€ä¸ªæ¨¡å—<code class="fe mz na nb nc b">nn</code>,ä½¿å¾—æ„å»ºç½‘ç»œæ›´åŠ ç®€å•ã€‚æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ç”¨<code class="fe mz na nb nc b">784 inputs</code>ã€<code class="fe mz na nb nc b">256 hidden units</code>ã€<code class="fe mz na nb nc b">10 output units</code>å’Œ<code class="fe mz na nb nc b">softmax output</code>æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="802f" class="ma mb it nc b gy nh ni l nj nk">from torch import nn</span><span id="20ae" class="ma mb it nc b gy nl ni l nj nk">class Network(nn.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>        <br/>        # Inputs to hidden layer linear transformation<br/>        self.hidden = nn.Linear(784, 256)<br/>        # Output layer, 10 units - one for each digit<br/>        self.output = nn.Linear(256, 10)<br/>        <br/>        # Define sigmoid activation and softmax output <br/>        self.sigmoid = nn.Sigmoid()<br/>        self.softmax = nn.Softmax(dim=1)<br/>        <br/>    def forward(self, x):<br/>        # Pass the input tensor through each of our operations<br/>        x = self.hidden(x)<br/>        x = self.sigmoid(x)<br/>        x = self.output(x)<br/>        x = self.softmax(x)<br/>        <br/>        return x</span></pre><blockquote class="nm nn no"><p id="f4f0" class="jq jr np js b jt ju jv jw jx jy jz ka nq kc kd ke nr kg kh ki ns kk kl km kn im bi translated">æ³¨:<code class="fe mz na nb nc b"><strong class="js iu">softmax</strong></code> <strong class="js iu">å‡½æ•°ï¼Œ</strong>ä¹Ÿç§°ä¸º<code class="fe mz na nb nc b"><strong class="js iu">softargmax</strong></code>æˆ–<code class="fe mz na nb nc b"><strong class="js iu">normalized</strong></code> <strong class="js iu"> </strong> <code class="fe mz na nb nc b"><strong class="js iu">exponential function</strong></code>æ˜¯ä¸€ä¸ªä»¥<em class="it"> K </em>å®æ•°çš„å‘é‡ä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶å½’ä¸€åŒ–ä¸ºç”±<em class="it"> K </em>ä¸ªæ¦‚ç‡ç»„æˆçš„<a class="ae le" href="https://en.wikipedia.org/wiki/Probability_distribution" rel="noopener ugc nofollow" target="_blank">æ¦‚ç‡åˆ†å¸ƒ</a>çš„å‡½æ•°ã€‚</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/04cd3c8c6424a8cb8cf065a0c5a5812c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWhBextdDSkxYvz0kEMTVg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">image from google</figcaption></figure><p id="26e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">è®©æˆ‘ä»¬ä¸€è¡Œä¸€è¡Œåœ°è¿‡ä¸€éã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="b781" class="ma mb it nc b gy nh ni l nj nk"><strong class="nc iu">class</strong> Network(nn.Module):</span></pre><p id="0c2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç»§æ‰¿äº†<code class="fe mz na nb nc b">nn.Module</code>ã€‚ä¸<code class="fe mz na nb nc b">super().__init__()</code>ç»“åˆï¼Œè¿™åˆ›å»ºäº†ä¸€ä¸ªè·Ÿè¸ªæ¶æ„çš„ç±»ï¼Œå¹¶æä¾›äº†è®¸å¤šæœ‰ç”¨çš„æ–¹æ³•å’Œå±æ€§ã€‚å½“ä½ ä¸ºä½ çš„ç½‘ç»œåˆ›å»ºä¸€ä¸ªç±»æ—¶ï¼Œä»<code class="fe mz na nb nc b">nn.Module</code>ç»§æ‰¿æ˜¯å¼ºåˆ¶æ€§çš„ã€‚ç±»æœ¬èº«çš„åç§°å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿ã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="7d75" class="ma mb it nc b gy nh ni l nj nk">self.hidden <strong class="nc iu">=</strong> nn.Linear(784, 256)</span></pre><p id="9311" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">è¿™ä¸€è¡Œåˆ›å»ºäº†ä¸€ä¸ªç”¨äºçº¿æ€§å˜æ¢çš„æ¨¡å—ï¼Œğ‘¥ğ–+ğ‘xW+bï¼Œæœ‰ 784 ä¸ªè¾“å…¥å’Œ 256 ä¸ªè¾“å‡ºï¼Œå¹¶å°†å…¶åˆ†é…ç»™<code class="fe mz na nb nc b">self.hidden</code>ã€‚è¯¥æ¨¡å—è‡ªåŠ¨åˆ›å»ºæˆ‘ä»¬å°†åœ¨<code class="fe mz na nb nc b">forward</code>æ–¹æ³•ä¸­ä½¿ç”¨çš„æƒé‡å’Œåå·®å¼ é‡ã€‚ä¸€æ—¦ä½¿ç”¨<code class="fe mz na nb nc b">net.hidden.weight</code>å’Œ<code class="fe mz na nb nc b">net.hidden.bias</code>åˆ›å»ºäº†ç½‘ç»œ(<code class="fe mz na nb nc b">net</code>ï¼Œæ‚¨å°±å¯ä»¥è®¿é—®æƒé‡å’Œåå·®å¼ é‡ã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="699f" class="ma mb it nc b gy nh ni l nj nk">self.output <strong class="nc iu">=</strong> nn.Linear(256, 10)</span></pre><p id="654f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ç±»ä¼¼åœ°ï¼Œè¿™åˆ›å»ºäº†å¦ä¸€ä¸ªå…·æœ‰ 256 ä¸ªè¾“å…¥å’Œ 10 ä¸ªè¾“å‡ºçš„çº¿æ€§è½¬æ¢ã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="e6cb" class="ma mb it nc b gy nh ni l nj nk">self.sigmoid <strong class="nc iu">=</strong> nn.Sigmoid()<br/>self.softmax <strong class="nc iu">=</strong> nn.Softmax(dim<strong class="nc iu">=</strong>1)</span></pre><p id="efaf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">è¿™é‡Œæˆ‘å®šä¹‰äº† sigmoid æ¿€æ´»å’Œ softmax è¾“å‡ºçš„æ“ä½œã€‚åœ¨<code class="fe mz na nb nc b">nn.Softmax(dim=1)</code>ä¸­è®¾ç½®<code class="fe mz na nb nc b">dim=1</code>è®¡ç®—å„åˆ—çš„ softmaxã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="43c3" class="ma mb it nc b gy nh ni l nj nk"><strong class="nc iu">def</strong> forward(self, x):</span></pre><p id="f28f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ç”¨<code class="fe mz na nb nc b">nn.Module</code>åˆ›å»ºçš„ PyTorch ç½‘ç»œå¿…é¡»å®šä¹‰ä¸€ä¸ª<code class="fe mz na nb nc b">forward</code>æ–¹æ³•ã€‚å®ƒæ¥å—ä¸€ä¸ªå¼ é‡<code class="fe mz na nb nc b">x</code>å¹¶é€šè¿‡æ‚¨åœ¨<code class="fe mz na nb nc b">__init__</code>æ–¹æ³•ä¸­å®šä¹‰çš„æ“ä½œä¼ é€’å®ƒã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="0bcd" class="ma mb it nc b gy nh ni l nj nk">x <strong class="nc iu">=</strong> self.hidden(x)<br/>x <strong class="nc iu">=</strong> self.sigmoid(x)<br/>x <strong class="nc iu">=</strong> self.output(x)<br/>x <strong class="nc iu">=</strong> self.softmax(x)</span></pre><p id="dc0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">è¿™é‡Œï¼Œè¾“å…¥å¼ é‡<code class="fe mz na nb nc b">x</code>é€šè¿‡æ¯ä¸ªæ“ä½œï¼Œå¹¶é‡æ–°åˆ†é…ç»™<code class="fe mz na nb nc b">x</code>ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¾“å…¥å¼ é‡ç»è¿‡éšè—å±‚ï¼Œç„¶åæ˜¯ sigmoid å‡½æ•°ï¼Œç„¶åæ˜¯è¾“å‡ºå±‚ï¼Œæœ€åæ˜¯ softmax å‡½æ•°ã€‚åªè¦æ“ä½œçš„è¾“å…¥å’Œè¾“å‡ºä¸æ‚¨æƒ³è¦æ„å»ºçš„ç½‘ç»œä½“ç³»ç»“æ„ç›¸åŒ¹é…ï¼Œæ‚¨åœ¨è¿™é‡Œç»™å˜é‡å–ä»€ä¹ˆåå­—å¹¶ä¸é‡è¦ã€‚åœ¨<code class="fe mz na nb nc b">__init__</code>æ–¹æ³•ä¸­å®šä¹‰äº‹ç‰©çš„é¡ºåºå¹¶ä¸é‡è¦ï¼Œä½†æ˜¯æ‚¨éœ€è¦åœ¨<code class="fe mz na nb nc b">forward</code>æ–¹æ³•ä¸­å¯¹æ“ä½œè¿›è¡Œæ­£ç¡®æ’åºã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="09b8" class="ma mb it nc b gy nh ni l nj nk"># Create the network and look at it's text representation<br/>model = Network()<br/>model</span></pre></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><p id="8b3e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">ä½¿ç”¨</strong>æ„å»ºç¥ç»ç½‘ç»œ<code class="fe mz na nb nc b"><strong class="js iu">nn.Sequential</strong></code></p><p id="75cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">PyTorch æä¾›äº†ä¸€ç§æ–¹ä¾¿çš„æ–¹æ³•æ¥æ„å»ºè¿™æ ·çš„ç½‘ç»œï¼Œå…¶ä¸­å¼ é‡é€šè¿‡è¿ç®—é¡ºåºä¼ é€’ï¼Œ<code class="fe mz na nb nc b">nn.Sequential</code> ( <a class="ae le" href="https://pytorch.org/docs/master/nn.html#torch.nn.Sequential" rel="noopener ugc nofollow" target="_blank">æ–‡æ¡£</a>)ã€‚ç”¨å®ƒæ¥æ„å»ºç­‰æ•ˆç½‘ç»œ:</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="bc88" class="ma mb it nc b gy nh ni l nj nk"># Hyperparameters for our network<br/>input_size = 784<br/>hidden_sizes = [128, 64]<br/>output_size = 10</span><span id="e110" class="ma mb it nc b gy nl ni l nj nk"># Build a feed-forward network<br/>model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),<br/>                      nn.ReLU(),<br/>                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),<br/>                      nn.ReLU(),<br/>                      nn.Linear(hidden_sizes[1], output_size),<br/>                      nn.Softmax(dim=1))<br/>print(model)</span></pre><blockquote class="nm nn no"><p id="b375" class="jq jr np js b jt ju jv jw jx jy jz ka nq kc kd ke nr kg kh ki ns kk kl km kn im bi translated">è¿™é‡Œæˆ‘ä»¬çš„å‹å·å’Œä¹‹å‰ä¸€æ ·:<code class="fe mz na nb nc b"> 784 input units</code>ã€<code class="fe mz na nb nc b">a hidden layer with 128 units</code>ã€<code class="fe mz na nb nc b"> ReLU activation</code>ã€<code class="fe mz na nb nc b">64 unit hidden layer</code>ï¼Œå†æ¥ä¸€ä¸ª<code class="fe mz na nb nc b"> ReLU</code>ï¼Œç„¶åæ˜¯<code class="fe mz na nb nc b">output layer with 10 units</code>ï¼Œå†æ¥ä¸€ä¸ª<code class="fe mz na nb nc b">softmax output</code>ã€‚</p></blockquote><p id="5df2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æ‚¨è¿˜å¯ä»¥ä¼ å…¥ä¸€ä¸ª<code class="fe mz na nb nc b">OrderedDict</code>æ¥å‘½åå„ä¸ªå±‚å’Œæ“ä½œï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¢é‡æ•´æ•°ã€‚æ³¨æ„å­—å…¸é”®å¿…é¡»æ˜¯å”¯ä¸€çš„ï¼Œæ‰€ä»¥<em class="np">æ¯ä¸ªæ“ä½œå¿…é¡»æœ‰ä¸åŒçš„åç§°</em>ã€‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="fa10" class="ma mb it nc b gy nh ni l nj nk">from collections import OrderedDict<br/>model = nn.Sequential(OrderedDict([<br/>                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),<br/>                      ('relu1', nn.ReLU()),<br/>                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),<br/>                      ('relu2', nn.ReLU()),<br/>                      ('output', nn.Linear(hidden_sizes[1], output_size)),<br/>                      ('softmax', nn.Softmax(dim=1))]))</span><span id="380d" class="ma mb it nc b gy nl ni l nj nk"><br/>model</span></pre><p id="dc8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ç°åœ¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ•´æ•°æˆ–åç§°æ¥è®¿é—®å›¾å±‚</p><pre class="kp kq kr ks gt nd nc ne nf aw ng bi"><span id="0d82" class="ma mb it nc b gy nh ni l nj nk">print(model[0])<br/>print(model.fc1)</span></pre><p id="45ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ä»Šå¤©åˆ°æ­¤ä¸ºæ­¢ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œã€‚ä½ ä¼šåœ¨è¿™é‡Œæ‰¾åˆ°å®ƒã€‚</p><p id="527c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬éšæ—¶æ¬¢è¿æ‚¨æå‡ºä»»ä½•å»ºè®¾æ€§çš„æ‰¹è¯„æˆ–åé¦ˆã€‚</p></div></div>    
</body>
</html>