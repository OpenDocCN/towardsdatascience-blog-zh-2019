<html>
<head>
<title>Kaggle vs. Colab Faceoff — Which Free GPU Provider is Tops?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ka ggle vs . Colab face off——哪个免费 GPU 提供商是 Tops？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=collection_archive---------4-----------------------#2019-03-20">https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=collection_archive---------4-----------------------#2019-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="22ca" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">规格，UX，以及 fastai 和混合精度训练的深度学习实验</h2></div><p id="86af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谷歌有两款产品可以让你在云中免费使用 GPU:Colab 和 Kaggle。如果你对深度学习和人工智能感兴趣，它们会非常棒。本文的目标是帮助您更好地选择何时使用哪个平台。</p><p id="61de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle 刚刚获得了 Nvida 特斯拉 P100 图形处理器的速度提升。🚀然而，正如我们将在计算机视觉实验中看到的，Colab 的混合精度训练有助于缩小速度差距。* * 2019 年 4 月 25 日更新— Colab 现在有了 Nvidia T4s。对于混合精度来说，它们真的很快。另外，随着硬件的改进，我不打算继续更新这篇文章。😄**</p><p id="a79c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将向您展示如何比较硬件规格和探索 UX 的差异。我们还将把计算机视觉任务的训练时间与迁移学习、混合精度训练、学习速率退火和测试时间增加进行比较。</p><p id="5525" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们开始吧！👍</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/dab96d9e5dfad715485ce006d2f06b94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6JJg-D8I9KIRFjQ5OTZoA.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Twin peaks Colab and Kaggle, side by side in the Google range</figcaption></figure><p id="bbf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle 和 Colab 是相当相似的产品。卡格尔和科拉布</p><ul class=""><li id="a9ec" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated">提供免费的 GPU</li><li id="5b19" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">在浏览器中提供 Jupyter 笔记本——尽管有他们自己独特的风格</li><li id="b253" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">旨在促进机器学习的合作。</li><li id="9981" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">是谷歌的产品</li><li id="5832" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">并不完美，但在许多情况下非常有用——尤其是当你开始深度学习的时候。😄</li><li id="99ae" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">不要提供关于他们硬件规格的大量信息</li></ul><p id="9aaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后一点我们一会儿会深入探讨。不幸的是，当你使用他们的环境时，Kaggle 和 Colab 都不会告诉你确切的规格。确实存在的文件往往已经过时(见<a class="ae mi" href="https://www.kaggle.com/docs/kernels#technical-specifications" rel="noopener ugc nofollow" target="_blank">此处</a>截至 2019 年 3 月 11 日)。此外，屏幕上的小部件讲述了一些故事，但与我发掘的不同。我将向您展示常见的 profiler 命令，您可以使用这些命令来查看您的环境规格。</p><p id="b27a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，简单介绍一下 GPU 的背景——如果这是老一套的话👒对你来说，请随意跳过前面。</p><h1 id="de30" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是 GPU？</h1><p id="4f87" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">GPU 是<a class="ae mi" href="https://en.wikipedia.org/wiki/Graphics_processing_unit" rel="noopener ugc nofollow" target="_blank">图形处理单元</a>的简称。GPU 是专门的芯片，最初是为了加速视频游戏的图形而开发的。他们快速地做许多矩阵计算。对于深度学习应用来说，这是一个非常方便的特性。有趣的事实:出于同样的原因，GPU 也是加密货币挖掘的首选工具。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/43c6a1f96b2f5bc17f15ddab03eb5795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/0*xEiTGz7qZ5yd-xYA.jpg"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Nvidia P100 GPU</figcaption></figure><h1 id="e411" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">为什么要用 GPU？</h1><p id="5bfe" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">使用具有足够内存的 GPU 使训练深度学习网络的速度比单独使用 CPU 快很多倍。因为在几分钟或几小时内而不是几天或几周内获得反馈要好得多，所以如果你对深度学习感兴趣，你会想要使用 GPU。毫无疑问。😃</p><h1 id="59cc" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">规范</h1><p id="e60c" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">截至 2019 年 3 月初，Kaggle 已经将其 GPU 芯片从<a class="ae mi" href="https://www.nvidia.com/en-gb/data-center/tesla-k80/" rel="noopener ugc nofollow" target="_blank"> Nvidia Tesla K80 </a>升级为<a class="ae mi" href="https://www.nvidia.com/en-us/data-center/tesla-p100/" rel="noopener ugc nofollow" target="_blank"> Nvidia Telsa P100 </a>。Colab 还是给你一个 K80。关于 Nvida 芯片类型的简要讨论，请参见我的文章比较云 GPU 提供商<a class="ae mi" rel="noopener" target="_blank" href="/maximize-your-gpu-dollars-a9133f4e546a">这里</a>。</p><p id="b09c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有很多不同的方法可以找到你的硬件信息。两个有用的命令是用于 GPU 信息的<code class="fe nh ni nj nk b">!nvidia-smi</code>和用于 CPU 信息的<code class="fe nh ni nj nk b">!cat /proc/cpuinfo</code>。即使你想用 GPU 训练你的模型，你也仍然需要一个 CPU 来进行深度学习。</p><p id="4d5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每当您在 Jupyter 笔记本代码行的开头使用感叹号时，您都在运行一个 bash 命令。<a class="ae mi" href="https://medium.com/me/stats/post/52c4b2ea34b7" rel="noopener">这是我写的关于<em class="nl"> bash </em>命令</a>的文章，包括<code class="fe nh ni nj nk b">cat</code>，如果你想知道更多关于它们的信息。</p><p id="be41" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请看<a class="ae mi" href="https://docs.google.com/spreadsheets/d/1YBNlI9QxQTiPBOhsSyNg6EOO9LH2M3zF7ar88SeFQRk/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">这张谷歌表</a>中我在下面的快照中编辑的规格。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nm"><img src="../Images/31d164ed46817fa8b77b145bcab1866b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6USMWs7h7fTP0a3GA9SIug.png"/></div></div></figure><p id="ae03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">内存和磁盘空间很难衡量。一旦 Colab 和 Kaggle 安装了他们的软件并启动了他们的程序，总数就无法得到了。下面是对<code class="fe nh ni nj nk b">!cat /proc/meminfo</code> profiler 命令与 Colab 和 Kaggle 小部件之间内存差异的分析。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/2bee0682c2b06143415df3281906deb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*rn_INfrvNGprLjk1KELBoA.png"/></div></figure><p id="cea0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nl"> Total </em>是总内存。<em class="nl">可用</em>是在没有额外运行进程的情况下启动后观察到的可用内存量。您可以看到，分析的数量很接近，但是与 Colab 和 Kaggle 小部件中显示的数量不完全一致。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi no"><img src="../Images/77f33a2202358385c3a0f8d53b986bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*_1O8pb1wpjZVDOQ2I1jm5Q.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Mouseover in Colab</figcaption></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/8b79e67d2133b3aae0f47bdcc92a80f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*W_D4fKR7LOmDztKylXahAw.png"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Kaggle Sidebar</figcaption></figure><p id="345b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有一个<a class="ae mi" href="https://www.kaggle.com/discdiver/profiling-your-gpu-runtime" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>，这里有一个<a class="ae mi" href="https://colab.research.google.com/drive/1LcfjGimVz1EHB9EAS7y-9f6UyLemdE16" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>，上面有命令，所以你可以在你自己的环境中查看规格。确保首先启用 GPU 运行时，如本文末尾所示。</p><p id="0244" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，来自命令分析器的 GPU 规格将以兆字节为单位返回，这与兆字节几乎相同，但不完全相同。兆字节可以通过谷歌搜索转换成兆字节——只需输入标记的数量进行转换。谷歌无处不在——不是吗？😄</p><p id="8ac8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle 小部件显示的磁盘空间也比我们看到的报告少得多。Kaggle 可以限制您在当前工作环境中可以使用的磁盘空间，而不管理论上有多少可用空间。</p><p id="63ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle 在他们的<a class="ae mi" href="https://www.kaggle.com/docs/kernels#technical-specifications" rel="noopener ugc nofollow" target="_blank">文档</a>中声明你有 9 个小时的执行时间。然而，内核环境在屏幕右侧的小部件中显示每个会话最多 6 小时。注意，重启内核会重启时钟。Kaggle 还会在 60 分钟不活动后重新启动您的会话。</p><p id="c7d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Colab 给你 12 小时的执行时间，但是如果你空闲超过 90 分钟，它也会把你踢出去。</p><p id="4b3b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看最重要的问题:在这些平台上进行一些深度学习需要多长时间！</p><h1 id="84d0" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">计算机视觉速度比较</h1><p id="b18b" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我在一个深度学习图像分类任务上对比了 Kaggle 和 Colab。目标是预测一张图片是猫还是狗。该数据集由 25，000 张图片组成，猫和狗的数量相等。该数据集被分成 23，000 个用于训练的图像和 2，000 个用于验证的图像。数据集可以在 Kaggle <a class="ae mi" href="https://www.kaggle.com/lingjin525/dogs-and-cats-fastai" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nq"><img src="../Images/f40e65ae07780215cf5194ba3f3dc763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SLKWlyjy_E9UHsW6NSr7A.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Cat and dog images from the dataset</figcaption></figure><p id="7d74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用 FastAI 库构建了一个卷积神经网络，并使用 ResNet30 的迁移学习对其进行了训练。该模型使用了几个技巧进行训练，包括数据扩充和学习速率退火。对测试集的预测是通过增加测试时间来实现的。代码改编自<a class="ae mi" href="https://github.com/fastai/fastai/blob/master/examples/dogs_cats.ipynb" rel="noopener ugc nofollow" target="_blank">这个 FastAI 的例子</a>。</p><p id="5b04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle 内核可以在这里<a class="ae mi" href="https://www.kaggle.com/discdiver/cloud-provider-comparison-mar-2019?scriptVersionId=11552126" rel="noopener ugc nofollow" target="_blank">访问</a>，Colab 笔记本可以在这里<a class="ae mi" href="https://colab.research.google.com/drive/1a06S46-APxNXhI3USnSYYkAR9H4VcZzE" rel="noopener ugc nofollow" target="_blank">访问</a>。批量大小设置为 16，FastAI 版本为 1.0.48。对 FastAI 的内置分析器报告的几个训练阶段和一个预测阶段的时间进行求和。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d522f58b45195519e7d1042b3c179c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*904mHiJzWt0Az372tCBdxw.gif"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Note that the y-axis does not start at 0.</figcaption></figure><p id="78d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在所有情况下，验证集的准确性都超过 99%。三次迭代的平均时间在 Kaggle 上是 11:17，在 Colab 上是 19:54。Kaggle 运行时环境比 Colab 环境快 40%。</p><h2 id="8b46" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">批量</h2><p id="7085" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">为了在 Kaggle 中成功运行图像分类，我不得不将批量大小从 64 个图像减少到 16 个。较大批量的错误似乎是由 Docker 容器中的共享内存设置得太低引起的。有趣的是，我在 2018 年末向谷歌 Colab 提出了这个确切的<a class="ae mi" href="https://github.com/googlecolab/colabtools/issues/329" rel="noopener ugc nofollow" target="_blank">问题——他们在一周内就解决了这个问题。截至 2019 年 3 月中旬，Kaggle </a>的同一<a class="ae mi" href="https://github.com/Kaggle/docker-python/issues/377" rel="noopener ugc nofollow" target="_blank">问题仍未解决。</a></p><p id="3531" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我用上面在 Colab 上使用的相同代码运行了两次迭代，但是将批处理大小改为 256。这一变化导致平均运行时间为 18:38。Colab 中批处理大小为 64 的两个额外迭代导致平均时间为 18:14。因此，Colab 降低了批量大于 16 的时间。</p><p id="ddff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管如此，较小的批量在这个任务中并不是一个大问题。各种各样的批量参数通常都很有效——关于讨论，请参见<a class="ae mi" href="https://arxiv.org/abs/1804.07612" rel="noopener ugc nofollow" target="_blank">这篇论文</a>、<a class="ae mi" href="https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>和<a class="ae mi" href="https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network" rel="noopener ugc nofollow" target="_blank">这篇 SO 回答</a>。</p><p id="0250" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我在批量大小为 256 的 Colab 上训练模型时，出现了一个警告，说我正在使用我的 11.17 GB GPU RAM 的大部分。见下文。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oe"><img src="../Images/eea8e0fbc1e5312a5ccd9a9e3976f773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3DGxyCIhk5p8juON6eYarg.png"/></div></div></figure><p id="934e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个警告很好，但是由于上面讨论的分析练习，我了解了 Gibibytes 和 Gigabytes 之间的区别。我们之前看到 Colab GPUs 拥有 11.17 千兆字节(12 千兆字节)的 RAM。因此，与警告所说的相反，我们实际上有 12gb 的 RAM 可以使用。尽管如此，如果内存不足，那就是内存不足。😃因此，对于这些图像大小、默认的工作线程数和 32 位精度数，看起来批处理大小 256 是最大值。</p><h2 id="a4c5" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">混合精确训练</h2><p id="8091" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">然后，我尝试了混合精度训练，以减少训练时间。混合精度训练意味着在计算中尽可能使用 16 位精度数，而不是 32 位精度数。Nvidia <a class="ae mi" href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/" rel="noopener ugc nofollow" target="_blank">声称</a>使用 16 位精度可以产生两倍于 P100 的吞吐量。</p><p id="d583" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">点击了解混合精度 FastAI 模块<a class="ae mi" href="https://docs.fast.ai/callbacks.fp16.html" rel="noopener ugc nofollow" target="_blank">。请注意，在使用测试时间增强进行预测之前，您需要将 FastAI 学习者对象切换到 32 位模式，因为<em class="nl"> torch.stack </em>还不支持半精度。</a></p><p id="1a7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过在 Colab 上使用混合精度训练，我能够在批量为 16 的情况下实现 16:37 的平均完成时间。我测试了两次。所以我们在减少时间。</p><p id="b5ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，混合精度训练将 Kaggle 上的总时间增加了一分半钟，达到 12:47！其他规格没有变化。所有地方的验证集准确率都保持在 99%以上。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/cb33314137a6b29c814360c62ace7437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/1*fMLFfEJ9NWr5JIYBCFtjFg.gif"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Note that the y-axis does not start at 0.</figcaption></figure><p id="2b0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我发现 Kaggle 的默认包包括稍微老一点的 torch 和 torchvision 版本。将软件包更新到 Colab 使用的最新版本对培训时间没有影响。总的来说，我注意到 Colab 上的默认包比 Kaggle 上的更新更快。</p><p id="74f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面提到的硬件差异似乎不太可能导致 Kaggle 上观察到的性能下降。观察到的唯一软件差异是 Kaggle 运行 CUDA 9.2.148 和 cuDNN 7.4.1，而 Colab 运行 CUDA 10.0.130 和 cuDNN 7.5.0。</p><p id="efda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CUDA 是 Nvidia 的 API，可以直接访问 GPU 的虚拟指令集。cuDNN 是 Nvidia 基于 CUDA 构建的深度学习原语库。据英伟达的<a class="ae mi" href="https://devblogs.nvidia.com/mixed-precision-programming-cuda-8/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>称，Kaggle 的软件应该能提升 P100 的速度。然而，正如在<a class="ae mi" href="https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_750.html#rel_750" rel="noopener ugc nofollow" target="_blank"> cuDNN 更改注释</a>中看到的，阻止加速的 bug 会定期被发现并修复。</p><p id="fbb0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还得等 Kaggle 升级 CUDA 和 cuDNN，看看混合精度训练是不是变快了。目前，如果使用 Kaggle，我仍然鼓励你尝试混合精确训练，但它可能不会给你带来速度提升。如果使用 Colab，混合精度训练应该与批量相对较小的 CNN 一起工作。</p><p id="42ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看使用 Colab 和 Kaggle 的其他方面。</p><h1 id="b9f4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">UX</h1><p id="b923" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">谷歌是一家希望你为你的 GPU 付费的企业，所以不应该指望它免费赠送农场。🐖</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/54c72429aa3b4ef38ab72205641da8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*YcTu4dYzxCaWANDWmPTMpw.png"/></div></figure><p id="39b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Colab 和 Kaggle 有令人沮丧和缓慢的方面。例如，两个运行时断开连接的频率比我们希望的要高。然后，您需要在重启时重新运行您的笔记本。😦</p><p id="eaee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在过去，甚至不能保证你会得到一个 GPU 运行时。看起来他们现在总是有空。如果您发现没有，请在 Twitter @discdiver 上告诉我。</p><p id="8e73" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看科 lab 和 Kaggle 的优缺点。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/096f7dd73583ae00d78fbdd3581cf224.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/format:webp/1*GXMQ_1kpE3XZoJGvr5VydQ.png"/></div></figure><h1 id="2b16" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">科拉布</h1><h2 id="aa32" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">赞成的意见</h2><ul class=""><li id="f809" class="lu lv it kk b kl nb ko nc kr oi kv oj kz ok ld lz ma mb mc bi translated">可以将笔记本保存到 Google Drive。</li><li id="e6fc" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">您可以向笔记本单元格添加注释。</li><li id="4d94" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">与<a class="ae mi" href="https://github.com/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>的良好集成——你可以直接将笔记本保存到 GitHub repos。</li><li id="101b" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">Colab 有免费的 TPU。TPU 类似于 GPU，只是速度更快。TPU 是谷歌自己定制的芯片。不幸的是，TPUs 与 py torch,<a class="ae mi" href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-across-google-cloud" rel="noopener ugc nofollow" target="_blank">还不能顺利工作，尽管</a>计划集成两者。如果实验是用 TensorFlow 而不是 FastAI/PyTorch 编写的，那么使用 TPU 的 Colab 可能会比使用 GPU 的 Kaggle 更快。</li></ul><h2 id="6b14" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">骗局</h2><ul class=""><li id="bb1d" class="lu lv it kk b kl nb ko nc kr oi kv oj kz ok ld lz ma mb mc bi translated">在 Colab 中，一些用户的共享内存限制很低。似乎至少有一个用户的问题已经解决(此处讨论<a class="ae mi" href="https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available" rel="noopener ugc nofollow" target="_blank">为</a>)。</li><li id="a66c" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">使用 Google Drive 有点痛苦。您必须验证每个会话。此外，你不能很容易地解压驱动器中的文件。</li><li id="bb99" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">键盘快捷键和普通的 Jupyter 笔记本有不同的绑定。如果你想知道这种情况是否会改变，下面是 GitHub 的第<a class="ae mi" href="https://github.com/googlecolab/colabtools/issues/75" rel="noopener ugc nofollow" target="_blank">期</a>。</li></ul><p id="4d97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们来看看 Kaggle 的利弊。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/6162e860d8ea5c81c7bb0851da9228c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*lt3sh1GvhkvYZwoqbfg_4w.png"/></div></figure><h1 id="f0e5" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">卡格尔</h1><h2 id="4af9" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">赞成的意见</h2><ul class=""><li id="7ca9" class="lu lv it kk b kl nb ko nc kr oi kv oj kz ok ld lz ma mb mc bi translated">Kaggle 社区非常适合学习和展示你的技能。</li><li id="755f" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">把你的工作交给 Kaggle 会创造一段美好的历史。</li><li id="68c6" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">许多 Jupyter 笔记本的键盘快捷键完全可以转移到 Kaggle 环境中。</li><li id="6157" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">Kaggle 有许多数据集可以导入。</li></ul><h2 id="0138" class="ns mk it bd ml nt nu dn mp nv nw dp mt kr nx ny mv kv nz oa mx kz ob oc mz od bi translated">骗局</h2><ul class=""><li id="9be8" class="lu lv it kk b kl nb ko nc kr oi kv oj kz ok ld lz ma mb mc bi translated">Kaggle 通常会自动保存你的工作，但如果你不提交，然后重新加载你的页面，你可能会发现你失去了一切。这不好玩。😦</li><li id="8903" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">如上所述，Docker 容器中的 PyTorch 共享内存在 Kaggle 中较低。当批量大于 16 张图像时，这导致图像分类任务的<code class="fe nh ni nj nk b">RuntimeError: DataLoader worker (pid 41) is killed by signal: Bus error.</code>。</li><li id="a88c" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">Kaggle 内核通常看起来有点滞后。</li></ul><p id="3b4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我不知道有其他云提供商提供免费的 GPU 时间(除了入门学分)，所以这次讨论并不是对谷歌的批评。感谢免费的 GPU，谷歌！👍如果你知道其他人有免费的(不仅仅是介绍性的)GPU 资源，请告诉我。</p><h1 id="c9dd" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="4f6d" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">Colab 和 Kaggle 都是在云中开始深度学习的绝佳资源。我发现自己在使用这两个平台。你甚至可以在两者之间下载和上传笔记本。😄</p><p id="312e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看到 Colab 和 Kaggle 增加更多的资源令人兴奋。在我们研究的图像分类任务中，使用 P100 GPU，Kaggle 在训练和预测方面肯定比 Colab GPU 更快。如果你正在运行一个密集的 PyTorch 项目，并希望提高速度，那么在 Kaggle 上开发它是值得的。</p><p id="bfb8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想更灵活地调整批量大小，你可以使用 Colab。使用 Colab，您还可以将您的模型和数据保存到 Google Drive，尽管这个过程可能会有点令人沮丧。如果您使用 TensorFlow，您可能希望在 Colab 上使用 TPUs。</p><p id="df42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你需要更多的能力或更多的时间来运行更长时间的进程，我之前的实验表明谷歌云平台是最具成本效益的云解决方案。</p><p id="b60a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望您发现 Colab 和 Kaggle 的这一比较很有用。如果你有，请分享到你最喜欢的社交媒体频道，这样其他人也可以找到它。👏</p><p id="79bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我撰写关于 Python、开发运营、数据科学和其他技术主题的文章。如果你对这些感兴趣，请查看并跟随我<a class="ae mi" href="https://medium.com/@jeffhale" rel="noopener">到这里</a>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><a href="https://dataawesome.com"><div class="ab gu cl om"><img src="../Images/ba32af1aa267917812a85c401d1f7d29.png" data-original-src="https://miro.medium.com/v2/format:webp/1*oPkqiu1rrt-hC_lDMK-jQg.png"/></div></a></figure><p id="670a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快乐深度学习！</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi on"><img src="../Images/0f436d23f21b7453d667313b64d79887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GY3TQq0R30d5Sj-wqt0BxQ.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Head down either path you like 😄</figcaption></figure></div></div>    
</body>
</html>