<html>
<head>
<title>Conv Nets for dummies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Conv 假人网</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conv-nets-for-dummies-a-bottom-up-approach-c1b754fb14d6?source=collection_archive---------15-----------------------#2019-01-06">https://towardsdatascience.com/conv-nets-for-dummies-a-bottom-up-approach-c1b754fb14d6?source=collection_archive---------15-----------------------#2019-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="728d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">直观的方法</h2></div><p id="ecda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多很棒的在线文章解释了从初学者到高级水平的卷积神经网络(或“CNN”)。这篇文章是为初学者写的，旨在采取一种不同于大多数人的方法:自下而上地解释 CNN 的机制和系统。我的假设是，许多工程师按照解决方案被创建的顺序来学习它们:一次添加一个新功能来构建最终产品。</p><h2 id="9641" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">本文将分为三个部分。</h2><ul class=""><li id="09ca" class="lv lw iq kh b ki lx kl ly ko lz ks ma kw mb la mc md me mf bi translated">首先，解释一下 CNN 要解决的问题。</li><li id="554e" class="lv lw iq kh b ki mg kl mh ko mi ks mj kw mk la mc md me mf bi translated">第二，逐一解释 CNN 的算法(“层”)。</li><li id="49d4" class="lv lw iq kh b ki mg kl mh ko mi ks mj kw mk la mc md me mf bi translated">第三，这些层的使用顺序和原因。</li></ul><h1 id="0aa3" class="ml ld iq bd le mm mn mo lh mp mq mr lk jw ms jx ln jz mt ka lq kc mu kd lt mv bi translated">第一部分:CNN 的设计初衷是什么？</h1><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4aef47d13c9cb728ede2c75ab637a8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/0*1evmirJ_TcEH0cdt.jpg"/></div></figure><p id="f53e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算机视觉奥林匹克是一年一度的竞赛，绰号为“图像网络挑战”(ILSVRC)。从 2010 年开始，这项任务一直是建立一个能够正确识别图像中物体的计算机程序。也就是说，如果我给你的程序一张蝴蝶的图片，它应该返回字符串“butterfly”</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/9ee790936059658efd519320fc5527eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AGS3aJIu_KEu4xNJ.jpg"/></div></div></figure><p id="ed8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个过程几乎是人脑瞬间完成的。不用我说，你已经知道上面的图像是什么了。那是因为人类看到狮子的那一刻，大脑就把它识别为一个截然不同的物体，并立刻将其归类为“狮子”。从生存的角度来考虑这些好处并不困难。ImageNet(名为“AlexNet”)的 2012 年获奖者将这种人类技能作为他们设计的基础。他们通过研究关于大脑识别物体的神经科学理论，创建了一个成功的 CNN。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nj"><img src="../Images/4bc0016f3fb30f6cd416838d63b7d372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Txt88alejvDoD-uQ3E6tg.png"/></div></div></figure><p id="51b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么大脑是如何把上面的图像变成“一块地里的三只狗？”我们做的一件事是识别背景的绿色和狗的棕色皮毛之间的清晰边缘。利用这个我们可以识别出狗的大致轮廓:两只耳朵伸出来，身体很长。这个轮廓内部的其他形状帮助我们确定它是一只狗而不是一只狐狸(考虑舌头、嘴和鼻子的形状等)。狗的颜色也帮助了我们。因此，假设我们想像人类一样处理识别形状的问题，我们可能想从制造一种算法开始，这种算法将识别图像中的某些形状或边缘。<em class="lb">这是第二部分的切入点。</em></p><h2 id="0a76" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">输入细节</h2><p id="215c" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">对于这个问题，理解输入数据的形状是很重要的。对计算机来说，图像是一个三维(宽×高×深)矩阵，值在 0-255 之间。4K 彩色图像的尺寸为 4096×2160×3。也就是说，它的像素宽度<em class="lb">乘</em>像素高度<em class="lb">乘</em>三个颜色通道 RGB。这些值表示每个像素的每种颜色的强度。为了简化，本文将主要考虑深度为 1 的黑白图像。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nn"><img src="../Images/960e5bd196b170abe5b9d267270cc81c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOScqv-bPc0SnHKveZ_gfA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">A visual representation of a 6×6×3 image</figcaption></figure></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="4581" class="ml ld iq bd le mm nz mo lh mp oa mr lk jw ob jx ln jz oc ka lq kc od kd lt mv bi translated">第二部分:CNN 的层次</h1><p id="e15f" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">卷积神经网络可以分解成几个部分。这些组件可以被认为是独立的算法，通常被称为“层”首先，单独考虑各层。第 3 节将在后面讨论它们是如何结合的。有三层我们来看看<em class="lb"> (A，B，C) </em>。</p><h2 id="49c0" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">层 A:卷积</h2><p id="c117" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated"><em class="lb">正如第 1 节</em>中提到的，我们可能想要识别图像内部的边缘或颜色。例如，我们可能想要检测如下图所示的曲线。可以使用值矩阵来表示曲线(就像输入一样)。<strong class="kh ir"> <em class="lb">滤镜的深度总是等于图像的深度。</em>T9】</strong></p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oe"><img src="../Images/da872938008663aa27a263abfb547caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDhnA7JiSJlsOpojRQYWcA.png"/></div></div></figure><p id="afa8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们要测试图像是否包含这个形状。代表这个形状的矩阵被称为<strong class="kh ir">过滤器</strong>。它也被称为神经元或内核。让我们使用我们的滤镜来测试下面这个简单的图形:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi of"><img src="../Images/c4d02c4f308390e51301da49f2ed8b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulwawgRLYbxSo3EZQPr-nA.png"/></div></div></figure><p id="8c9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们关注与过滤器具有相同尺寸(W×H×D)的图像部分，我们可以计算图像部分值和过滤器值的点积。首先，让我们检查包含我们要测试的形状的图像区域。我们关注的区域被称为<strong class="kh ir">感受野</strong>:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi og"><img src="../Images/e25788ca6aa61b1b6ddb3dce34ec23c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zchSodksfKC4SjcS6hes8Q.png"/></div></div></figure><p id="94c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在执行过滤器和感受野之间的点积:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oh"><img src="../Images/3344e549a00595632f712f917b9429e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UpYPJcnncdntjYadqdq6oQ.png"/></div></div></figure><p id="5b0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个部分的点积计算为 218535，这是一个非常大的数字。如果图像中的形状与过滤器的形状不太相似，这个数字会更小。在下面的示例中，由于图像中的形状与滤镜的形状不匹配，点积计算出的值要低得多(计算出的值为 0)。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oi"><img src="../Images/c315af9cbfd4596bd40b1e21b360f0cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmfPeUDgGUkMtkZa3B2bYA.png"/></div></div></figure><p id="8236" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，点积越大，过滤器和图像的截面越相似。因此，我们可以使用过滤器和图像部分的点积来测试特定形状的位置。获得正确的过滤器值是很重要的，因为您想要测试适当的形状。我们在 CNN 中“训练”的值正是这个:过滤器的矩阵值。在对一组图像进行训练之前，通常会随机初始化这些值。<em class="lb"> </em>注意，过滤器的值也可以是负数。</p><p id="8494" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们如何存储这些信息呢？我们希望为图像中有曲线的地方保留某种形式的记录。我们如何存储左上方有一条曲线，而右侧没有？</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oj"><img src="../Images/b30bf4be72f0d7e7e36d3f8bc4c5ac57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51l_QXZJ38L7ux9lvTYPvA.png"/></div></div></figure><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/c32fd3c15170a38cc8fff73a79288f5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*p-tucejPrQBONJeb.gif"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Taken from <a class="ae ol" href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener ugc nofollow" target="_blank">this</a> very helpful repo on GitHub</figcaption></figure><p id="2ae0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于每个感受野，点积计算存储在另一个称为<strong class="kh ir">激活图</strong>的矩阵中。</p><p id="b58a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它被称为<em class="lb">图</em>，因为激活图上的任何位置都将表示形状(过滤器)与实际图像的相应位置的匹配程度。换句话说，地图显示了图像中某个形状出现的位置。</p><p id="ebfe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">一个滤镜的激活图深度始终为 1。</em>T3】</strong></p><h2 id="76ad" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">B 层:池化</h2><p id="fb6a" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">池层的目的是减少激活图的空间大小。这不仅减少了必要的计算量，而且防止了过度拟合。合用的想法很简单。我们想把大矩阵缩小成小矩阵。最常用的池技术是<strong class="kh ir">最大池</strong>。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi om"><img src="../Images/cb485e9708a369b4ff2813b84beeea3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hhXJeSSaR2dhZRnPXXqXQ.png"/></div></div></figure><p id="39a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种方法的思想是只保留激活图中较小区域的最大值，而去掉其余的。在上面的橙色区域中，7 是最大值，因此它被保留，而 5、3 和 2 被丢弃。</p><h2 id="379c" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">C 层:完全连接</h2><p id="6741" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">全连接层总是卷积神经网络的最后一层。这是因为它是将图像上完成的转换关联到实际类别(如“狮子”和“鼠标”)的层。</p><p id="49da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一层是传统的多层感知器。理解多层感知器对于从总体上理解机器学习模型很重要(<a class="ae ol" rel="noopener" target="_blank" href="/artificial-neural-networks-for-total-beginners-d8cd07abaae4">在这里用图像找到一个很棒的解释！</a>)。CNN 的全连接层只是其应用的众多情况之一。因此，我敦促你寻找另一个更深入的教程。现在，我将重点讨论这一层的输入和输出。</p><p id="9c5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">全连接层的输入</strong>是一个值矩阵，包含某些复杂形状的位置信息。它实际上指出了这些形状在图像上的位置。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi on"><img src="../Images/d8d657358c19139b98c2e82330e43a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QVdTZoal6-EBiYGWw9PMcA.png"/></div></div></figure><p id="d6a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们如何获得这种输入将在第 3 节中变得更加明显。然而，现在要记住的重要事情是，输入指示复杂图案的位置，这些复杂图案帮助我们猜测图像是由什么组成的。我们称这些复杂的模式为<strong class="kh ir">可训练分类器</strong>。模型学习寻找的确切的可训练分类器可能与上面给出的说明性例子有很大不同。</p><blockquote class="oo op oq"><p id="92f5" class="kf kg lb kh b ki kj jr kk kl km ju kn or kp kq kr os kt ku kv ot kx ky kz la ij bi translated"><em class="iq">为什么我们不</em> <strong class="kh ir"> <em class="iq">只</em> </strong> <em class="iq">使用全连接层？</em></p></blockquote><p id="4b74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">好吧，虽然全连接层可能能够“分析”已经识别的形状的组合，但是它不能理解单个像素。这是因为单个像素与图像包含的内容无关，而复杂的形状却相关。很少有猫的图像包含轮子的形状。</em></p><p id="b071" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">全连接层的输出</strong>是我们决定训练模型的每个类别的概率向量。例如，如果我们强迫一个模型将一幅图像分类为“猫”、“狮子”或“汽车”，那么输出可能是一个向量，例如[0.91，0.08，0.01]。这意味着有 91%的可能性图像是一只猫，8%是一只狮子，1%是一辆汽车。然后，我们选择最有可能的类别作为我们对该图像的“猜测”。<strong class="kh ir"> <em class="lb">这个向量中的元素之和总是加 1。</em> </strong>(如果你对为什么和多层感知器的激活功能有关感兴趣)。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ou"><img src="../Images/8e3337882d9a39720606488e609560f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXPPryWZMRXcvANeuZkWCQ.png"/></div></div></figure><p id="81f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，输出权重来源于图像中的可训练分类器的内容，以及它们相对于彼此的位置。这突出了一组好的图片对训练的重要性。如果模型从未从侧面看过汽车，它可能会将这样的图像误分类为不是汽车。然而，我们所做的工作意味着我们不需要从每个角度去看<em class="lb">。</em></p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="b381" class="ml ld iq bd le mm nz mo lh mp oa mr lk jw ob jx ln jz oc ka lq kc od kd lt mv bi translated"><strong class="ak">第三节:合并图层</strong></h1><p id="5f18" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated"><em class="lb">有几种方法可以将第 2 节中描述的图层组合成对图像分类有用的东西。在这里，我们看看如何结合多个卷积层来识别复杂的形状，以及 CNN 中使用的第四个“层”:非线性函数。最后，我们将看看一些成功的 CNN 及其一般架构。</em></p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ov"><img src="../Images/afa4fcd7e349c60a8bb646a43a52650c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QfLYW2Zz5INs-dzd-x37bg.png"/></div></div></figure><p id="6531" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 2A 一节中，我们讨论了卷积层，并以一个简单的形状为例来测试图像。实际上，过滤器看起来有点不同。左边是一个来自 CNN 的斯坦福课程的例子。这是过滤器外观的更精确的可视化。</p><p id="9cc0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">认识到这些模式是一个好的开始，但它们可能不会识别出什么是“狮子”或“猫”为此，我们需要用这些简单的形状构建更复杂的形状。</p><p id="6e84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了识别下面的形状，我们可以像前面一样为它创建一个过滤器。如此复杂的过滤器的问题是，它可能无法识别相似但不完全适合的形状，或者它可能会错误地触发看起来不像过滤器的形状。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ow"><img src="../Images/30122c308d4242962877ded88a1e4f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IRA1jBqINGoPHh3gW7vr2w.png"/></div></div></figure><p id="d0be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更简单的过滤器可以更好地避免这些问题。因此，它们保持简单。相反，我们在一个卷积层中对图像应用多个滤波器，并且仅当它们被检测到并被单独记录在激活图中时，才在下一层中组合它们。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ox"><img src="../Images/3c66a43f39b4d497466f9214b342bd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZgHDQwopswiVc2TZaNeDw.png"/></div></div></figure><p id="6154" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原始图像上的两个单独的形状(过滤器 1 和 2)在激活图中被识别为较高的值(根据点积计算)。然后，我们可以创建一个与第一层的输出深度相同的过滤器来组合这些过滤器。在上面的例子中，这个深度是 2，因为我们使用了 2 个过滤器。在其他架构中，这可能更大；这完全取决于我们在第一层使用多少过滤器。在我们的例子中，第二层的滤波器可以非常简单。我们希望通过查看激活图 1 找到形状 1 的出现，通过查看激活图 2 找到形状 2 的出现。将这些投影到 2D 图像上应该会产生它们的并排组合。因此，我们可以识别图像中具有更复杂形状的区域。</p><p id="f84b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，这个过程会根据您的需要重复多次。重复更多次意味着网络可以学习越来越复杂的形状。目标是学习检测复杂的特征，这些特征可以成为一系列对象的<strong class="kh ir">可训练分类器</strong>。考虑以下汽车的复杂特征:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oy"><img src="../Images/1d1780c57495d69bb0a248a4d1ffdad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*itUQexEzTSTgcU3BK6NdxA.png"/></div></div></figure><p id="4333" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述具体特征并不一定是参与 ILSVRC 竞争的网络所要“寻找”的。它们只是帮助我们人类理解 CNN 下正在发生的事情的可视化。</p><h2 id="8d73" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">那么，为什么要为这个“非线性函数”而烦恼呢？</h2><p id="7a5d" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">如果你熟悉其他神经网络结构，你不会对在卷积层之间使用非线性函数感到惊讶。但这是为什么呢？非线性函数有什么作用？</p><p id="adc0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单的回答就是卷积是线性变换。对此有简单的数学解释(比如<a class="ae ol" href="https://www.quora.com/Why-do-we-need-a-non-linear-activation-function-in-a-convolutional-neural-network-The-convolution-is-already-non-linear-Shouldnt-that-already-be-enough" rel="noopener ugc nofollow" target="_blank">这个</a>)，如果你还不相信的话，我建议你读一读。</p><p id="bef1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果我们一个接一个地执行多个线性变换，最终的过程可以简化为单个线性变换。因此，为了避免卷积层折叠成单个变换，我们可以在每个卷积之间引入非线性元素。</p><p id="27c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多 CNN 中使用的一个成功的非线性函数是 ReLU。这是一个简单的函数“max(0，x)”，其中 x 是输入值，应用于整个矩阵的元素。它把任何负值变成 0。</p><h2 id="d58d" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">把这些放在一起，设计 CNN 的架构</h2><p id="3073" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">现在，您已经了解了所有的构建模块。我们(1)采取一个形象，并适用于卷积层。然后，我们(2)对输出应用非线性函数，以便(3)用另一个卷积层重复。在几个卷积和非线性对层之后，我们(4)应用汇集层以降低复杂性并避免过拟合。重复几次(步骤 1-4 ),我们已经确定了一些可训练的分类器，并且可以(6)将输出矩阵发送到完全连接的层中。它输出我们想要训练的每个类别的概率权重。该过程总结如下:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="ab gu cl oz"><img src="../Images/15f45e6cc09b0aa01743221888686901.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2SWb6CmxzbPZijmevFbe-g.jpeg"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Again, taken from Stanford’s <a class="ae ol" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">course</a> on CNNs</figcaption></figure><p id="fa92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有关于层数、超参数和它们的顺序的选择将唯一地识别一个网络。有许多开源和著名的网络，有不同的目的和成功的程度。我们已经讨论了 AlexNet，ILSVRC 2012 的获胜者。另一个专注于识别更复杂的可训练分类器的网络称为 VGG。</p><p id="f550" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">就是这样！</strong>在这一点上，我们理解了 CNN 如何解决我们在顶部确定的问题:将它以前没有见过的图像分类到主题类别中。</p><p id="57ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你喜欢这篇文章，请考虑给它一点掌声。这真的帮助了我，激励我去做更多！</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi pa"><img src="../Images/3e8f82abd4478e22a2f9ae96755b5041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQtE_hkxpr1HBfRwqynP9A.png"/></div></div></figure></div></div>    
</body>
</html>