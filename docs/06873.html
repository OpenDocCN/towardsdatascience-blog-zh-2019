<html>
<head>
<title>Real-time Mobile Video Object Detection using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流的实时移动视频对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-mobile-video-object-detection-using-tensorflow-a75fa0c5859d?source=collection_archive---------6-----------------------#2019-09-30">https://towardsdatascience.com/real-time-mobile-video-object-detection-using-tensorflow-a75fa0c5859d?source=collection_archive---------6-----------------------#2019-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7e66" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">全栈数据科学</h2><div class=""/><div class=""><h2 id="5993" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">向您的下一个移动应用程序添加对象检测的分步指南</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/f4cb76590dcf906160107de5238de778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yu9ksZJXbV5RT_oOdjNszg.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Photo by GeoHey</figcaption></figure><p id="f2f7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">随着人们对自动驾驶汽车、人脸识别、智能交通系统等计算机视觉用例的兴趣日益增加。人们正在寻求建立定制的机器学习模型来检测和识别特定的对象。</p><p id="37f8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然而，从零开始构建定制模型需要大量的专业知识、时间和计算资源——从数据标注到模型服务。为了减少障碍，谷歌发布了开源工具，如<a class="ae lz" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">tensor flow Object Detection API</a>和<a class="ae lz" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub </a>，使人们能够利用那些已经广泛使用的预训练模型，如更快的 R-CNN、R-FCN 和 SSD，使用迁移学习快速构建定制模型。</p><p id="4081" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">本文将展示我们如何使用 TensorFlow 的对象检测 API 来训练实时视频对象检测器，并通过以下步骤将其快速嵌入到我们自己的移动应用程序中:</p><ol class=""><li id="db7c" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly mf mg mh mi bi translated">设置开发环境</li><li id="a9c2" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">准备图像和元数据</li><li id="c5cb" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">模型配置和培训</li><li id="7146" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">将定型模型转换为 TensorFlow Lite</li><li id="8944" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">在移动应用程序中测试模型</li></ol><h1 id="3b3a" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">设置环境</h1><p id="9334" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">本文中的所有代码都基于 macOS &amp; Linux 系统。对于 Windows 用户，你可以在<a class="ae lz" href="https://hub.docker.com/r/tensorflow/tensorflow/" rel="noopener ugc nofollow" target="_blank"> docker </a>容器中工作:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="42ac" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">或者安装<a class="ae lz" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10" rel="noopener ugc nofollow" target="_blank"> Windows 子系统用于 Linux </a>(由于主机硬件隔离，这个不支持 TensorFlow GPU)。</p><p id="5861" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于 VS 代码用户来说，remote <a class="ae lz" href="https://code.visualstudio.com/docs/remote/wsl" rel="noopener ugc nofollow" target="_blank"> WSL </a>和<a class="ae lz" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers" rel="noopener ugc nofollow" target="_blank"> Containers </a>的扩展也给出了更好的开发体验，应该完全兼容本文中的脚本。</p><h2 id="1e5b" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">设置项目目录</h2><p id="05d3" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">为了便于阅读，我们将在主项目目录中创建三个子文件夹:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e25c0ad0775e141e51d87ed3e28fb297.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UtxsBkc6OTxCeaTaK_m6Fw.png"/></div></figure><p id="7a07" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">数据— </strong>存储模型数据的文件夹(如*。记录，*。csv 等。)</p><p id="8019" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">模型— </strong>存储所有预训练模型及其配置文件的文件夹。</p><p id="7683" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> tf-models — </strong>一个文件夹，其中包含来自 Tensorflow 的克隆模型代码，我们将在建模中使用这些代码。</p><p id="466f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用下面的脚本复制上面的项目文件夹结构。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h2 id="f04f" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">安装 Tensorflow 对象检测 API 和依赖项</h2><p id="79c4" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">一旦我们有了项目设置，Tensorflow 对象检测 API 现在应该位于<code class="fe nz oa ob oc b">rf-models/research/object_detection</code>中，代码库目前由社区维护，稍后我们将从那里调用模块进行模型训练。</p><blockquote class="od oe of"><p id="5834" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">(可选)对于 Tensorflow 对象检测 API 代码基础之上的任何进一步工作，请查看<code class="fe nz oa ob oc b">model_main.py</code>和<code class="fe nz oa ob oc b">model_lib.py</code>作为起点。</p></blockquote><p id="6ae9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在我们需要安装其余的依赖项。要安装所需的 python 库:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="6125" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">安装<a class="ae lz" href="https://github.com/cocodataset/cocoapi" rel="noopener ugc nofollow" target="_blank"> COCO API </a></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><blockquote class="od oe of"><p id="7aab" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:如果您在编译 COCO API 时遇到问题，请确保在编译之前已经安装了 Cython 和 Numpy。</p></blockquote><p id="17d8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">安装<a class="ae lz" href="https://github.com/protocolbuffers/protobuf" rel="noopener ugc nofollow" target="_blank"> Protobufs </a> — Tensorflow 对象检测 API 使用 Protobufs 来配置模型和训练参数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="a432" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">向 PYTHONPATH 添加 Tensorflow 库</strong></p><p id="4dca" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本地运行时，<code class="fe nz oa ob oc b">rf-models/research/</code>和<code class="fe nz oa ob oc b">rf-models/research/slim</code>目录需要追加到 PYTHONPATH 中，以便将来自 TensorFlow 对象检测 API 的 python 模块添加到搜索路径中，它们将在稍后阶段从模型脚本中被调用。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><blockquote class="od oe of"><p id="6c2a" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:上述脚本需要在每个新的终端环境中运行。或者，您可以添加您的~/。以绝对路径作为永久解决方案的 bashrc 文件。</p></blockquote><h2 id="e98f" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">测试安装</h2><p id="b2b0" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">要测试一切是否按预期运行:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="9561" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">您应该会看到如下测试输出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/e35f0623dd8d0b70a0ec2e70d89cfffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2nOnlnEzp96XEGginU8TRA.png"/></div></figure><h1 id="7e1c" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">准备图像和元数据</h1><h2 id="904a" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">下载图像数据</h2><p id="e445" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">我们使用的图像数据来自香港中文大学多媒体实验室创建的 DeepFashion 数据库。这是一个大规模的服装数据库，拥有超过 800，000 张不同的时尚图片，从造型优美的商店图片到无拘无束的消费者照片。</p><p id="c5aa" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">数据库中的所有图像都被标注了丰富的信息，包括 50 个不同的类别，1000 个描述性属性，边界框和服装标志。</p><p id="99e0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">特别地，我们使用“类别和属性预测基准”类别作为时尚对象检测任务的训练数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/12cc025d7da619fe04bf4610e27d424f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zaUXHyfscrZHGRFUJTeLcQ.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Photo by DeepFashion</figcaption></figure><p id="bf8b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这里下载数据(<a class="ae lz" href="https://drive.google.com/drive/folders/0B7EVK8r0v71pWGplNFhjc01NbzQ" rel="noopener ugc nofollow" target="_blank"> Google Drive </a>)并将它们解压到我们项目目录下的<code class="fe nz oa ob oc b">data</code>文件夹中。完成后将有三个子文件夹:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a50e377812861ccd87c0e7717f310e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ys1aU1HHL53VS863_HaOnQ.png"/></div></figure><p id="b777" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">彦俊</strong> —标注包括包围盒标签、时尚地标标签、服装类别标签、服装属性标签。</p><p id="c648" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">Eval</strong>—分别用于训练、验证和测试集的图像名称。</p><p id="a2fd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">img</strong>—289222 张多样的服装图片。(为了加快开发速度，我们在本文中使用低分辨率图像)</p><h2 id="bf50" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">我们先来看看数据</h2><p id="cac6" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">我从数据集中随机挑选了一些图像，并用它们的边框打印出来。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/f98edd466073df94c47c52a377f608ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIF95aG4Q0aYyG2W-cMaPw.png"/></div></figure><blockquote class="od oe of"><p id="1e9a" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:由于 DeepFashion 数据库已经提供了边界框标签，我们不需要标记数据，而如果你想为其他图像创建自己的标签，或者改进当前的标签(正如我们在上面的图像中看到的，一些边界框的质量并不完美。<a class="ae lz" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> LabelImg </strong> </a>将是那些工作的工具之一。</p></blockquote><p id="64e8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们还将使用图像元数据的聚合视图为训练集和测试集创建汇总表。汇总表将在稍后阶段用于为模型训练生成建模数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/bb2f3cb2778d401addec85251fb1057b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*3xdORPIFkH4tH-VU3h4dRg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">summary table — training set</figcaption></figure><p id="b6e7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">可视化上述图像并生成汇总表的 python 脚本可以在这里找到<a class="ae lz" href="https://github.com/ivanliu1989/Real-time-Mobile-Video-Object-Detection/blob/master/generate_summary_table.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>。因此，我们现在在<code class="fe nz oa ob oc b">data</code>文件夹中有了汇总表(<code class="fe nz oa ob oc b">train_labels.csv</code> &amp; <code class="fe nz oa ob oc b">test_labels.csv</code>)。</p><blockquote class="od oe of"><p id="b605" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:为了简化工作，您将在笔记本中看到我们只选择了前 6 个常用类别。</p></blockquote><h2 id="2f90" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">生成 TF 记录</h2><p id="14b8" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">为了高效地读取数据，TensorFlow 使用 TFRecord 格式，这是一种存储二进制记录序列的简单格式。它对数据进行序列化，使它们能够被线性读取，如果数据是通过网络传输的，这一点尤其正确。</p><p id="59ce" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了将图像数据转换为 TFRecord 格式，我们将使用以下 python 模板，并将我们创建的汇总表作为参考:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><blockquote class="od oe of"><p id="729e" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:通过为新标签更新 class_text_to_int()，我们可以为其他数据集使用相同的模板。</p></blockquote><p id="aa03" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一旦执行完成，你会在<code class="fe nz oa ob oc b">data</code>文件夹下看到两个新文件，分别命名为<code class="fe nz oa ob oc b">test.record</code>和<code class="fe nz oa ob oc b">train.record</code>。</p><h2 id="9af7" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">生成标签地图</h2><p id="2d2d" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">我们现在需要创建一个标签映射，即将每个使用的标签映射到一个整数值。训练和推理过程都将使用标签映射。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="9e32" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">上面的脚本给了我们一个名为<code class="fe nz oa ob oc b">label_map.pbtxt</code>的新文件。如果我们想引入额外的新标签，我们需要相应地更新它。</p><p id="df5a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们已经在<code class="fe nz oa ob oc b">data</code>文件夹中准备好了所有需要的文件。</p><h1 id="f188" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">模型配置和培训</h1><h2 id="d5fb" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">下载预先训练的模型</h2><p id="b78d" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">正如我们在开始时提到的，我们将使用预训练模型，而不是从头开始设计模型，<a class="ae lz" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">检测模型动物园</a>收集广泛使用的预训练模型的列表。</p><p id="14d9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">例如，我们将使用 SSD mobilenet 量化模型，该模型针对移动设备性能进行了优化，降低了模型推理的复杂性(同时牺牲了一些模型性能)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="42e6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">模型文件将保存在如下的<code class="fe nz oa ob oc b">models</code>文件夹下。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e81f01f43907843afffc058589480de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*cTrPkSiykXAGCQC4GhxV1Q.png"/></div></figure><p id="8b16" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们需要了解的一些文件是:</p><ul class=""><li id="e69d" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly om mg mh mi bi translated"><strong class="lf jd"> model.ckpt </strong> —您的模型(预训练模型/部分训练模型)的检查点，带有用于进一步训练的估计器。</li><li id="03ba" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly om mg mh mi bi translated"><strong class="lf jd"> pipeline.config </strong> —模型、训练数据、评估数据等的配置。</li></ul><h2 id="21a0" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">更新模型管道配置</h2><p id="1a48" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated"><code class="fe nz oa ob oc b">pipeline.config</code>中有五个主要部分<em class="og">。</em><em class="og">模型</em>部分定义了网络的预设计架构。<em class="og"> train_config </em>部分定义模型训练参数，为我们提供调整参数的灵活性，如批量大小、学习速率、学习步骤等。</p><pre class="ks kt ku kv gt on oc oo op aw oq bi"><span id="f732" class="nn mp it oc b gy or os l ot ou">model {<br/>(... Add model config here...)<br/>}<br/><br/>train_config : {<br/>(... Add train_config here...)<br/>}<br/><br/>train_input_reader: {<br/>(... Add train_input configuration here...)<br/>}<br/><br/>eval_config: {<br/>}<br/><br/>eval_input_reader: {<br/>(... Add eval_input configuration here...)<br/>}</span></pre><p id="5674" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于我们的试验，我们将模型配置和超参数保留为默认值，仅更新以下配置:</p><ul class=""><li id="c657" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly om mg mh mi bi translated">数量类 : 6</li><li id="0cf9" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly om mg mh mi bi translated"><strong class="lf jd">微调检查点</strong>:检查点文件的路径<code class="fe nz oa ob oc b">model.ckpt</code></li><li id="8c14" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly om mg mh mi bi translated"><strong class="lf jd"> label_map_path </strong>:上面创建的<code class="fe nz oa ob oc b">label_map.pbtxt</code>的路径</li><li id="f172" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly om mg mh mi bi translated"><strong class="lf jd"> tf_record_input_reader </strong>:上面创建的<code class="fe nz oa ob oc b">train.record</code>和<code class="fe nz oa ob oc b">test.record</code>的路径</li></ul><h2 id="3e4c" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">模特培训</h2><p id="eff7" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">接下来，为了初始化训练，我们现在可以直接使用来自 TensorFlow 对象检测 API 的建模脚本:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="bcd2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">训练开始后，我们应该会在下面的控制台中看到训练进度日志。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/b8f9ba52331f03548c1a1cf5e08fdac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHy-3Wzp6RcnlmhDWWKskA.png"/></div></figure><p id="2d4b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">此外，我们还可以使用 tensorboard 根据可视化的性能指标和验证集对训练步骤的预测来持续监控进度。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/47ed4c168b44cf08bb3aa5ff3389bc1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pI1wshY3M4S29NLPxVrYjg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/5530f4aee88495bf4695e4f7806b4ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*csnx1lg1W4O6u1zeaLRitg.png"/></div></figure><blockquote class="od oe of"><p id="7752" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注 1:如果在训练过程中出现内存不足错误，请尝试减少<code class="fe nz oa ob oc b"><em class="it">pipeline.config</em></code>文件中训练步骤的批量。</p><p id="d240" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注 2:我们可以随时停止训练，稍后通过更新<code class="fe nz oa ob oc b"><em class="it">pipeline.config</em></code>中的<code class="fe nz oa ob oc b"><em class="it">fine_tune_checkpoint</em></code>从任何检查点继续。作为一个例子，你可以在这里找到我部分训练的模型检查点<a class="ae lz" href="https://github.com/ivanliu1989/Real-time-Mobile-Video-Object-Detection/tree/master/models/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><h1 id="4404" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">转换为 TensorFlow Lite</h1><p id="529b" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">一旦我们有了一个经过训练/部分训练的模型，要为移动设备部署该模型，我们需要首先使用<a class="ae lz" href="https://www.tensorflow.org/mobile/tflite/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>将该模型转换为一个针对移动和嵌入式设备优化的轻量级版本。它支持设备上的机器学习推理，具有低延迟和更小的二进制大小。它使用像量化核这样的技术来实现更小更快的(定点数学)模型。</p><blockquote class="od oe of"><p id="1613" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">目前仅支持 SSD 型号。目前不支持 faster_rcnn 这样的模型。</p></blockquote><h2 id="d159" class="nn mp it bd mq no np dn mu nq nr dp my lm ns nt na lq nu nv nc lu nw nx ne iz bi translated">安装 Bazel 并生成冻结图</h2><p id="6992" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">我们需要首先安装 Bazel 构建工具(对于不同的操作系统，请参考<a class="ae lz" href="https://docs.bazel.build/versions/master/install.html" rel="noopener ugc nofollow" target="_blank">安装指南</a>)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="fbaa" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Bazel 安装完成后，我们将选择最新的检查点，以获得 TensorFlow 冻结图，该图具有兼容的操作，可以与 TensorFlow Lite 一起使用。要获得冻结图，我们可以直接从<code class="fe nz oa ob oc b">tf-models/research</code>使用模板脚本<code class="fe nz oa ob oc b">export_tflite_ssd_graph.py</code>。</p><blockquote class="od oe of"><p id="4caf" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:这是为了简单起见，我们应该总是检查模型评估来决定最佳的检查点/步骤。</p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="315e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这将给我们指定输出目录(<code class="fe nz oa ob oc b">/tmp/tflite</code>)中的两个文件(<code class="fe nz oa ob oc b">tflite_graph.pb</code> &amp; <code class="fe nz oa ob oc b">tflite_graph.pbtxt</code>)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/42726ecd9436907395ba323e74c9f3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4tgwSUCJrGegAdDjkRLEg.png"/></div></figure><p id="7425" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">之后，我们将使用 TensorFlow Lite 优化转换器<a class="ae lz" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco" rel="noopener ugc nofollow" target="_blank">到</a>从 TensorFlow 冻结图源文件(<code class="fe nz oa ob oc b">tflite_graph.pb</code>)中获取优化的模型。我们将通过运行下面来自<code class="fe nz oa ob oc b">tensorflow</code>目录的脚本，为更好的移动性能生成一个量化模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="158c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果脚本运行成功，您现在应该会在<code class="fe nz oa ob oc b">/tmp/tflite</code>目录下看到一个新文件— <code class="fe nz oa ob oc b">detect.tflite</code>。该文件包含图表和所有模型参数，可通过 Andriod &amp; iOS 设备上的 TensorFlow Lite 解释器运行。</p><h1 id="4a19" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">在移动设备上运行 TensorFlow Lite 模型</h1><p id="1df3" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">现在，我们剩下的最后一步是将我们的模型嵌入到我们的移动应用程序中，这应该很简单，因为 TensorFlow 已经提供了示例应用程序，使人们更容易测试模型。</p><p id="760a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要下载示例应用程序代码并以 ios 为例:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><blockquote class="od oe of"><p id="f28e" class="ld le og lf b lg lh kd li lj lk kg ll oh ln lo lp oi lr ls lt oj lv lw lx ly im bi translated">注意:构建 iOS 应用程序超出了本文的范围，本质上，上面的脚本是安装 Podfile 中列出的 iOS 应用程序的所有依赖项。一旦脚本完成，就会在<code class="fe nz oa ob oc b">ios</code>目录下创建一个<code class="fe nz oa ob oc b">*.xcworkspace</code>文件。</p></blockquote><p id="4893" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">实际模型文件保存在<code class="fe nz oa ob oc b">ios/ObjectDetection/Model</code>下，其中包含模型文件(<code class="fe nz oa ob oc b">detect.tflite</code>)和一个标签映射文件。我们需要从我们的模型中覆盖模型文件和标签映射。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="7654" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">接下来，要构建应用程序:</p><ol class=""><li id="cf86" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly mf mg mh mi bi translated">在 Xcode 中打开<code class="fe nz oa ob oc b">ObjectDetection.xcworkspace</code>。</li><li id="f3fd" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">首次编译应用程序时，请更新捆绑包标识符，并在“常规-&gt;签名”中选择您的开发团队。</li><li id="87e7" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">将您的移动设备连接到笔记本电脑</li><li id="bfff" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly mf mg mh mi bi translated">在 Xcode 中构建并运行应用程序。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/0cd537e7b37d63a753aaf13444380005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJPE9xmk231wq-oLesbEOg.png"/></div></figure><p id="4359" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一旦项目建立，应用程序现在应该在您的移动设备上运行，并测试我们的模型执行得有多好！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/4ded442667cc34004ab76b7b78a92825.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Qqj1ZM6cK132rgaA8-9SHA.png"/></div></figure><h1 id="460f" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">下一步是什么</h1><p id="65e9" class="pw-post-body-paragraph ld le it lf b lg ng kd li lj nh kg ll lm ni lo lp lq nj ls lt lu nk lw lx ly im bi translated">到目前为止，我们已经完成了使用实时视频对象检测的自定义模型创建 iOS 应用程序的过程，这也是一个很好的起点，可以通过利用一些现有的预训练模型来快速原型化这些想法。</p><p id="d4fe" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">可以通过以下方式进一步实施应用程序:</p><ul class=""><li id="abc2" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly om mg mh mi bi translated">手动标记原始图像数据以获得训练集的更好质量(例如，标记如下<strong class="lf jd"> ) </strong></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/2e3498fa4d4fedc578ac557356b98641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wf0Ea9oDT2RC1uI9rnKslg.png"/></div></figure><ul class=""><li id="6906" class="ma mb it lf b lg lh lj lk lm mc lq md lu me ly om mg mh mi bi translated">模型选择和超参数调整以获得更好的模型性能。</li><li id="068f" class="ma mb it lf b lg mj lj mk lm ml lq mm lu mn ly om mg mh mi bi translated">将应用容器化，并利用云服务(例如 TPU)进一步扩展建模。</li></ul><p id="d94e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><a class="ae lz" href="https://github.com/ivanliu1989/Real-time-Mobile-Video-Object-Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> GitHub </strong> </a>资源库为教程。</p><h1 id="1472" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">参考</h1><div class="ow ox gp gr oy oz"><a href="https://www.tensorflow.org/lite/examples" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd jd gy z fp pe fr fs pf fu fw jc bi translated">TensorFlow Lite 示例| TensorFlow</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">面向移动和嵌入式设备的 TensorFlow Lite</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">www.tensorflow.org</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn kx oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#training-the-model" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd jd gy z fp pe fr fs pf fu fw jc bi translated">培训自定义对象检测器- TensorFlow 对象检测 API 教程文档</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">所以，到目前为止你应该已经做了以下事情:现在我们已经做了以上所有的事情，我们可以开始做一些酷…</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">tensor flow-object-detection-API-tutorial . readthedocs . io</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn kx oz"/></div></div></a></div></div></div>    
</body>
</html>