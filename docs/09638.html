<html>
<head>
<title>Three Model Explanability Methods Every Data Scientist Should Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个数据科学家都应该知道的三种模型解释方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/three-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df?source=collection_archive---------6-----------------------#2019-12-18">https://towardsdatascience.com/three-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df?source=collection_archive---------6-----------------------#2019-12-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="368c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">排列重要性和部分相关性绘图新版 scikit-learn 0.22 支持(庆祝🎉！)和 SHAP 作为奖励。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/728b46d54a5e4ef29c776b254e683625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lnALFZUXE8-Zw4F9"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@sagarp7?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sagar Patil</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3026" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2019 年 12 月 3 日，新版<code class="fe lv lw lx ly b">scikit-learn</code>0.22 版本发布，其中附带了许多精彩且不容错过的功能，作为其<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html#" rel="noopener ugc nofollow" target="_blank"> <em class="lz">发布亮点 scikit-learn 0.22</em></a><em class="lz"/>给出了一个快速总结:</p><ul class=""><li id="7f21" class="ma mb it lb b lc ld lf lg li mc lm md lq me lu mf mg mh mi bi translated">新增绘图 API:<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html" rel="noopener ugc nofollow" target="_blank">plot_roc_curve</a></code>、<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html#sklearn.inspection.plot_partial_dependence" rel="noopener ugc nofollow" target="_blank">plot_partial_dependence</a></code>、<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html" rel="noopener ugc nofollow" target="_blank">plot_precision_recall_curve</a></code>和<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">plot_confusion_matrix</a></code>。</li><li id="f295" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated">sci kit-学习<a class="ae ky" href="http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/" rel="noopener ugc nofollow" target="_blank">堆叠</a>、<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html" rel="noopener ugc nofollow" target="_blank">StackingClassifier</a></code>和<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html" rel="noopener ugc nofollow" target="_blank">StackingRegressor</a></code>的原生类。</li><li id="66cf" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated">一个 scikit-学习排列重要性的本地函数，<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html" rel="noopener ugc nofollow" target="_blank">permutation_importance</a></code></li><li id="6759" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning" rel="noopener ugc nofollow" target="_blank">一个新参数</a> <code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning" rel="noopener ugc nofollow" target="_blank">ccp_alpha</a></code>用于基于决策树的模型修剪树。</li><li id="e9fe" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated">支持<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank"> AUCROC 函数</a> <code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank">roc_auc_score</a></code>的多类分类。</li><li id="6fb4" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi">….</li></ul><p id="7f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看到了吗？很多期待已久的功能！尤其是原生支持堆叠岩石！但是在这篇文章中，我们来看看<em class="lz">模型可移植性的三个重要工具</em> <strong class="lb iu"> <em class="lz">，</em> </strong>其中一部分是由<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.partial_dependence.plot_partial_dependence.html" rel="noopener ugc nofollow" target="_blank">plot_partial_dependence</a></code>和<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html" rel="noopener ugc nofollow" target="_blank">permutation_importance</a></code>在新版本 scikit-learn 中实现的。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="6306" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">目录</h1><ol class=""><li id="ad3b" class="ma mb it lb b lc nn lf no li np lm nq lq nr lu ns mg mh mi bi translated">为什么可解释性很重要？</li><li id="574c" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">首先要做的是…</li><li id="60fe" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">可变重要性-基于树的模型可变重要性</li><li id="10b1" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">可变重要性—排列重要性</li><li id="8b5e" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">部分相关图</li><li id="5712" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">沙普利附加解释(SHAP)</li><li id="b527" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">那么，用哪个呢？</li><li id="82fc" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">结论</li><li id="9240" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu ns mg mh mi bi translated">参考</li></ol></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="0c58" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">1.为什么可解释性很重要？</h1><p id="d793" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">人们经常说机器学习模型是一个“黑匣子”。</p><p id="911f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人们知道他们非常擅长预测，但当有人问他们为什么擅长预测时，像损失函数最小化或利润最大化这样的行话不会有帮助。</p><p id="9fc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，人们想听到的是“<em class="lz">变量 A 正作用+10，变量 B 负作用-2… </em>”之类的东西，这就是线性模型相对于高级 ML 算法的常见嫌疑人的优势。</p><p id="1dad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管如此，由于许多研究人员的贡献，现在有一些有用的工具来给机器学习模型赋予<em class="lz">可解释性</em> <strong class="lb iu"> </strong>。</p><p id="62aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了那些工具，我们就可以知道和理解(至少<em class="lz">感觉像</em>我们理解)那个<strong class="lb iu"/>哪个变量对预测的影响有多大<strong class="lb iu"/>？</p><p id="41e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据 Kaggle 教程<a class="ae ky" href="https://www.kaggle.com/learn/machine-learning-explainability" rel="noopener ugc nofollow" target="_blank">“机器学习可解释性”</a>，可解释性的好处如下:</p><blockquote class="nw nx ny"><p id="7cd1" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><strong class="lb iu">调试</strong></p><p id="9464" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> -您可以从对预测的可疑影响中识别错误的预处理或数据泄漏。</em></p><p id="375b" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><strong class="lb iu">通知特征工程</strong></p><p id="f7bb" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> -当你没有直觉什么样的变量组合能给出好的预测力时，数据可解释性研究可能会给你一个答案。</em></p><p id="a355" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><strong class="lb iu">指导未来的数据收集</strong></p><p id="1349" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it">——值得投资收藏的可能新变量是什么？</em></p><p id="bd27" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><strong class="lb iu">通知人类决策</strong></p><p id="6e1e" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> -通过预测原因的可视化为人类决策提供洞察力。</em></p><p id="61c5" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><strong class="lb iu">建立信任</strong></p><p id="8eeb" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> -如果解释与人类或专家的共同感知相匹配，它可以建立对模型的信任。</em></p></blockquote><p id="82a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我将介绍三种常见的解释工具，</p><ul class=""><li id="b043" class="ma mb it lb b lc ld lf lg li mc lm md lq me lu mf mg mh mi bi translated"><strong class="lb iu">可变重要性(基于树或通过排列)</strong></li><li id="7297" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated"><strong class="lb iu">部分依赖图</strong></li><li id="9cf1" class="ma mb it lb b lc mj lf mk li ml lm mm lq mn lu mf mg mh mi bi translated"><strong class="lb iu"> SHAP </strong></li></ul><p id="30f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP 不在这次 sklearn 更新中，但是我把它包括在列表中，因为它对模型的可解释性很重要。</p><blockquote class="nw nx ny"><p id="e044" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it">-</em>-<strong class="lb iu">-<em class="it">-</em>-</strong>-【变量重要性】-<em class="it">给出每个变量的‘重要性’量。</em> <strong class="lb iu"> <em class="it">每个变量都有代表重要性的单值，它们的绝对值没有任何实际用途</em> </strong> <em class="it">因为它们就像变量的存在对损失函数值的影响。</em></p><p id="db5a" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it">-</em>偏相关图<em class="it">给出变量变化对预测的影响程度。</em> <strong class="lb iu"> <em class="it">图的比例实际上对应于目标变量的比例，容易理解。</em> </strong> <em class="it">同样，</em> <strong class="lb iu"> <em class="it">我们可以检查曲线上的变量变化</em> </strong> <em class="it">，不是单个变量的值不像上面所说的变量重要性。</em></p><p id="7b6b" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it">-</em>【SHAP】<em class="it">给出</em> <strong class="lb iu"> <em class="it">每行上的每个变量对预测贡献了多少。</em></strong></p><p id="53db" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> -作为奖励，“</em>LIME”<em class="it">是另一种模型解释方法，它给出预测的行和列级分解。我不会在这里过多地谈论 LIME，但让我们只说 LIME 是 SHAP 的精简版(SHAP 需要时间来计算，特别是在内核 SHAP 的情况下。)参见</em> <a class="ae ky" href="https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/" rel="noopener ugc nofollow" target="_blank"> <em class="it">这篇才华横溢的帖子</em> </a> <em class="it">作者</em> Joshua Poduska <em class="it">更多莱姆和 SHAP 的对比。</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/eecd9ea2034817d1ed8eb53783b5369d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G6FHvzJPv2Zz-F75"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@jtzanno?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joao Tzanno</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="a15c" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">2.首先要做的是…</h1><p id="9c23" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">但是在深入到个体解释方法之前，我需要指出的是<strong class="lb iu">我们首先要做的是制造一个性能良好的模型</strong>,我们不能期望从糟糕的模型中获得正确的见解！这是因为每个解释逻辑都假设模型的预测足够好。</p><p id="6248" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，<strong class="lb iu">你不能指望模型解释取代 EDA </strong>。相反，它是为了更好的特征工程而支持和增强 EDA(回到第一章并回顾“<em class="lz">为什么可解释性很重要？</em>“！！)</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="3f5a" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">3.可变重要性-基于树的模型可变重要性</h1><p id="e308" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated"><em class="lz">“变量重要性”</em>给出每个变量的“重要性”数量。每个变量都有一个代表重要性的值。我们应该记住的另一个性质是<strong class="lb iu">它们的标度没有任何实际意义</strong>因为它们是变量的存在对损失函数值的影响量。</p><p id="bae2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于决策树的模型(决策树分类器、CART、随机森林、lightgbm 等。)有自己的可变重要性计算逻辑，基于通过节点分裂减少损失函数(<a class="ae ky" href="https://stats.stackexchange.com/questions/92419/relative-importance-of-a-set-of-predictors-in-a-random-forests-classification-in/92843#92843" rel="noopener ugc nofollow" target="_blank">参见此处</a>了解更多细节)，但是<strong class="lb iu">记住 GBDT 倾向于有多个选项来计算重要性</strong>，默认选项不是必要的损失函数减少。它可以是其他指标，如感兴趣的变量的分裂计数。</p><p id="e3a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">姑且称之为“<strong class="lb iu">基于树的模型变量重要性</strong>”由于模型特定的架构，基于树的模型重要性是可计算的，因此训练过程是在单个变量、离散决策上分割节点，并且很容易比较<em class="lz">进行</em>或<em class="lz">不进行</em>。</p><p id="cf63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，难道其他模型不能表现可变的重要性吗？答案是肯定的！这就是“<em class="lz">排列重要性”</em>的原因！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="c967" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">4.可变重要性—排列重要性</h1><p id="21d4" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">" P<em class="lz">er mutation importance "</em><strong class="lb iu"/>是<strong class="lb iu">与模型无关的变量重要性方法</strong>，这意味着它们不需要像决策树一样的单个变量相关的离散训练过程。他们是怎么做到的？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/d28fd668ce9de8777666ca1a4cf10bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XcgKHMAW20wLoohh-FV79w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Illustration of how to calculate permutation importance (<a class="ae ky" href="https://www.kaggle.com/dansbecker/permutation-importance" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/dansbecker/permutation-importance</a>)</figcaption></figure><p id="86b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上表中的变量名，假设我们想预测一个人 20 岁时的身高(第一列)，使用 10 岁时的数据(其他列)。</p><p id="fe82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我假设我们已经训练了一些模型，并且具有下降精度(下面的步骤 0)—同样，<strong class="lb iu"> </strong>如果没有下降模型，我们无法获得变量重要性。</p><blockquote class="nw nx ny"><p id="b598" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 0。成功做出一个好的预测模型。</em></p><p id="ec7b" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 1。排列重要性从随机排列单个列中的值开始，以准备一种“新的”数据集。</em></p><p id="e877" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 2。接下来使用“新”数据，使用预训练模型进行预测(不要使用“新”数据重新训练模型！).精度应该比原始数据的精度稍差，并且应该增加损失函数。注意损失函数增加。</em></p><p id="09c7" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 3。将数据恢复到原始顺序，重复相同的洗牌，并在下一列进行测量。</em></p><p id="a2dd" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 4。可选但常见的是，将所有变量中的重要性标准化为总计 1.0。</em></p><p id="10aa" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated"><em class="it"> 5。改变洗牌，我们可以多次计算一个变量的重要性。因此，我们可以计算排列重要性的平均值和标准差。</em></p></blockquote><p id="4499" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是使用 sci kit-learn 0.22 版中新函数<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html" rel="noopener ugc nofollow" target="_blank">permutation_importance</a></code>的示例代码。使用的数据集来自<a class="ae ky" href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data" rel="noopener ugc nofollow" target="_blank"> Kaggle 竞赛“纽约市出租车费用预测”</a>。代码的输出是基于树的变量重要性与排列重要性输出的比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/545107da712f50ace4b59354de43e5e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZ2UPfrS8gEThTGGXigugQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Tree-based vs. permutation importance. Find permutation importance has confidence interval.</figcaption></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="02bd" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">5.部分相关图</h1><p id="9c9d" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">变量重要性为每个变量给出一个重要性分数，这有助于了解哪个变量影响更大或更小。</p><p id="b403" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lz">【PDP】</em><strong class="lb iu">则给出了代表变量在哪个取值范围对最终预测影响有多大的曲线。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/6645428c5be68d0188169de5c860a4c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WA4iXHrkB-B1_yC_DRDkVg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Illustration of Partial Dependence Plot (PDP)</figcaption></figure><p id="d123" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在从原始数据表拟合模型后，有意地将想要获得 PDP 的变量值更改为特定量，并运行预测，重复预测以覆盖区间。</p><p id="ab0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PDP 可以通过 scikit-learn 版本 0.22 中的新函数<code class="fe lv lw lx ly b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html" rel="noopener ugc nofollow" target="_blank">plot_partial_dependence</a></code>实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/30a86e92107234f524c016d5b0362cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*-lgDlbx5D4DSooEYdxawaQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">1D partial dependence plots of lightgbm model prediction from NY taxi fare data</figcaption></figure><p id="247a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以存在<strong class="lb iu">双变量版本的 PDP。</strong>新的 scikit-learn 功能支持其中任何一种。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3a30793704a7025e30292abfa312291c.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*qdgojfRikptQoGHqQJncmA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">2D partial dependence plots of lightgbm model prediction from NY taxi fare data</figcaption></figure><p id="fd98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的 PDP 输出中，我们可以看到 PDP 的计算量更大，并且需要时间来运行，尤其是一个 2D PDP 甚至需要 13 秒。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="e2f1" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">6.沙普利附加解释(SHAP)</h1><p id="a5ee" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated"><em class="lz">【SHAP】</em>与其他方法论最重要的区别是，SHAP 赋予<strong class="lb iu">行&amp;变量级影响预测</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/ca5c0e368b7d5040288f05de8d202328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Ak25uBXHAKtlgGvHHYQDw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Illustration of SHAP</figcaption></figure><p id="4086" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在该图中，每个记录 ID 的预测值将被分解为<strong class="lb iu">“预测”=“平均预测”+“每个变量的 SHAP 值”</strong>。</p><p id="90f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，他们是如何做到的呢？SHAP 是基于<em class="lz">联盟博弈论</em>中的 Shapley 值方法。Shapley 值的本质是衡量联盟中每个成员对最终结果的贡献，保持贡献的总和等于最终结果。进一步讨论见<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/shapley.html" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="2edc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的数学机制太难描述了，我也不完全理解:)，但至少我们可以运行 API 来获得 SHAP 值，这要感谢<a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> python 库</a> <code class="fe lv lw lx ly b"><a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">shap</a></code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/bf7581e006c05d187c987a5b099df99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*alDfkRBTAOAc1Xk6UGKaKA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">How SHAP values look like.</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/7be922c2f356fa28e71aa74650caa286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M25-wjNpOgraSdAVzY_gQQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">SHAP: Visualize SHAP values to the first row data (prediction average 8.486 to first row prediction 5.86)</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/a157209f3f84ea80ba5fa9d4bb9d055f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WjtujIAEbyjAZo_meUxn7A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">SHAP: Variable importance-like plot (based on average of absolute SHAP value)</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/9e6085f7246a49baf64178b04fe65dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*uGdSJKZvSwdjQ_OIDc1KPg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">SHAP: PDP-like visualization</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/36e3197b6dcd2c03beea24ab8bae5182.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bvS29VtaJRxm2HH76ZnqTQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">SHAP: Each plot represents one data row, with SHAP value for each variable, along with red-blue as the magnitude of the original data.</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/b4805ab9891324ad51e516729fdd6abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eR46jV61xNGD7DrNGktROA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">SHAP: Plot to play around interactively (two axis have pull-down menu to change items to show)</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/fa5e3a5dba613e8feb20c0727e2e73d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KwtjjQ3LLrFgXjm_"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@lanipham?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Lan Pham</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="7ead" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">7.那么，用哪个呢？</h1><p id="0e97" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">我们看到了三种不同的模型可解释性输出:可变重要性、PDP 和 SHAP。它们都提供不同外观的输出。当我们想要解释的时候，我们如何选择其中之一呢？</p><h2 id="e535" class="os mw it bd mx ot ou dn nb ov ow dp nf li ox oy nh lm oz pa nj lq pb pc nl pd bi translated">a.SHAP 值可以用于其他任何事情。</h2><p id="5750" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">第一点是:</p><blockquote class="nw nx ny"><p id="0bb6" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated">从某种意义上说，SHAP 具有优势，因为他们提供最精细的输出。</p></blockquote><p id="f383" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">粒度输出可以汇总为粒度更小的输出，反之则不成立。这表明:</p><blockquote class="nw nx ny"><p id="9f03" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated">根据 SHAP 值，我们可以计算出可变重要性结果和 PDP 图:</p></blockquote><p id="a4dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">取每个变量的绝对 SHAP 值的平均值将是一种变量重要性，绘制变量值对同一变量的 SHAP 值是一种 PDP。</p><p id="1c6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/shap.html#examples-4" rel="noopener ugc nofollow" target="_blank">这个网页</a>给出了一个令人敬畏的列表，并解释了 SHAP 值的可能用途，甚至像<em class="lz">使用 SHAP 值进行聚类</em>。</p><h2 id="1550" class="os mw it bd mx ot ou dn nb ov ow dp nf li ox oy nh lm oz pa nj lq pb pc nl pd bi translated">b.那么，为什么人们不总是使用 SHAP 呢？</h2><p id="ddd9" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">SHAP 的一个缺点是它需要较长的计算时间。有两种类型的 SHAP，据报道<em class="lz">“kernel shap”</em>超级超级慢(参见上面示例代码中的注释；它慢了 40K 倍！！)，而另一种类型<em class="lz">“TreeSHAP”</em>则实现速度更快。然而，让我们记住一件事:</p><blockquote class="nw nx ny"><p id="66e8" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated">不幸的是，TreeSHAP 只适用于基于决策树的模型。</p></blockquote><p id="7797" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不使用 SHAP 的另一个原因是，你为什么想要模型解释，</p><blockquote class="nw nx ny"><p id="4665" class="kz la lz lb b lc ld ju le lf lg jx lh nz lj lk ll oa ln lo lp ob lr ls lt lu im bi translated">获取行和列级别的 SHAP 值可能会矫枉过正，而且不是实现目标的直接方法。</p></blockquote><h2 id="8fab" class="os mw it bd mx ot ou dn nb ov ow dp nf li ox oy nh lm oz pa nj lq pb pc nl pd bi translated">c.当可变重要性足够时</h2><p id="d01b" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">在某些情况下，可变重要性就足够了，我们不需要 PDP 或 SHAP。</p><ul class=""><li id="4f0e" class="ma mb it lb b lc ld lf lg li mc lm md lq me lu mf mg mh mi bi translated"><strong class="lb iu"> <em class="lz">当我们希望领域专家对模型合理性进行嗅探测试时。</em>T3】</strong></li></ul><p id="2dd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可变重要性给出其对预测的重要性的单一分数。这可以让非数据专家的领域专家确保模型是合理的。他们只能从每个变量的重要性的条形图中进行判断，如果不常见的变量变高，这可能是识别模型错误或数据泄漏的提示。</p><ul class=""><li id="9fba" class="ma mb it lb b lc ld lf lg li mc lm md lq me lu mf mg mh mi bi translated"><strong class="lb iu"> <em class="lz">当我们要对变量重要性的顺序做变量选择时。</em> </strong></li></ul><p id="f073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量选择在建模中非常有用，可以用更简单的方式解释模型，消除模型噪声以提高精度，避免共线性等。</p><p id="69f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于可变重要性输出，我们可以选择具有最高重要性的原始变量集的子集。</p><p id="5d58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的纽约出租车费用示例中，很明显，乘客数量与费用金额无关，这从常识来看是有道理的，因为纽约出租车费用公式与乘客数量无关(虽然乘客多的出租车可能比单人出租车走得更远，但这对于我们从上下车地点获得的信息来说并不是新信息。)</p><h2 id="8189" class="os mw it bd mx ot ou dn nb ov ow dp nf li ox oy nh lm oz pa nj lq pb pc nl pd bi translated">d.PDP 够用的时候。</h2><p id="a1e9" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">此外，在某些情况下，我们想要的不仅仅是可变的重要性，但是 PDP 就足够了，SHAP 也是多余的。</p><ul class=""><li id="f855" class="ma mb it lb b lc ld lf lg li mc lm md lq me lu mf mg mh mi bi translated"><strong class="lb iu"> <em class="lz">当我们知道哪个变量是重要的，而我们只想挖掘“如何”时。</em>T11】</strong></li></ul><p id="56d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过变量重要性研究，我们可以知道哪个变量使模型具有预测性，但接下来我们很自然地开始想知道它是如何做到的，即重要变量的哪个范围使预测更高或更低。</p><p id="a0f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的纽约出租车费用的例子中，我们了解到的是，在经度或纬度的终点，而不是中间让乘客上车或下车的出租车应该有更高的收益——曼哈顿中间的乘客很可能是短途乘客。</p><p id="d18d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这里，自然要想出一个新的特征工程思想来取取送地点之间的距离，而不仅仅是那两个单独的绝对位置。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/2382a3eaf11978a042d7d31c0e197415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-q5vbjXlATYbNauF"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Priscilla Du Preez</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="85a8" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">8.结论</h1><p id="93c1" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">模型可解释性在调试、特征工程、指导未来的数据收集、人类决策和建立信任中是有用的。</p><p id="485c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经介绍了三种类型的可解释性方法，可变重要性(基于树和排列)，部分依赖图(PDP)和 SHAP。</p><p id="e918" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然 SHAP 是了解模型可解释性的最细粒度的方法，并且可以检索类似于其他方法的输出，但是运行会花费时间并且变得过度。</p><p id="5082" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们数据科学家应该首先从为什么我们想知道模型的解释开始，并使用最符合目的的方法。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="1ea4" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">9.参考</h1><p id="5794" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html" rel="noopener ugc nofollow" target="_blank">sci kit 发布亮点-学习 0.22 </a></p><p id="1906" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kaggle 课程<a class="ae ky" href="https://www.kaggle.com/learn/machine-learning-explainability" rel="noopener ugc nofollow" target="_blank">“机器学习可解释性”</a></p><p id="d27f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank"> Christoph Molnar“可解释的机器学习——让黑盒模型变得可解释的指南。”</a></p><p id="f078" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/" rel="noopener ugc nofollow" target="_blank">Joshua Poduska“SHAP 和 LIME Python 库:第 1 部分——伟大的解释者，两者都有优点和缺点”</a></p></div></div>    
</body>
</html>