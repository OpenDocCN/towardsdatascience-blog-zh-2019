# ç”¨ PyTorch æ„å»ºç¥ç»ç½‘ç»œ

> åŸæ–‡ï¼š<https://towardsdatascience.com/building-neural-network-using-pytorch-84f6e75f9a?source=collection_archive---------2----------------------->

â€œè®¡ç®—æœºèƒ½å¦æ€è€ƒçš„é—®é¢˜å¹¶ä¸æ¯”æ½œè‰‡èƒ½å¦æ¸¸æ³³çš„é—®é¢˜æ›´æœ‰è¶£ã€‚â€
â€• **åŸƒå¾·æ ¼Â·wÂ·è¿ªæ°æ–¯ç‰¹æ‹‰**

![](img/566411b1e847aa9e6766e37b2f055cde.png)

source: [here](https://deeplizard.com/learn/video/k4jY9L8H89U)

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ PyTorch ä»å¤´å¼€å§‹å®ç°ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚æˆ‘æ­£åœ¨åˆ†äº«æˆ‘ä»æœ€è¿‘çš„ facebook-udacity å¥–å­¦é‡‘æŒ‘æˆ˜é¡¹ç›®ä¸­å­¦åˆ°çš„ä¸œè¥¿ã€‚æœ¬æ•™ç¨‹å‡è®¾ä½ äº‹å…ˆäº†è§£ç¥ç»ç½‘ç»œå¦‚ä½•å·¥ä½œã€‚

è™½ç„¶æœ‰å¾ˆå¤šåº“å¯ä»¥ç”¨äºæ·±åº¦å­¦ä¹ ï¼Œä½†æˆ‘æœ€å–œæ¬¢ PyTorchã€‚ä½œä¸ºä¸€å python ç¨‹åºå‘˜ï¼Œæˆ‘å–œæ¬¢ PyTorch çš„ python è¡Œä¸ºæ˜¯èƒŒåçš„åŸå› ä¹‹ä¸€ã€‚å®ƒä¸»è¦ä½¿ç”¨ python çš„é£æ ¼å’ŒåŠŸèƒ½ï¼Œæ˜“äºç†è§£å’Œä½¿ç”¨ã€‚

**py torch çš„æ ¸å¿ƒæä¾›äº†ä¸¤ä¸ªä¸»è¦ç‰¹æ€§:**

*   n ç»´å¼ é‡ï¼Œç±»ä¼¼äº numpyï¼Œä½†å¯ä»¥åœ¨ GPU ä¸Šè¿è¡Œ
*   ç”¨äºå»ºç«‹å’Œè®­ç»ƒç¥ç»ç½‘ç»œçš„è‡ªåŠ¨å¾®åˆ†

**ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ**

ç¥ç»ç½‘ç»œæ˜¯ä¸€ç»„ç®—æ³•ï¼Œå¤§è‡´æ¨¡ä»¿äººè„‘ï¼Œç”¨äºè¯†åˆ«æ¨¡å¼ã€‚ç½‘ç»œæ˜¯ç”±è¿‘ä¼¼ç¥ç»å…ƒçš„å•ä¸ªéƒ¨åˆ†æ„æˆçš„ï¼Œé€šå¸¸ç§°ä¸ºå•å…ƒæˆ–ç®€ç§°ä¸ºâ€œ**ç¥ç»å…ƒ**â€æ¯ä¸ªå•å…ƒéƒ½æœ‰ä¸€äº›åŠ æƒè¾“å…¥ã€‚è¿™äº›åŠ æƒè¾“å…¥ç›¸åŠ åœ¨ä¸€èµ·(çº¿æ€§ç»„åˆ)ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªæ¿€æ´»å‡½æ•°å¾—åˆ°å•å…ƒçš„è¾“å‡ºã€‚

## ç¥ç»ç½‘ç»œä¸­çš„èŠ‚ç‚¹ç±»å‹:

1.  è¾“å…¥å•å…ƒâ€”å‘ç½‘ç»œæä¾›æ¥è‡ªå¤–éƒ¨ä¸–ç•Œçš„ä¿¡æ¯ï¼Œç»Ÿç§°ä¸ºâ€œè¾“å…¥å±‚â€ã€‚è¿™äº›èŠ‚ç‚¹ä¸æ‰§è¡Œä»»ä½•è®¡ç®—ï¼Œå®ƒä»¬åªæ˜¯å°†ä¿¡æ¯ä¼ é€’ç»™éšè—èŠ‚ç‚¹ã€‚
2.  éšè—å•å…ƒâ€”è¿™äº›èŠ‚ç‚¹ä¸å¤–ç•Œæ²¡æœ‰ä»»ä½•ç›´æ¥çš„è”ç³»ã€‚å®ƒä»¬æ‰§è¡Œè®¡ç®—å¹¶å°†ä¿¡æ¯ä»è¾“å…¥èŠ‚ç‚¹ä¼ è¾“åˆ°è¾“å‡ºèŠ‚ç‚¹ã€‚éšè—èŠ‚ç‚¹çš„é›†åˆå½¢æˆäº†â€œéšè—å±‚â€ã€‚è™½ç„¶å‰é¦ˆç½‘ç»œåªæœ‰ä¸€ä¸ªè¾“å…¥å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼Œä½†å®ƒå¯ä»¥æœ‰é›¶ä¸ªæˆ–å¤šä¸ªéšè—å±‚ã€‚
3.  è¾“å‡ºå•å…ƒ-è¾“å‡ºèŠ‚ç‚¹ç»Ÿç§°ä¸ºâ€œè¾“å‡ºå±‚â€ï¼Œè´Ÿè´£è®¡ç®—å’Œå°†ä¿¡æ¯ä»ç½‘ç»œä¼ è¾“åˆ°å¤–éƒ¨ä¸–ç•Œã€‚

æ¯å±‚åŒ…æ‹¬ä¸€ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹ã€‚

**æ„å»ºç¥ç»ç½‘ç»œ**

PyTorch æä¾›äº†ä¸€ä¸ªæ¨¡å—`nn`,ä½¿å¾—æ„å»ºç½‘ç»œæ›´åŠ ç®€å•ã€‚æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ç”¨`784 inputs`ã€`256 hidden units`ã€`10 output units`å’Œ`softmax output`æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œã€‚

```
from torch import nnclass Network(nn.Module):
    def __init__(self):
        super().__init__()

        # Inputs to hidden layer linear transformation
        self.hidden = nn.Linear(784, 256)
        # Output layer, 10 units - one for each digit
        self.output = nn.Linear(256, 10)

        # Define sigmoid activation and softmax output 
        self.sigmoid = nn.Sigmoid()
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        # Pass the input tensor through each of our operations
        x = self.hidden(x)
        x = self.sigmoid(x)
        x = self.output(x)
        x = self.softmax(x)

        return x
```

> æ³¨:`**softmax**` **å‡½æ•°ï¼Œ**ä¹Ÿç§°ä¸º`**softargmax**`æˆ–`**normalized**` `**exponential function**`æ˜¯ä¸€ä¸ªä»¥ *K* å®æ•°çš„å‘é‡ä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶å½’ä¸€åŒ–ä¸ºç”± *K* ä¸ªæ¦‚ç‡ç»„æˆçš„[æ¦‚ç‡åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Probability_distribution)çš„å‡½æ•°ã€‚

![](img/04cd3c8c6424a8cb8cf065a0c5a5812c.png)

image from google

è®©æˆ‘ä»¬ä¸€è¡Œä¸€è¡Œåœ°è¿‡ä¸€éã€‚

```
**class** Network(nn.Module):
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç»§æ‰¿äº†`nn.Module`ã€‚ä¸`super().__init__()`ç»“åˆï¼Œè¿™åˆ›å»ºäº†ä¸€ä¸ªè·Ÿè¸ªæ¶æ„çš„ç±»ï¼Œå¹¶æä¾›äº†è®¸å¤šæœ‰ç”¨çš„æ–¹æ³•å’Œå±æ€§ã€‚å½“ä½ ä¸ºä½ çš„ç½‘ç»œåˆ›å»ºä¸€ä¸ªç±»æ—¶ï¼Œä»`nn.Module`ç»§æ‰¿æ˜¯å¼ºåˆ¶æ€§çš„ã€‚ç±»æœ¬èº«çš„åç§°å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿ã€‚

```
self.hidden **=** nn.Linear(784, 256)
```

è¿™ä¸€è¡Œåˆ›å»ºäº†ä¸€ä¸ªç”¨äºçº¿æ€§å˜æ¢çš„æ¨¡å—ï¼Œğ‘¥ğ–+ğ‘xW+bï¼Œæœ‰ 784 ä¸ªè¾“å…¥å’Œ 256 ä¸ªè¾“å‡ºï¼Œå¹¶å°†å…¶åˆ†é…ç»™`self.hidden`ã€‚è¯¥æ¨¡å—è‡ªåŠ¨åˆ›å»ºæˆ‘ä»¬å°†åœ¨`forward`æ–¹æ³•ä¸­ä½¿ç”¨çš„æƒé‡å’Œåå·®å¼ é‡ã€‚ä¸€æ—¦ä½¿ç”¨`net.hidden.weight`å’Œ`net.hidden.bias`åˆ›å»ºäº†ç½‘ç»œ(`net`ï¼Œæ‚¨å°±å¯ä»¥è®¿é—®æƒé‡å’Œåå·®å¼ é‡ã€‚

```
self.output **=** nn.Linear(256, 10)
```

ç±»ä¼¼åœ°ï¼Œè¿™åˆ›å»ºäº†å¦ä¸€ä¸ªå…·æœ‰ 256 ä¸ªè¾“å…¥å’Œ 10 ä¸ªè¾“å‡ºçš„çº¿æ€§è½¬æ¢ã€‚

```
self.sigmoid **=** nn.Sigmoid()
self.softmax **=** nn.Softmax(dim**=**1)
```

è¿™é‡Œæˆ‘å®šä¹‰äº† sigmoid æ¿€æ´»å’Œ softmax è¾“å‡ºçš„æ“ä½œã€‚åœ¨`nn.Softmax(dim=1)`ä¸­è®¾ç½®`dim=1`è®¡ç®—å„åˆ—çš„ softmaxã€‚

```
**def** forward(self, x):
```

ç”¨`nn.Module`åˆ›å»ºçš„ PyTorch ç½‘ç»œå¿…é¡»å®šä¹‰ä¸€ä¸ª`forward`æ–¹æ³•ã€‚å®ƒæ¥å—ä¸€ä¸ªå¼ é‡`x`å¹¶é€šè¿‡æ‚¨åœ¨`__init__`æ–¹æ³•ä¸­å®šä¹‰çš„æ“ä½œä¼ é€’å®ƒã€‚

```
x **=** self.hidden(x)
x **=** self.sigmoid(x)
x **=** self.output(x)
x **=** self.softmax(x)
```

è¿™é‡Œï¼Œè¾“å…¥å¼ é‡`x`é€šè¿‡æ¯ä¸ªæ“ä½œï¼Œå¹¶é‡æ–°åˆ†é…ç»™`x`ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¾“å…¥å¼ é‡ç»è¿‡éšè—å±‚ï¼Œç„¶åæ˜¯ sigmoid å‡½æ•°ï¼Œç„¶åæ˜¯è¾“å‡ºå±‚ï¼Œæœ€åæ˜¯ softmax å‡½æ•°ã€‚åªè¦æ“ä½œçš„è¾“å…¥å’Œè¾“å‡ºä¸æ‚¨æƒ³è¦æ„å»ºçš„ç½‘ç»œä½“ç³»ç»“æ„ç›¸åŒ¹é…ï¼Œæ‚¨åœ¨è¿™é‡Œç»™å˜é‡å–ä»€ä¹ˆåå­—å¹¶ä¸é‡è¦ã€‚åœ¨`__init__`æ–¹æ³•ä¸­å®šä¹‰äº‹ç‰©çš„é¡ºåºå¹¶ä¸é‡è¦ï¼Œä½†æ˜¯æ‚¨éœ€è¦åœ¨`forward`æ–¹æ³•ä¸­å¯¹æ“ä½œè¿›è¡Œæ­£ç¡®æ’åºã€‚

```
# Create the network and look at it's text representation
model = Network()
model
```

**ä½¿ç”¨**æ„å»ºç¥ç»ç½‘ç»œ`**nn.Sequential**`

PyTorch æä¾›äº†ä¸€ç§æ–¹ä¾¿çš„æ–¹æ³•æ¥æ„å»ºè¿™æ ·çš„ç½‘ç»œï¼Œå…¶ä¸­å¼ é‡é€šè¿‡è¿ç®—é¡ºåºä¼ é€’ï¼Œ`nn.Sequential` ( [æ–‡æ¡£](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential))ã€‚ç”¨å®ƒæ¥æ„å»ºç­‰æ•ˆç½‘ç»œ:

```
# Hyperparameters for our network
input_size = 784
hidden_sizes = [128, 64]
output_size = 10# Build a feed-forward network
model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),
                      nn.ReLU(),
                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),
                      nn.ReLU(),
                      nn.Linear(hidden_sizes[1], output_size),
                      nn.Softmax(dim=1))
print(model)
```

> è¿™é‡Œæˆ‘ä»¬çš„å‹å·å’Œä¹‹å‰ä¸€æ ·: `784 input units`ã€`a hidden layer with 128 units`ã€ `ReLU activation`ã€`64 unit hidden layer`ï¼Œå†æ¥ä¸€ä¸ª `ReLU`ï¼Œç„¶åæ˜¯`output layer with 10 units`ï¼Œå†æ¥ä¸€ä¸ª`softmax output`ã€‚

æ‚¨è¿˜å¯ä»¥ä¼ å…¥ä¸€ä¸ª`OrderedDict`æ¥å‘½åå„ä¸ªå±‚å’Œæ“ä½œï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¢é‡æ•´æ•°ã€‚æ³¨æ„å­—å…¸é”®å¿…é¡»æ˜¯å”¯ä¸€çš„ï¼Œæ‰€ä»¥*æ¯ä¸ªæ“ä½œå¿…é¡»æœ‰ä¸åŒçš„åç§°*ã€‚

```
from collections import OrderedDict
model = nn.Sequential(OrderedDict([
                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),
                      ('relu1', nn.ReLU()),
                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),
                      ('relu2', nn.ReLU()),
                      ('output', nn.Linear(hidden_sizes[1], output_size)),
                      ('softmax', nn.Softmax(dim=1))])) model
```

ç°åœ¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ•´æ•°æˆ–åç§°æ¥è®¿é—®å›¾å±‚

```
print(model[0])
print(model.fc1)
```

ä»Šå¤©åˆ°æ­¤ä¸ºæ­¢ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œã€‚ä½ ä¼šåœ¨è¿™é‡Œæ‰¾åˆ°å®ƒã€‚

æˆ‘ä»¬éšæ—¶æ¬¢è¿æ‚¨æå‡ºä»»ä½•å»ºè®¾æ€§çš„æ‰¹è¯„æˆ–åé¦ˆã€‚