<html>
<head>
<title>Heart of Darkness: Logistic Regression vs. Random Forest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">黑暗之心:逻辑回归与随机森林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/heart-of-darkness-logistic-regression-vs-random-forest-1db7b0aa1711?source=collection_archive---------10-----------------------#2019-02-08">https://towardsdatascience.com/heart-of-darkness-logistic-regression-vs-random-forest-1db7b0aa1711?source=collection_archive---------10-----------------------#2019-02-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/61d8b30e5eacd33aa203383e09cd440b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MuWBcMXb6yifn4ZJIS7aeA.png"/></div></div></figure><p id="04c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从 Lambda 学校开始学习数据科学已经 9 周了。本周的挑战涉及一个多类分类问题，以卡格竞赛的形式呈现，只涉及我们班的学生:DS-1。</p><p id="172c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们的任务是结合数字和分类变量来预测坦桑尼亚的哪些水泵有故障:</p><h1 id="b9bd" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">坦桑尼亚水点挑战:</h1><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/7cadaf9ac9acdcfe1485e4ed1fe04d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*QN1MQpKsqGSiql3x.jpg"/></div></figure><p id="1e57" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">目标变量:'状态 _ 组'</strong></p><ol class=""><li id="3c65" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated">功能的</li></ol><p id="f807" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.功能需求修复</p><p id="4a41" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.无功能</p><p id="f025" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">特征变量</strong></p><p id="5f55" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="mi">数字</em> </strong>:</p><p id="6700" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">身份证明（identification）</p><p id="f3b1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">金额 _tsh</p><p id="1fd5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">日期 _ 记录</p><p id="1e32" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">gps _ 高度</p><p id="b73f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">经度</p><p id="4540" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">纬度</p><p id="6d83" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">区域代码</p><p id="4c43" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">建造年份</p><p id="2321" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">建造年份</p><p id="ff8f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人口</p><p id="b86a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="mi"/></strong>:</p><p id="2967" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">量</p><p id="66c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">投资者</p><p id="219e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">安装程序</p><p id="8a38" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">wpt_name</p><p id="b88a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数量 _ 私有</p><p id="7f4d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">盆地</p><p id="563b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">子村</p><p id="4df0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">地区</p><p id="35c8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大于胎龄儿</p><p id="0758" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">病房</p><p id="2ec8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">公开会议</p><p id="d0e6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">录制者</p><p id="bcca" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">方案 _ 管理</p><p id="d3eb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">方案名称</p><p id="9efa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">许可证</p><p id="a11e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提取类型</p><p id="b459" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提取类型组</p><p id="dff6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提取类型类</p><p id="f09e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">管理</p><p id="e8a0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">管理 _ 集团</p><p id="fc13" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支付</p><p id="6d6a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">付款类型</p><p id="87c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">水质</p><p id="df71" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">质量 _ 组</p><p id="7427" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数量 _ 组</p><p id="28e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源</p><p id="42e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源类型</p><p id="f530" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源 _ 类别</p><p id="6bae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">水点类型</p><p id="1a83" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">水点类型组</p><p id="8b3b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果有读者想接受挑战，你可以在这里找到所有相关数据:</p><ol class=""><li id="420b" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated"><a class="ae mj" href="https://raw.githubusercontent.com/Captmoonshot/kaggle_waterpumps_2/master/train_features.csv" rel="noopener ugc nofollow" target="_blank">训练集</a></li></ol><p id="3570" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.<a class="ae mj" href="https://raw.githubusercontent.com/Captmoonshot/kaggle_waterpumps_2/master/train_labels.csv" rel="noopener ugc nofollow" target="_blank">培训标签</a></p><p id="85cb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.<a class="ae mj" href="https://raw.githubusercontent.com/Captmoonshot/kaggle_waterpumps_2/master/test_features.csv" rel="noopener ugc nofollow" target="_blank">测试设置</a></p><p id="8f52" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">训练集有 59400 行和 40 列——在数据科学世界中，这是一个相对较小的数据集，但对于初学者来说仍然是相当大的(在维度方面)。</p><p id="4dc5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们启动 Jupyter 笔记本并加载数据:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="ee44" class="mp kx iq ml b gy mq mr l ms mt"># Our usual trio of imports</span><span id="d4c7" class="mp kx iq ml b gy mu mr l ms mt">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="d64f" class="mp kx iq ml b gy mu mr l ms mt">df_train = pd.read_csv('train_features.csv')<br/>df_test = pd.read_csv('test_features.csv')<br/>train_labels = pd.read_csv('train_labels.csv')</span><span id="9fab" class="mp kx iq ml b gy mu mr l ms mt">df_train.head()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/b7180fb022f2010dc4d7bf6e3b666f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BcX19UFgyYgSSh6jlKqD9Q.jpeg"/></div></div></figure><p id="890a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">作为 Kaggle 挑战赛的参赛者，需要记住和做的最重要的事情之一是清理包括训练集和测试集在内的数据集。主要流程如下:</p><ol class=""><li id="a955" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated">使用我们的一个奇怪的技巧连接训练集和测试集。</li><li id="9c33" class="lz ma iq ka b kb mw kf mx kj my kn mz kr na kv me mf mg mh bi translated">清理数据:丢弃 NaNs、插值、创建新变量等。</li><li id="c9cc" class="lz ma iq ka b kb mw kf mx kj my kn mz kr na kv me mf mg mh bi translated">拆分训练集和测试集</li><li id="ebdd" class="lz ma iq ka b kb mw kf mx kj my kn mz kr na kv me mf mg mh bi translated">在训练集上训练你选择的机器学习模型</li><li id="bb7c" class="lz ma iq ka b kb mw kf mx kj my kn mz kr na kv me mf mg mh bi translated">对您之前分离出来的测试集进行预测</li></ol><p id="8778" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们的<strong class="ka ir">一招</strong>:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="0e6c" class="mp kx iq ml b gy mq mr l ms mt">df_train['training_set'] = True<br/>df_test['training_set'] = False</span><span id="5c97" class="mp kx iq ml b gy mu mr l ms mt">df_full = pd.concat([df_train, df_test])</span><span id="755d" class="mp kx iq ml b gy mu mr l ms mt">df_full.shape</span></pre><p id="8294" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">组合数据集(df_full)应该有 73758 行和 41 列，其中包括我们刚刚创建的“training_set”列。我们这样做的原因是为了确保模型被训练的数据在<strong class="ka ir">形式</strong>中与测试集相同。否则，如果测试集在某些方面与训练集不同，例如逻辑的系数就没有意义，更不用说预测了。由于很难跟踪我们对训练集所做的一切，我们不妨一石二鸟，从而保证它们的相同性质。</p><p id="150c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将在这个集合上使用逻辑回归和随机森林分类器，但在此之前，我们还需要考虑其他一些事情。</p><blockquote class="nb nc nd"><p id="880b" class="jy jz mi ka b kb kc kd ke kf kg kh ki ne kk kl km nf ko kp kq ng ks kt ku kv ij bi translated">我并不惊讶…</p></blockquote><p id="3d47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">内特·迪亚兹</p><p id="8b8a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有时生活给你正确的彩票号码，有时给你柠檬。但是当生活感觉像虐待狂时，它会给你坦桑尼亚水点挑战。让这一挑战变得格外严峻的是不平衡的数据:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="9945" class="mp kx iq ml b gy mq mr l ms mt">train_labels['status_group'].value_counts(normalize=True)</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/b84902a42d35062954c3a5a6b8c6009a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vVbizyFha_IQGUzyE6Cw5w.jpeg"/></div></div></figure><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="99ac" class="mp kx iq ml b gy mq mr l ms mt">import seaborn as sns</span><span id="2de5" class="mp kx iq ml b gy mu mr l ms mt">fig, ax = plt.subplots(figsize=(14, 8))<br/>sns.countplot(x='status_group', data=train_labels, palette='hls')</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/3837fb769b28398498bf9d0ee256d79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lPe50gqyoXdY4dTmC0YM0Q.png"/></div></div></figure><p id="2ce9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">目标变量的“功能性需求修复”类别仅占整个集合的 7%左右。这意味着无论你最终使用什么算法，它都可能比这个算法更好地学习其他两个平衡类。这就是数据科学:斗争是真实的。</p><h2 id="4e6e" class="mp kx iq bd ky nj nk dn lc nl nm dp lg kj nn no lk kn np nq lo kr nr ns ls nt bi translated">回到正题</h2><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e468aae75695cad2225c03bf298b24af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*IXdes5tYC01fUkH5Z5J0WA.jpeg"/></div><figcaption class="nv nw gj gh gi nx ny bd b be z dk">meme sponsored by fakedoors.com</figcaption></figure><p id="609d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们要做的第一件事是为 waterpoints 创建一个“年龄”变量，因为这似乎非常相关。</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="c3f1" class="mp kx iq ml b gy mq mr l ms mt">df_full['date_recorded'] = pd.to_datetime(df_full['date_recorded'])</span><span id="d759" class="mp kx iq ml b gy mu mr l ms mt">df_full['date_recorded'] = df_full['date_recorded'].dt.year</span><span id="a047" class="mp kx iq ml b gy mu mr l ms mt"># Replacing the NaN value with the mode - this would turn out to be <br/># less effective than I thought</span><span id="78a9" class="mp kx iq ml b gy mu mr l ms mt">df_full['construction_year'] = df_full['construction_year'].replace(0, 1986)</span><span id="4c09" class="mp kx iq ml b gy mu mr l ms mt">df_full['age'] = np.abs(df_full['date_recorded'] - df_full['construction_year'])</span><span id="d171" class="mp kx iq ml b gy mu mr l ms mt"># We now have an 'age' column indicating the age of the waterpoint #relative to its 'construction_year'</span></pre><p id="480a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">“人口”变量也具有高度右偏的分布，因此我们也要改变这种情况:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="413e" class="mp kx iq ml b gy mq mr l ms mt">df_full['population'] = df_full['population'].replace(0, 1)<br/>df_full['population_logged'] = np.log(df_full['population'])</span></pre><p id="61bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">“amount_tsh”中的零也可能是 NaNs，因此我们将做一些极端的事情，将其简化为 0 和 1:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="0401" class="mp kx iq ml b gy mq mr l ms mt">amount_tsh_encoded = []</span><span id="34ed" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['amount_tsh']:<br/>    if row == 0:<br/>        amount_tsh_encoded.append(0)<br/>    else:<br/>        amount_tsh_encoded.append(1)<br/>        <br/>df_full['amount_tsh_encoded'] = amount_tsh_encoded</span><span id="2bd0" class="mp kx iq ml b gy mu mr l ms mt"># And drop the old variables:</span><span id="a8b1" class="mp kx iq ml b gy mu mr l ms mt">df_full.drop(['date_recorded', 'construction_year', 'population',<br/>             'amount_tsh', 'num_private'], axis=1, inplace=True)</span></pre><p id="d520" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此时，您可以只分离出 df_full 数据帧的数字特征，并通过以下方式对其运行分类器:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="a070" class="mp kx iq ml b gy mq mr l ms mt">df_full_num = df_full.select_dtypes(include=['number']).copy()</span></pre><p id="817d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们从上周学到的最重要的一点，也是让我记忆犹新的一点，就是尽可能快地提出一个基线模型的想法。我们需要某种参考点来迭代我们的模型性能。因此，对于像我们这样的分类问题，我们可以使用我们的主要类别“功能”作为我们的基线。</p><p id="770c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">重要的是要记住，只有当机器学习模型能够在预测方面击败多数分类器时，它才能开始提供优于人类学习的好处。</p><p id="8dd4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们在 df_full_num 上运行逻辑回归，我们应该得到大约 54%的准确率，这是多数类给我们的。</p><p id="81aa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此时对我来说最重要的是不要气馁。</p><p id="6eb4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们将只研究分类变量。对于大多数分类特征，我们将采取极端简化的步骤，将它们转换成二进制变量。因为它们中的许多包含一个占主导地位的类别，其余的只占总数的一小部分…本质上是一种长尾分布。</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="1c17" class="mp kx iq ml b gy mq mr l ms mt">df_full['funder'] = df_full['funder'].fillna(df_full['funder'].mode()[0])<br/>df_full['subvillage'] = df_full['subvillage'].fillna(df_full['subvillage'].mode()[0])<br/>df_full['public_meeting'] = df_full['public_meeting'].fillna(df_full['public_meeting'].mode()[0])<br/>df_full['permit'].fillna(df_full['permit'].describe().top, inplace=True)</span></pre><p id="ff74" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">简化分类变量的例子:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="40f6" class="mp kx iq ml b gy mq mr l ms mt">funder_cleaned = []</span><span id="5820" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['funder']:<br/>    if row == 'Government Of Tanzania':<br/>        funder_cleaned.append('Tanzania')<br/>    else:<br/>        funder_cleaned.append('Other')<br/>        <br/>df_full['funder_cleaned'] = funder_cleaned</span></pre><p id="2e5e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们对几乎每一个分类特征都做同样的事情。</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="be97" class="mp kx iq ml b gy mq mr l ms mt">installer_cleaned = []</span><span id="a49c" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['installer']:<br/>    if row == 'DWE':<br/>        installer_cleaned.append('DWE')<br/>    else:<br/>        installer_cleaned.append('Other')<br/>        <br/>df_full['installer_cleaned'] = installer_cleaned</span><span id="6214" class="mp kx iq ml b gy mu mr l ms mt">scheme_management_cleaned = []</span><span id="cf7b" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['scheme_management']:<br/>    if row == 'VWC':<br/>        scheme_management_cleaned.append('VWC')<br/>    else:<br/>        scheme_management_cleaned.append('Other')<br/>        <br/>df_full['scheme_management_cleaned'] = scheme_management_cleaned</span><span id="3503" class="mp kx iq ml b gy mu mr l ms mt">extraction_type_cleaned = []</span><span id="d682" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['extraction_type']:<br/>    if row == 'gravity':<br/>        extraction_type_cleaned.append('gravity')<br/>    else:<br/>        extraction_type_cleaned.append('other')<br/>    <br/>df_full['extraction_type_cleaned'] = extraction_type_cleaned</span><span id="8815" class="mp kx iq ml b gy mu mr l ms mt">management_cleaned = []</span><span id="58c7" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['management']:<br/>    if row == 'vwc':<br/>        management_cleaned.append('vwc')<br/>    else:<br/>        management_cleaned.append('other')<br/>    <br/>df_full['management_cleaned'] = management_cleaned</span><span id="e554" class="mp kx iq ml b gy mu mr l ms mt">management_group_cleaned = []</span><span id="a17e" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['management_group']:<br/>    if row == 'user-group':<br/>        management_group_cleaned.append('user-group')<br/>    else:<br/>        management_group_cleaned.append('other')<br/>        <br/>df_full['management_group_cleaned'] = management_group_cleaned</span><span id="19c4" class="mp kx iq ml b gy mu mr l ms mt">payment_cleaned = []</span><span id="490a" class="mp kx iq ml b gy mu mr l ms mt">for row in df_full['payment']:<br/>    if row == 'never pay':<br/>        payment_cleaned.append('never pay')<br/>    else:<br/>        payment_cleaned.append('other')<br/>        <br/>df_full['payment_cleaned'] = payment_cleaned<br/></span><span id="98fc" class="mp kx iq ml b gy mu mr l ms mt"># I'm going to skip the other variables for the sake of staying #awake</span></pre><p id="70d4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这个漫长过程的最后，我们必须放弃我们的旧变量:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="69fc" class="mp kx iq ml b gy mq mr l ms mt">drop_list = ['wpt_name', 'basin', 'subvillage', 'funder',<br/>             'installer', 'scheme_management', 'permit', 'public_meeting',<br/>             'lga', 'ward', 'recorded_by', 'region', 'scheme_name', 'extraction_type',<br/>             'extraction_type_group', 'extraction_type_class', 'management',<br/>             'management_group','payment', 'payment_type', 'water_quality',<br/>             'quality_group', 'quantity', 'quantity_group','source', 'source_class',<br/>             'source_type', 'waterpoint_type', 'waterpoint_type_group']</span><span id="7c21" class="mp kx iq ml b gy mu mr l ms mt">df_full.drop(drop_list, axis=1, inplace=True)</span></pre><p id="8448" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们可以把它们变成虚拟变量。虽然大多数其他人可能会选择使用某种类别编码器，但这些变量不是有序的——这意味着，例如，重力的“提取类型”和其他类型的提取之间没有内在的可测量的距离。虽然它可能不会在预测方面产生很大的差异，但我相信如果我们出于分析原因使用逻辑回归，它会产生很大的差异。换句话说，从序数拟合中学习到的系数可能是不同的。</p><p id="de86" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们用熊猫做假人:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="caf5" class="mp kx iq ml b gy mq mr l ms mt">dummy_columns=['funder_cleaned', 'installer_cleaned', 'scheme_management_cleaned', 'extraction_type_cleaned',<br/>        'management_cleaned', 'management_group_cleaned', 'payment_cleaned', 'water_quality_cleaned',<br/>        'quality_group_cleaned', 'quantity_cleaned', 'source_cleaned', 'source_class_cleaned',<br/>        'waterpoint_type_cleaned']</span><span id="f57d" class="mp kx iq ml b gy mu mr l ms mt">print("Original Features:\n", list(df_full.columns), "\n")<br/>df_full_dummies = pd.get_dummies(df_full, columns=dummy_columns)<br/>print("Features after get_dummies: \n", list(df_full_dummies.columns))</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/5e400e494e2c96257c9f6e0ac0720fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qnnvbCI4xpFg7q_pBx08Xw.jpeg"/></div></div></figure><p id="bb40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然已经对数据进行了预处理，让我们使用之前创建的“training_set”布尔列来分离训练集和测试集。然后，我们可以在训练集上训练模型，并在测试集上进行预测。</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="4170" class="mp kx iq ml b gy mq mr l ms mt">df_train = df_full_dummies[df_full_dummies['training_set'] == True]</span><span id="09c9" class="mp kx iq ml b gy mu mr l ms mt">df_train = df_train.drop('training_set', axis=1)</span><span id="ece1" class="mp kx iq ml b gy mu mr l ms mt">df_test = df_full_dummies[df_full_dummies['training_set'] == False]</span><span id="0f54" class="mp kx iq ml b gy mu mr l ms mt">df_test = df_test.drop('training_set', axis=1)</span></pre><p id="1a3b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一点上我感觉很好。我觉得很有成就感。我觉得自己像终结者。事实上，我想走到杂货店里的某个陌生人面前，问他:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/9a4a5f65d1c04be206ad2b6d25c02a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*EWkW92l-SaUFtk0PzII2aA.jpeg"/></div><figcaption class="nv nw gj gh gi nx ny bd b be z dk">Globo Gym wins again</figcaption></figure><p id="9ab4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在所有这些工作之后，我只能取得大约 10%的进步:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="a66a" class="mp kx iq ml b gy mq mr l ms mt">from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import cross_val_score</span><span id="db12" class="mp kx iq ml b gy mu mr l ms mt">X = df_train.drop(['id', 'status_group'], axis=1)<br/>y = df_train['status_group']</span><span id="9790" class="mp kx iq ml b gy mu mr l ms mt">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</span><span id="2335" class="mp kx iq ml b gy mu mr l ms mt">lr = LogisticRegression(C=100).fit(X_train, y_train)<br/>scores = cross_val_score(lr, X, y, cv=5) # Cross-validating the model on the whole dataset</span><span id="022f" class="mp kx iq ml b gy mu mr l ms mt">y_pred = lr.predict(X_test)</span><span id="ccd8" class="mp kx iq ml b gy mu mr l ms mt">print("CV scores: {}".format(scores))<br/>print("CV scores mean: {}".format(scores.mean()))</span><span id="1eef" class="mp kx iq ml b gy mu mr l ms mt">CV scores: [0.66315967 0.65970878 0.66271044 0.67020202 0.66635797]<br/>CV scores mean: 0.6644277752104382</span></pre><p id="e130" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，随机森林分类器做得更好，这是我最终用来对测试集进行预测的:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="262a" class="mp kx iq ml b gy mq mr l ms mt">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import cross_val_score</span><span id="4a57" class="mp kx iq ml b gy mu mr l ms mt">X = df_train.drop(['id', 'status_group'], axis=1)<br/>y = df_train['status_group']</span><span id="bb9d" class="mp kx iq ml b gy mu mr l ms mt">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</span><span id="4416" class="mp kx iq ml b gy mu mr l ms mt">rf = RandomForestClassifier(n_estimators=100, min_samples_leaf=3).fit(X_train, y_train)<br/>scores = cross_val_score(rf, X, y, cv=5)</span><span id="dc41" class="mp kx iq ml b gy mu mr l ms mt">scores = </span><span id="fc5a" class="mp kx iq ml b gy mu mr l ms mt">[0.78444575 0.78318323 0.78265993 0.7787037  0.7797609 ]</span></pre><p id="353a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Kaggle 竞赛需要记住的另一件事是，您的提交材料必须采用正确的格式:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="3719" class="mp kx iq ml b gy mq mr l ms mt">X_test = df_test.drop('id', axis=1)</span><span id="6882" class="mp kx iq ml b gy mu mr l ms mt">final_preds = rf.predict(X_test)</span><span id="b690" class="mp kx iq ml b gy mu mr l ms mt">kaggle_baseline_submission_7 = pd.DataFrame({'id': df_test.id, 'status_group': final_preds})</span><span id="f088" class="mp kx iq ml b gy mu mr l ms mt">kaggle_baseline_submission_7.head()</span></pre><p id="07ad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在你知道了。通过一些工作，我能够在数据上训练两个分类器，对变量进行特征工程，进行预测并提交准确性评分。然而，对整个过程有一种根深蒂固的不满(因此有了过于戏剧性的“黑暗之心”的标题)。</p><p id="4243" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然随机森林在预测什么可能是错误的水点方面比逻辑回归“更好”，但我们仍然没有比我们在机器学习模型之前开始的时候更好地理解这个人为问题。</p><p id="9a18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，我们可以找出拟合的随机森林模型的特征重要性，并将其绘制如下:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="47ac" class="mp kx iq ml b gy mq mr l ms mt">plt.style.use('seaborn')<br/>#fig, ax = plt.subplot(figsize=(12, 8))<br/>feats = {}<br/>for feature, importance in zip(feature_names, rf.feature_importances_):<br/>    feats[feature] = importance<br/>    <br/>importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})</span><span id="53da" class="mp kx iq ml b gy mu mr l ms mt">importances.sort_values(by='Gini-importance').plot(kind='bar', rot=90, figsize=(20, 20))</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/3afd1564f10e6caf5998073dd4f5ff95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8z5kYVlTmRBXRsMleL21Iw.png"/></div></div></figure><p id="f6af" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是这些特征的重要性并不一定被解释为有助于做出预测或者允许我们分析问题。这些特征的重要性只在模型中是重要的，因为它们是如何对作为一个整体的决策树的决策起作用的。如果我们观察这个图，绝对没有理由相信错误的供水点的问题与“经度”和“纬度”有任何关系。</p><p id="a22f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，我仍然坚信，如果我们以正确的方式对数据进行特征设计，逻辑回归仍然是更好预测的关键。</p><p id="1c0f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，逻辑回归的可取之处在于，它允许我们查看系数，并计算出它们实际上如何影响功能和非功能水点:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f02f3105e77ff02ab279e3688dbfb462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJx3d99xdzvNYpb1Xhi-xg.png"/></div></div></figure><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="282b" class="mp kx iq ml b gy mq mr l ms mt">Red = Non-Functional<br/>Blue = Functional<br/>Green = Functional Needs Repair</span></pre><p id="c935" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的图是通过训练一个模型得到的，该模型具有一组修改过的标签，这些标签仅由两类组成:功能性和非功能性，而不是三类。我用这种方法来解决不平衡数据的问题。此外，特征 coord_cluster_1、coord_cluster_2 和 coor_cluster_3 是通过用 n=3 的 KMeans 聚类拟合纬度和经度数字来创建的，以便尝试提取某种更有意义的信息:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="904d" class="mp kx iq ml b gy mq mr l ms mt"># extract the longitude and latitude values<br/>long_lat = df_full[['longitude', 'latitude']].values</span><span id="50be" class="mp kx iq ml b gy mu mr l ms mt">from sklearn.cluster import KMeans</span><span id="c104" class="mp kx iq ml b gy mu mr l ms mt">kmeans = KMeans(n_clusters=3)<br/>kmeans.fit(long_lat)</span><span id="dbc6" class="mp kx iq ml b gy mu mr l ms mt">print("cluster memberships:\n{}".format(kmeans.labels_[:25]))</span><span id="6678" class="mp kx iq ml b gy mu mr l ms mt">coord_cluster = kmeans.labels_<br/>df_full['coord_cluster'] = coord_cluster</span></pre><p id="6712" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">输出:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="cd18" class="mp kx iq ml b gy mq mr l ms mt">cluster memberships:<br/>[2 0 0 2 0 2 0 0 0 0 2 2 0 0 0 2 2 2 0 2 2 1 2 0 0]</span></pre><p id="42b4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然 k 均值聚类确实提供了比之前的逻辑回归中的纬度或经度更多的信息，但它仍然没有产生足够的信息来制作顶部系数。</p><p id="5046" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">功能用水点相对于非功能用水点的前四大影响因素</strong>:</p><pre class="lv lw lx ly gt mk ml mm mn aw mo bi"><span id="f567" class="mp kx iq ml b gy mq mr l ms mt">1. waterpoint_type: <strong class="ml ir">handpump</strong><br/>2. water_source: <strong class="ml ir">spring</strong><br/>3. quantity: <strong class="ml ir">enough</strong><br/>4. extraction_type: <strong class="ml ir">gravity</strong></span></pre><p id="1b2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些系数的重要之处在于，它们几乎与<a class="ae mj" href="https://www.theguardian.com/society/katineblog/2008/feb/25/waterdebatedoboreholeswork" rel="noopener ugc nofollow" target="_blank">专家</a>在非洲讨论这个问题时所说的完全一致。</p><p id="c6b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，供水点故障的一个根本原因是社区缺乏修理供水点故障的机制。从设计上来说，手泵比许多其他类型的供水点更简单，并且不需要机械的持续维护。因此，手泵抽取类型在模型中具有单一的最高系数。同样的事情也可以说是关于引力的提取。因为它们不需要电动泵之类的东西，所以显然需要更少的维护。另一个看似显而易见的解释变量是水量:水量越大，我们就越有可能拥有一个正常运作的供水点。</p><p id="bf9e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总之，尽管我没有赢得 Kaggle 挑战赛，尽管随机森林表现得更好，但我仍然相信，解决这类问题的合适的机器学习算法是逻辑回归。逻辑回归给了我们随机森林永远无法提供的东西:对企业和政府管理人员的解释，他们可以回头尝试实施解决方案。</p><p id="f8d2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">吸取教训</strong>:</p><ol class=""><li id="40f8" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated">寻求帮助:在 Lambda，我们有一个 20 分钟的规则，如果我们自己仍然不能解决问题，我们会寻求帮助。我打破了这个规则，决定耍流氓，并为此付出了大量浪费时间清理没有任何有价值信息的数据。</li><li id="0229" class="lz ma iq ka b kb mw kf mx kj my kn mz kr na kv me mf mg mh bi translated">数据科学是我做过的最难的事情之一。虽然结果可能令人沮丧，但大多数情况下，这是一个通过实践和失败反复学习的过程。我很高兴能成为 Lambda 学校的一员。</li></ol><p id="f1f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以在这里找到 Jupyter 笔记本版本<a class="ae mj" href="https://github.com/Captmoonshot/kaggle_waterpumps_2/blob/master/final_model_2.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>