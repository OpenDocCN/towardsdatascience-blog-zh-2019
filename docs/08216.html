<html>
<head>
<title>Multi-Label Text Classification with XLNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 XLNet 的多标签文本分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df?source=collection_archive---------3-----------------------#2019-11-10">https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df?source=collection_archive---------3-----------------------#2019-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dae3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">使用 XLNet 实现最先进的多标签和多类别文本分类</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/dae2a845069ffd68d496a67513e9d054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1iypsouAGB6jABtPW-JyA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Photo by <a class="ae kz" href="https://unsplash.com/@cgower" rel="noopener ugc nofollow" target="_blank">Christopher Gower</a> on <a class="ae kz" href="https://unsplash.com/photos/m_HRfLhgABo" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="90c3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在 2019 年 6 月 19 日发表时，XLNet 在 18 项任务上取得了最先进的结果，包括文本分类、问答、自然语言推理、情感分析和文档排名。</p><p id="d086" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">它甚至在 20 个任务上超过了 BERT！</p><p id="3f78" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由卡耐基梅隆大学和谷歌大脑开发的<a class="ae kz" href="https://arxiv.org/abs/1906.08237" rel="noopener ugc nofollow" target="_blank"> XLNet </a>是一个基于排列的自回归语言模型。</p><p id="87b5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们不会过多地探究模型的内部工作原理，因为有很多很好的资源可以用于这个目的。相反，本文将集中讨论 XLNet 在多标签和多类文本分类问题上的应用。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="0731" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">介绍</h1><p id="9423" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">让我们快速回顾一下。在多类分类问题中，有多个类，但是任何给定的文本样本将被分配一个类。</p><p id="3d54" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">另一方面，在多标签文本分类问题中，一个文本样本可以被分配给多个类别。</p><p id="ff21" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将使用由 HuggingFace 开发的<a class="ae kz" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变形金刚</a>库。Transformers 库提供了许多先进语言模型的易用实现:BERT、XLNet、GPT-2、RoBERTa、CTRL 等。</p><p id="8a08" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">此外，我还想对<a class="ae kz" href="https://medium.com/@kaushaltrivedi" rel="noopener"> Kaushal Trivedi </a>表示感谢，他在 BERT 上关于多标签分类的惊人的<a class="ae kz" href="https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d" rel="noopener">教程</a>是这里代码的基础。</p><p id="bca5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将应对 Kaggle 的<a class="ae kz" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview" rel="noopener ugc nofollow" target="_blank">毒性评论分类挑战，</a>我们需要预测在线评论的六种可能的评论毒性类别的概率。</p><p id="ab77" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">快速说明一下，XLNet 有一个基础版本和一个大版本:</p><ul class=""><li id="b605" class="na nb it lc b ld le lg lh lj nc ln nd lr ne lv nf ng nh ni bi translated">XLNet 库:12 层，768 个隐藏单元，12 个注意头，110M 参数。</li><li id="5aa5" class="na nb it lc b ld nj lg nk lj nl ln nm lr nn lv nf ng nh ni bi translated">XLNet Large: 24 层，768 个隐藏单元，16 个注意头，340M 参数</li></ul><p id="20ce" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将在 Google Colab 上训练我们的模型，Google Colab 免费提供 16 GB 的特斯拉 P100！</p><p id="3014" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于特斯拉 P100 的 GPU 内存限制，我们将使用 XLNet 基础为我们的任务。</p><p id="0d6d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们不会从头开始训练模型，而是对预训练的模型进行微调。这个概念被称为迁移学习。</p><p id="ad09" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">没有别的事了，我们开始吧！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="7bfb" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">密码</h1><p id="be2d" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">点击<a class="ae kz" href="https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7" rel="noopener ugc nofollow" target="_blank">此处</a>获取本文附带的 Colab 笔记本。</p><p id="849f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，让我们安装必要的库，实际上只是变压器。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="dc56" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们导入必要的库。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="bc58" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">检查 GPU 是否可用。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nq"><img src="../Images/c92c6e4d756c4323cdaef3c2a9b1da97.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*fJ2rUO00MXZt83eMhsCykQ.jpeg"/></div></div></figure><p id="5572" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">将你的 google drive 安装到你的 Colab 笔记本上。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="36e9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于我们的例子，我们将在 google drive 中创建一个<code class="fe nr ns nt nu b">Data</code>文件夹，并将数据集放在那里。</p><p id="29a9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">读取<code class="fe nr ns nt nu b">.csv</code>文件。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="5c66" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们来看看数据集。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nv"><img src="../Images/ad0c3fa216eebd96add6743c207265e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1M51AFIvMgMWUETCRmpaQ.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Train dataset</figcaption></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nw"><img src="../Images/b6f42da5c5e96966f2a4ff836e77c96c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAc4-xFXbiIn0DvWbgb1iA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Test dataset</figcaption></figure><p id="1e1a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们做一些快速 EDA。分析标签的分布，我们注意到标签是不平衡的。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nx"><img src="../Images/2993c1f96e993d295a35e9bd6b6918d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RYkVmw2_Dsm5oDrgByveIw.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Distribution of labels in the training data</figcaption></figure><p id="9103" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在将一段文本输入模型之前，必须将文本标记成适当的子词。为此，我们可以使用 HuggingFace 的<code class="fe nr ns nt nu b">XLNetTokenizer</code>。</p><p id="2f8f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">理论上，基于 XLNet 的模型能够处理多达 512 个子字的序列。然而，为了减少训练时间，也考虑到有限的 GPU 内存，我们将选择一个较小的序列大小。</p><p id="fa60" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们可以分析评论的子词数量的分布。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ny"><img src="../Images/2603dcad3023af0dbdccd35124268a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmDc7SwEQU8JEqdRhkF-Lg.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Distribution of the number of sub-word tokens in the training data</figcaption></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nz"><img src="../Images/3606d64765da9e4e13af658ac9e4d122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zIReW2kVapXKBy3Sh-_3_w.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Distribution of the number of sub-word tokens in the testing data</figcaption></figure><p id="d6cb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于大多数评论的子词少于 250 个，我们可以将所有评论截断或填充到 250 个子词。</p><p id="8c75" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">将输入文本序列转换成适当的数字标记 id。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/4ec2b02d4684cec4f67987f61e2d8b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmgKp8ZzBiNR5lX7FK1dpA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Example of the processed tokenized inputs</figcaption></figure><p id="78c0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们将创建注意屏蔽，它指示模型在适当的令牌上执行注意。目的是防止我们的模型对填充标记进行关注。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="1386" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">将标记化的数字输入和注意屏蔽附加到数据帧。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/aa9035f00f8f76d5609cb8e9745ded6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9nw_-oaDXM2yhZVEJepjw.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Train dataframe</figcaption></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/0711ab634e06b4e3533e61826d8910f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6D3z4mpIYXp1xurtt5hgg.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Test dataframe</figcaption></figure><p id="0133" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">出于交叉验证的目的，我们将执行培训和验证分割。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="adb2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">创建特征、遮罩和标签数组，并将其转换为火炬张量。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="cc48" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，为训练集和验证集创建<code class="fe nr ns nt nu b">Dataloaders</code>。我们将使用 32 的批量大小。</p><p id="86c8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果 Colab 为您的运行时分配 12 GB Tesla K80，您可能会考虑将批处理大小减少到 16，以避免耗尽 GPU 内存。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="4a55" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们定义我们的 XLNet 分类模型。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="86f1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于输入序列有 250 个记号，XLNet 将产生 250 个输出向量，每个向量的维数为 768。我们将对输出向量进行平均汇集，并生成一个维数为 768 的向量。该向量将成为全连接层的输入，该层将预测 6 个注释毒性标签。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ob"><img src="../Images/86557920d20d7594b88ff174d2e32576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9NYGAL5tgxf1GkvE_GEhYg.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Mean pooling the output vectors into a single vector</figcaption></figure><p id="c751" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">您肯定可以探索其他方法来汇集输出，比如将输出连接成一个大的向量，或者甚至使用 XLNet 最后几个隐藏层的输出。</p><p id="654d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们初始化优化器。我们将使用<code class="fe nr ns nt nu b">AdamW</code>优化器。如果需要，您还可以设置学习率计划。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="61c8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们现在将定义训练函数。在训练期间，该函数将在达到最低验证损失时保存模型。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="04d7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在特斯拉 P100 上，一次训练大约需要 1 小时 30 分钟。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oc"><img src="../Images/bccc7617214d594b88bd2a2f1533cd2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OrJh_g5dy7fm8AIHy6aCIQ.jpeg"/></div></div></figure><p id="6bfa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们的模型被训练之后，我们可以为 153，164 个测试示例生成预测。</p><p id="1b66" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果我们试图一次性预测所有测试示例的标签，我们的 GPU 很可能会耗尽内存。对此的解决方案是为每 32 个测试实例生成预测，并将它们连接在一起。</p><p id="69f7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当然，32 的批量大小可以根据 GPU 内存的多少而改变。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="9dcd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">将结果提交给 Kaggle，经过一个时期的微调训练，我们获得了 0.98182 的公共分数和 0.98323 的私有分数。不算太寒酸！</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi od"><img src="../Images/42516347ead20f53176d529074cffec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3XHr980yo72suDnWX0v6Q.jpeg"/></div></div></figure><p id="9389" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">请注意，我们没有执行任何参数调整或功能工程。</p><p id="7bdf" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您想要预测的硬标签而不是软概率，只需将软概率四舍五入到最接近的整数(0 或 1)。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oe"><img src="../Images/a7fd3b7e98221467466f2e95a4edf90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W1UpmPVGV0h3taK0kSwgbA.jpeg"/></div></div></figure><p id="8744" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">就是这样！Colab 笔记本的链接可以在<a class="ae kz" href="https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="7615" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="of">感谢您阅读这篇文章！如果你有任何想法或反馈，请在下面留下评论或给我发电子邮件到 leexinjie@gmail.com。我很想收到你的来信！</em></p></div></div>    
</body>
</html>