<html>
<head>
<title>Hands-on Global Model Interpretation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动手全球模型解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-global-model-interpretation-3bb4264732b5?source=collection_archive---------25-----------------------#2019-08-05">https://towardsdatascience.com/hands-on-global-model-interpretation-3bb4264732b5?source=collection_archive---------25-----------------------#2019-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d9cc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">什么特性是重要的，为什么</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/39cce9ca5be118691dda60aa89a2bd08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-27KX0OivF0uEZN0"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@bramnaus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bram Naus</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a366" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文是我关于模型可解释性和可解释人工智能系列文章的延续。如果你还没有，我强烈推荐你阅读本系列的第一篇文章— <a class="ae ky" rel="noopener" target="_blank" href="/introduction-to-machine-learning-model-interpretation-55036186eeab">“机器学习模型解释简介”</a>，它涵盖了模型可解释性的基础知识，从什么是模型可解释性，为什么我们需要它到模型解释的潜在区别。</p><p id="c1b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将通过更深入地探究全局模型解释的来龙去脉来重拾我们离开的地方。首先，我们将快速回顾一下什么是全球模型解释及其重要性。然后我们将深入其中两种最流行的方法的理论——特征重要性和部分依赖图——并应用它们来获得关于<a class="ae ky" href="https://www.kaggle.com/ronitf/heart-disease-uci" rel="noopener ugc nofollow" target="_blank">心脏病数据集</a>的特征的信息。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3f95" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">什么是全局模型解释？</h1><p id="6762" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">全局模型解释是一套帮助我们回答问题的技术，比如一个模型通常是如何表现的？哪些功能驱动预测，哪些功能对你的事业完全没用。使用这些知识，您可以对数据收集过程做出决策，创建仪表板来解释您的模型，或者使用您的领域知识来修复明显的错误。</p><p id="7e7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数全局解释方法都是通过研究完整数据集上因变量和自变量(特征)之间的条件交互作用来工作的。他们还创建和使用大量的可视化工具，这些工具很容易理解，但包含大量用于分析模型的有用信息。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3f6f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">特征重要性</h1><blockquote class="mz na nb"><p id="77d8" class="kz la nc lb b lc ld ju le lf lg jx lh nd lj lk ll ne ln lo lp nf lr ls lt lu im bi translated">特征的重要性是在我们置换了特征的值之后模型的预测误差的增加，这打破了特征和真实结果之间的关系。— <a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/feature-importance.html" rel="noopener ugc nofollow" target="_blank">可解释的机器学习，一个让黑盒模型变得可解释的指南</a></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ng"><img src="../Images/fe741774fc57013d18257ce830fdd5bc.png" data-original-src="https://miro.medium.com/v2/format:webp/1*649hWkMOaHApRNTRlJmghw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 2: Feature importance example</figcaption></figure><h2 id="2955" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">概念和理论</h2><p id="61c6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">特性重要性的概念非常简单。使用特征重要性，我们通过计算在置换/混洗给定特征的特征值之后给定模型的误差的增加来测量特征的重要性。</p><p id="f809" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果置换会增加模型误差，则特征是“重要的”。这是因为在这种情况下，模型严重依赖这一特征来做出正确的预测。另一方面，如果置换不会对误差产生太大影响或者根本不会改变误差，那么特征就是“不重要”的。</p><p id="a720" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Fisher，Rudin 和 Dominici 在他们 2018 年的论文<a class="ae ky" href="https://arxiv.org/abs/1801.01489" rel="noopener ugc nofollow" target="_blank">中建议，“所有的模型都是错误的，但许多是有用的……”</a>不是随机洗牌，而是应该将功能分成两半，并交换两半。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="8787" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">优势</h2><p id="dc14" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">特性重要性是了解特性重要性的最流行的技术之一。这是因为这是一种简单的技术，它为您提供了关于某个特性重要性的高度压缩的全局洞察力。此外，它不需要重新训练模型，这总是一个优势，因为节省了计算时间。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="7e3e" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">不足之处</h2><p id="294a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">尽管特征重要性是一种应该一直使用的解释技术，但是它仍然有一些缺点。例如，不清楚您是否应该<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/feature-importance.html" rel="noopener ugc nofollow" target="_blank">使用训练或测试集来计算特性重要性</a>。此外，由于置换过程，当重复计算时，结果可能变化很大。</p><p id="a964" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个问题是，特征之间的相关性会通过产生不现实的实例或者通过在两个相关特征之间分割重要性来偏离特征的重要性。</p><p id="8257" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多信息，我强烈推荐你去看看<a class="ae ky" href="https://christophm.github.io/" rel="noopener ugc nofollow" target="_blank"> Christoph Molnar 的</a>电子书“<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">可解释的机器学习</a>”，这是一本学习更多解释模型的好书。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="57d1" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">示例和解释</h2><blockquote class="nt"><p id="40e4" class="nu nv it bd nw nx ny nz oa ob oc lu dk translated">模型认为什么特征对于确定患者是否患有心脏病很重要？</p></blockquote><p id="cb49" class="pw-post-body-paragraph kz la it lb b lc od ju le lf oe jx lh li of lk ll lm og lo lp lq oh ls lt lu im bi translated">这个问题可以用特征重要性来回答。</p><p id="b1a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我在文章开头提到的，我们将研究心脏病数据集。你可以在我的 Github 上或者作为<a class="ae ky" href="https://www.kaggle.com/tannergi/heart-disease-analysis#Interpreting-models" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>找到本教程使用的所有代码。</p><p id="1c21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数库，如<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn、</a> <a class="ae ky" href="https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>以及其他机器学习库，已经有了自己的特征重要性方法，但是如果您想在处理来自多个库的模型时获得准确的结果，使用相同的方法来计算每个模型的特征重要性是有利的。</p><p id="1704" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保这一点，我们将使用<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> ELI5 库</a>。ELI5 允许用户可视化和调试各种机器学习模型。它提供的不仅仅是特性的重要性，还包括特定于库的特性以及一个<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html" rel="noopener ugc nofollow" target="_blank">文本解释器</a>。</p><p id="3ab5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了计算特征的重要性，我们可以使用<code class="fe oi oj ok ol b"><em class="nc">permutation_importance</em></code>方法。在计算了给定模型的特征重要性之后，我们可以使用<code class="fe oi oj ok ol b">show_weights</code>方法来可视化它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="ae43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">利用上述方法可以得到模型的特征重要度，并对它们进行比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/563aaa82369537870d54c3dc2d02662f.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*SOvL5tV39ze1TElwKC7cEw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 3: Feature Importance of Logistic Regression</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/faa43b84a752663fa984d7245b10d5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*JsdwvUJY1aPGkQ26KsJlDg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 4: Feature Importance of XGBoost</figcaption></figure><p id="c292" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到这两个模型对于一个特性有着非常不同的重要性分数。这会对你对结果的信任度产生负面影响。</p><p id="6875" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管如此，我们可以看到，像 ca、性别和 thal 这样的特征对于获得正确的预测非常有用，而年龄和 cp 对于获得正确的预测并不重要。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="aa64" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">部分相关图</h1><blockquote class="mz na nb"><p id="3420" class="kz la nc lb b lc ld ju le lf lg jx lh nd lj lk ll ne ln lo lp nf lr ls lt lu im bi translated">部分相关图(简称 PDP 或 PD 图)显示了一个或两个特征对机器学习模型的预测结果的边际效应</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/636390c13365d05ce12b1e830533a32d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c4-FRKU_Cs9krwkL_brljA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 5: Partial Dependence Plot Example</figcaption></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="eb51" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">概念和理论</h2><p id="13fe" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">部分相关图为您提供了有关特征如何影响模型预测的信息。这可以帮助我们理解什么样的特征值会给我们更高或更低的输出。</p><p id="0da8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于分类特征，可以容易地计算部分相关性。我们通过强制所有数据实例具有相同的类别来获得每个类别的估计值。例如，如果我们对性别如何影响患心脏病的几率感兴趣，我们可以首先用值“男性”替换“性别”列中的所有值，并对预测进行平均，然后用值“女性”进行平均。</p><p id="eb57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算回归的部分相关性要困难得多，但是 Christoph Molnar 在他的电子书中很好地解释了这个问题。因此，如果你有兴趣深入了解模型解释，一定要去看看。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="8ebd" class="nh md it bd me ni nj dn mi nk nl dp mm li nm nn mo lm no np mq lq nq nr ms ns bi translated">示例和解释</h2><p id="6439" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了创建部分相关图，我们将使用<a class="ae ky" href="https://github.com/SauceCat/PDPbox" rel="noopener ugc nofollow" target="_blank"> PDPbox 库</a>。PDPbox 为我们提供了一些不同的精心设计的图，包括单个功能的部分依赖图以及多个功能的部分依赖图。</p><div class="kj kk kl km gt ab cb"><figure class="or kn os ot ou ov ow paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/097ac489fe5ab729097c86e6cd5b333c.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*V4WT6F5l_UAXNIaRktq8xQ.png"/></div></figure><figure class="or kn ox ot ou ov ow paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/db54eaea47b970477cebda461034aa54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*KQg3RUB5imIVklSqGBcS5w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk oy di oz pa">Figure 6: PDP’s for one and two features</figcaption></figure></div><p id="ccf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要安装 PDPbox，我们可以键入:</p><pre class="kj kk kl km gt pb ol pc pd aw pe bi"><span id="3136" class="nh md it ol b gy pf pg l ph pi">pip install git+https://github.com/SauceCat/PDPbox.git</span></pre><p id="5731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以使用<code class="fe oi oj ok ol b">pdp_isolate</code>和<code class="fe oi oj ok ol b">pdp_plot</code>方法创建一个部分相关图来分析不同性别对患心脏病概率的影响。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/d07536e25d85de754dbc3cd0dd409039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Opd8CrBgVOi6Gk5F15ItIg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 7: PDP for Gender</figcaption></figure><p id="61d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当将性别从<em class="nc"> sex_0 </em>更改为<em class="nc"> sex_1 </em>时，黄黑线给出了预测的平均效果。只看这条线，我们就能看出性别为 0 的患者比性别为 1 的患者更有可能患心脏病。</p><p id="633a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了创建一个部分依赖图，向我们展示目标上两个特征的交互作用，我们可以使用<code class="fe oi oj ok ol b">pdp_interact</code>和<code class="fe oi oj ok ol b">pdp_interact_plot</code>方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/50244294edf8a252dbbe220fd5c84f86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akcy9Ge-o978JILnfDUolg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 8: 2d partial dependence plot</figcaption></figure><p id="d302" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这可以帮助我们找到两个特征之间的相互作用，甚至是单个特征值。例如，我们可以看到，无论性别栏的值如何，年龄在 55 岁至 63 岁之间的患者患心脏病的概率最低。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="7ad5" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="d79d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">全局模型解释是帮助我们回答一些问题的技术，比如一个模型通常是如何表现的？哪些功能驱动预测，哪些功能对你的事业完全没用。</p><p id="ce6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两种最常用的全局模型解释技术是特征重要性和部分相关图。</p><p id="0a5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用特征重要性来了解模型认为特征对于进行预测有多重要。</p><p id="14d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">部分相关图有助于我们理解特定特征值如何影响预测。这是非常有用的，因为它允许你对特定的特征值感兴趣，然后可以进一步分析或共享。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="ca3f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">下一步是什么？</h1><p id="1574" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在本系列的第 3 部分中，我们将深入了解什么是局部模型解释，以及两种局部模型解释技术(石灰值和 Shapely 值)是如何工作的，从而更深入地了解个人预测。</p><p id="316d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是这篇文章的全部内容。如果你有任何问题或者只是想和我聊天，请在下面留下评论或者在社交媒体上联系我。如果你想获得我博客的持续更新，请确保在 Medium 上关注我，并加入我的简讯。</p></div></div>    
</body>
</html>