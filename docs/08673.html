<html>
<head>
<title>Predict figure skating world championship ranking from season performances</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从赛季表现预测花样滑冰世锦赛排名</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2?source=collection_archive---------29-----------------------#2019-11-21">https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2?source=collection_archive---------29-----------------------#2019-11-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9e20" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">体育分析</h2><div class=""/><div class=""><h2 id="062a" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">第 4 部分:从多个因素对运动员进行排名</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/19998e748c5fe38c73d5e9d0a658dbf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_77jJyPivm7V_cv9Pwojg.jpeg"/></div></div></figure><ul class=""><li id="9eee" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><em class="ls">要看我为这个项目写的代码，可以去看看它的 Github </em> <a class="ae lt" href="https://github.com/dknguyengit/skate_predict" rel="noopener ugc nofollow" target="_blank"> <em class="ls">回购</em> </a></li><li id="bd99" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><em class="ls">对于项目的其他部分:</em> <a class="ae lt" rel="noopener" target="_blank" href="/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&amp;sk=7e6b2992c6dd5e6e7e1803c574b4236d"> <em class="ls">第一部分</em> </a> <em class="ls">，</em> <a class="ae lt" rel="noopener" target="_blank" href="/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&amp;sk=86881d127654ece260be2e3029dfbad2"> <em class="ls">第二部分</em> </a> <em class="ls">，</em> <a class="ae lt" rel="noopener" target="_blank" href="/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&amp;sk=48c2971de1a7aa77352eb96eec77f249"> <em class="ls">第三部分</em> </a> <em class="ls">，第四部分</em> <a class="ae lt" href="https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-7461dc5c0722?source=friends_link&amp;sk=fcf7e410d33925363d0bbbcf59130ade" rel="noopener"> <em class="ls">第五部分</em><em class="ls">，</em> </a><a class="ae lt" href="https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-d97bfbd37807" rel="noopener"> <em class="ls">第六部分</em> </a></li></ul><h1 id="8304" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">背景</h1><p id="b0c6" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">在项目的前几部分，我试图根据运动员在该赛季前几场比赛中获得的分数来预测一年一度的世界花样滑冰锦标赛的排名。主要策略是将<strong class="lc ja">选手效应</strong>(每个选手的内在能力)与<strong class="lc ja">事件效应</strong>(一个事件对选手表现的影响)分开，以便建立更准确的排名。</p><p id="6289" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">具体来说，在项目的<a class="ae lt" rel="noopener" target="_blank" href="/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&amp;sk=48c2971de1a7aa77352eb96eec77f249"> part 3 </a>中，每个项目和每个滑手都由多个潜在因素来表示。一个项目和一名运动员之间的这些潜在因素的乘积，当加到基线得分时，将接近该项目-运动员对在赛季中的得分:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7479d755ba39a8a5addba8169c034f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*uQmcmihQSym7VWVoj8UQpA.png"/></div></figure><ul class=""><li id="7c51" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">ŷ_event-skater</code>:给定运动员在给定项目中的预测得分</li><li id="d37c" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">θ_event</code>:基线得分(在所有项目和运动员中保持不变)</li><li id="27b8" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">m</code>:模型的潜在因素数</li><li id="ea02" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">存在于每个项目和每个运动员身上的潜在因素</li><li id="59c5" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">θ_event,f</code>:给定事件的潜在因素得分</li><li id="705a" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">θ_skater,f</code>:给定选手的潜在因素得分</li></ul><h1 id="7d6a" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">问题</h1><p id="d1ff" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">使用梯度下降，我们可以找到所有项目和运动员的不同因素的潜在得分。然而，一旦找到了每个选手的潜在分数，我们就面临一个大难题:我们应该用什么分数给选手排名？</p><p id="538f" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">正如在<a class="ae lt" rel="noopener" target="_blank" href="/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&amp;sk=48c2971de1a7aa77352eb96eec77f249">第 3 部分</a>中所讨论的，如果我们按照每个单独的因素对运动员进行排名，没有一个因素可以给出一个像样的排名:给定 5 个潜在因素，任何一个因素的最高肯德尔τ是 0.45(从第一个因素开始)。这甚至远远低于季节平均值的基线模型(0.695)，更不用说我们以前建立的模型(加法和乘法模型为 0.732，混合模型为 0.724)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/dcc79132bc546b825ca21ad249a49f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K4b17yUOSsR6CNmf.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Predicted rankings from each individual factor. <strong class="bd nt">In parentheses:</strong> Kendall’s tau of each predicted ranking to the world championship ranking</figcaption></figure><p id="1119" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因此，我们必须找到一种方法，将不同因素之间的潜在得分结合起来，以便更准确地对滑冰运动员进行排名。</p><h1 id="d554" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">综合多种因素对运动员进行排名</h1><p id="36bb" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">对我来说，这是这个项目中最难的部分，因为最初我绞尽脑汁想知道我究竟如何将几个因素的潜在分数结合起来给运动员排名。</p><p id="f062" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">然而，“啊哈！”当我意识到我可以只使用每年的世界锦标赛排名来直接学习如何组合潜在的分数时，那一刻到来了。我也很幸运，因为 Kendall 的 tau 的简单排名度量允许我建立一个简单的逻辑回归模型来组合它们。</p><h2 id="dbef" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">肯德尔的 tau 排序度量</h2><p id="7c19" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">让我们回顾一下<a class="ae lt" href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">肯德尔τ</a>的等级度量公式，也称为肯德尔等级相关系数，在项目的<a class="ae lt" rel="noopener" target="_blank" href="/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&amp;sk=7e6b2992c6dd5e6e7e1803c574b4236d">第 1 部分</a>中有解释。这是一个衡量两个排名彼此相似程度的指标，比如在世界锦标赛中的预测排名和实际排名之间。</p><p id="ecc3" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">使用前面部分的 4 名滑手的相同玩具示例，让我们假设在该赛季结束时的世界锦标赛中，这 4 名滑手的排名是这样的(从最高到最低；为简单起见，去掉了名字):</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="e896" class="nu ma iq nn b gy oj ok l ol om">1. FERNANDEZ<br/>2. MURA<br/>3. GE<br/>4. MAJOROV</span></pre><p id="26ab" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从这个排名中，我们可以生成 4×(4–1)/2 = 6 个有序对，其中每对中第一个溜冰者的排名总是高于第二个。在本例中，6 个有序对是:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="0866" class="nu ma iq nn b gy oj ok l ol om">(FERNANDEZ, MURA)<br/>(FERNANDEZ, GE)<br/>(FERNANDEZ, MAJOROV)<br/>(MURA, GE)<br/>(MURA, MAJOROV)<br/>(GE, MAJOROV)</span></pre><p id="e4e5" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">与世界锦标赛完全匹配的预测排名也将产生它自己的 6 个有序对，与上面的 6 个有序对匹配。我们把在两种排序中都匹配的有序对称为<strong class="lc ja">和谐对</strong>，而那些只出现在一种排序中而不出现在另一种排序中的有序对称为<strong class="lc ja">不和谐对</strong>。</p><p id="3cd9" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">那么，两个等级之间的肯德尔τ可以计算为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/615c2356da2b357714165a38455ff028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WDa9sx3-Nm-5WjLy.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">n:</strong> number of skaters in the world championship</figcaption></figure><p id="4292" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">结果，该预测的排序将具有 6 个一致对和 6 个总有序对中的 0 个不一致对。这转化为(6–0)/6 = 1 的肯德尔τ，这也是两个等级之间的肯德尔τ的上限。相比之下，下限是-1，这是两个完全相反的排名之间的肯德尔τ。</p><p id="c0bf" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">上述公式中的一个重要观察结果是，Kendall 的 tau 相对于一致对的数量严格增加。因此，优化预测排名的肯德尔τ与试图从中获得最高数量的一致对是一样的。更简单地说，在世界锦标赛的有序对中，我们预测的排名需要尽可能多地正确猜测这些对。</p><h2 id="ab3f" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">逻辑回归模型</h2><p id="f398" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">但是我们如何对这些有序对进行智能猜测呢？这就是来自多因素模型的潜在得分的来源。如前所述，在我们的玩具示例中，从 4 名溜冰者的世界锦标赛排名中，我们可以生成 4(4–1)/2 = 6 个有序对。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/8675f423b979a0c2b36d0c9683624078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pK2eEkNzVxJM0B08aZd8JA.png"/></div></div></figure><ul class=""><li id="6d13" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">每个有序对将作为我们逻辑回归问题的一个<strong class="lc ja">观察值</strong>。</li><li id="90ff" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">对于每一个有序对，第一个滑手(姑且称他为滑手 A)的排名都高于第二个滑手(姑且称他为滑手 B)。这将作为我们逻辑回归的基本事实<strong class="lc ja">响应</strong>。更具体地说，每一对的响应将是一个二元变量，它指示溜冰者 A 是否将超过溜冰者 B: <code class="fe nk nl nm nn b">I(A&gt;B)</code>。在这种情况下，在每对选手中，选手 A 的名次都高于选手 B；因此，训练样本中所有对的响应都将是 1。</li><li id="7f8d" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">对于两位选手(A &amp; B)，我们已经有了他们之前运行多因素模型的潜在分数。因此，我们可以从运动员 A 的潜在得分中减去运动员 B 的潜在得分，以获得两个运动员在每个因素上的差异。这些差异将被用作每次观察的<strong class="lc ja">预测值</strong>。</li></ul><p id="491c" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">根据上面的设置，很明显，我们可以使用逻辑回归来预测每对/观察值的二元响应。更具体地说，对于每一对选手，我们预测 A 选手在世界锦标赛中超过 B 选手的概率<code class="fe nk nl nm nn b">P(A&gt;B)</code>。因此，理想的情况是每一对的这个<strong class="lc ja">预测概率</strong>尽可能接近 1，假设每个观察的地面真实响应总是 1。</p><p id="4977" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">对于逻辑回归，运动员 A 将超过运动员 B 的预测概率将是一个 sigmoid 函数，应用于两个运动员在不同因素上的潜在得分差异的线性组合:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/1d3ccf66322a1dd500c43a74462564ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*6QqfNqWr_lHV3YE-r0QWAg.png"/></div></figure><ul class=""><li id="b770" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">P(A &gt; B)</code>:在有序配对中，第一个选手(A)的排名超过第二个选手(B)的预测概率</li><li id="0ef8" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">β_f</code>:潜在因素得分差异的线性系数<code class="fe nk nl nm nn b">f</code></li><li id="aeac" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">Δθ_f</code>:两名选手在<code class="fe nk nl nm nn b">f</code>因子上的得分差异</li><li id="9dbb" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">Δθ_A,f</code>:选手 A 中<code class="fe nk nl nm nn b">f</code>因素的潜在得分</li><li id="b832" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">Δθ_B,f</code>:运动员 B 中<code class="fe nk nl nm nn b">f</code>因素的潜在得分</li></ul><p id="8d96" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因此，一旦我们知道了每个因素<code class="fe nk nl nm nn b">f</code>的差异的线性系数<code class="fe nk nl nm nn b">β_f</code>，我们就可以使用上面的公式来预测 A 选手在世界锦标赛中超过 B 选手的概率。然后，如果这个预测的概率大于 0.5，我们预测溜冰者 A 将排名溜冰者 b。最后，从这些成对的排名预测，我们可以预测从上到下所有溜冰者的最终排名。</p><h2 id="0133" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">学习模型系数</h2><p id="36ed" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">但是我们如何学习逻辑回归模型的线性系数呢？关键是从所有 n(n-1)/2 个有序对中找到最大化观察地面真实响应的联合概率的系数——溜冰者 A 确实比溜冰者 B 排名更高。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9fe2a600ee22da1aa47a0eea2ee48c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*uSbx9BYdG0rNjxOd3Fsjeg.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">m:</strong> number of factors, <strong class="bd nt">n:</strong> number of skaters in the world championship</figcaption></figure><ul class=""><li id="4963" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">β̂_1</code>、…、<code class="fe nk nl nm nn b">β̂_m</code>:逻辑回归模型的学习线性系数(每个因子一个)</li><li id="4517" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">p</code>:从世界锦标赛排名中提取的每个有序对/观察</li><li id="7a2b" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><code class="fe nk nl nm nn b">P(A &gt; B)_p</code>:在双人世界锦标赛中，A 选手的排名超过 B 选手的预测概率<code class="fe nk nl nm nn b">p</code></li></ul><p id="661d" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的公式中注意到，最大化联合概率与最大化其对数是一样的，我们通常称之为<a class="ae lt" href="https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ja">对数似然</strong> </a>。取对数的原因是预测概率的乘积被转换成这些概率的对数之和，这是一个更容易最大化的目标函数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d6f779e4bfcff8b4d2bf27054c9ebda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*8kCD_jMJN-8xAeuZiTF2cw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">m:</strong> number of factors, <strong class="bd nt">n:</strong> number of skaters in the world championship</figcaption></figure><p id="15a2" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因此，我们可以找到这个目标函数<code class="fe nk nl nm nn b">J</code>相对于每个模型系数<code class="fe nk nl nm nn b">β_1</code>到<code class="fe nk nl nm nn b">β_n</code>的梯度，并使用<strong class="lc ja">梯度上升</strong>相应地更新这些系数。梯度上升只不过是相反的梯度下降:对于模型参数的更新步骤，我们增加而不是减少梯度。换句话说，既然目标是最大化目标函数，我们就需要沿着梯度走，而不是逆着梯度走。</p><h2 id="327d" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">梯度上升算法</h2><p id="3646" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">更具体地，对于因子<code class="fe nk nl nm nn b">k</code>，目标函数相对于其模型系数<code class="fe nk nl nm nn b">β_k</code>的梯度通过简单的链式法则找到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/0c2a788cf4d39b474d135c4596eac940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msustV6suo_8GTvnF46aEw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">m:</strong> number of factors, <strong class="bd nt">n:</strong> number of skaters. Terms highlighted for clarity.</figcaption></figure><p id="5cc8" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的梯度公式——用总和和向量符号表示——一旦我们有了每对的预测概率作为列向量，我们就可以从所有 1 的向量中减去它。然后，我们将结果向量与因子<code class="fe nk nl nm nn b">k</code>的预测列(潜在得分差)进行点积。该点积的标量结果将是目标函数相对于因子<code class="fe nk nl nm nn b">k</code>的模型系数的梯度。</p><p id="04b0" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">一旦计算了所有因子的梯度，我们可以通过添加相应的梯度来更新每个因子的系数，以及学习速率α来控制梯度上升的收敛速率:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/b800d27ec11cc6b20799776acc45438e.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*CLo8h1bAT8ESZ8ajJDtNUA.png"/></div></figure><p id="ffe2" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">简而言之，梯度上升算法可以概括为以下步骤:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/927ec846bb3a3a1bc5f3174bd5b2b16d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*zee1NWRw-ySUHEsI5Ykauw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">m:</strong> number of factors, <strong class="bd nt">n:</strong> number of skaters in the world championship, <strong class="bd nt">p: </strong>each ordered pair in the world championship</figcaption></figure><p id="d846" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">对于梯度上升，可以通过检查平均对数似然(对数似然除以训练样本中有序对的数量)来监控收敛，并查看它是否在迭代之间保持稳定。除以训练对的数量使得对数似然独立于数据大小，并且更容易监控。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/f8be1e0c0aee23725b6c3e9285899b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OIQ7joW2Cy7A3cW53foEPQ.png"/></div></div></figure><h1 id="b44a" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">编码梯度上升算法</h1><h2 id="9fab" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">准备预测矩阵</h2><p id="053f" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">有了上面的梯度上升模型，让我们看看如何使用 Python 为我们的玩具示例编码。首先，在用 2 个因素训练多因素模型之后，我们现在有了一个大小为(4，2)的熊猫数据帧<code class="fe nk nl nm nn b">skater_scores</code>，它代表了这 2 个因素在 4 个溜冰者中的潜在得分。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/1e6f5a931208b1d660e1bab0eac51a4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*hwyybKVmBQ10wApyJmI6LA.png"/></div></figure><p id="837a" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">接下来，我们对这个数据帧中的运动员/行进行排序(使用<code class="fe nk nl nm nn b"><a class="ae lt" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html" rel="noopener ugc nofollow" target="_blank">reindex</a></code>方法)以匹配世界冠军排名的顺序:费尔南德斯&gt; MURA &gt;葛&gt;马约罗夫。我们还将这个数据帧转换成一个二维 numpy 数组，这样我们可以更容易地操作它:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="c149" class="nu ma iq nn b gy oj ok l ol om">world_ranking = ['Javier, FERNANDEZ', 'Takahito, MURA', 'Misha, GE', 'Alexander, MAJOROV']</span><span id="919f" class="nu ma iq nn b gy ox ok l ol om">skater_scores = skater_scores.reindex(world_ranking)<br/>skater_scores = skater_scores.values<br/># array([[16.00924627,  4.59479646],<br/>#        [14.05961149,  3.02042308],<br/>#        [11.91968361,  7.2807469 ],<br/>#        [10.22685671,  3.12272308]])</span></pre><p id="4229" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">接下来，对于每个因素，我们通过减去平均值并除以该因素的标准偏差来标准化其得分。这导致所有因子的均值为零，标准差为 1。这种标准化有两个目的:</p><ul class=""><li id="ed64" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">这将有助于梯度上升更好地收敛:通过保持预测值较小，sigmoid 函数中的指数在计算预测概率时不会内爆/爆炸。</li><li id="6c5e" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">标准化因素意味着它们现在处于相同的尺度。因此，这些因素的模型系数可以帮助我们衡量每个因素在运动员排名中的有用程度。这将在后面的结果部分探讨。</li></ul><p id="3131" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">这种标准化可以在 Python 中很容易地完成(见下文)，通过<code class="fe nk nl nm nn b">axis=0</code>取平均值和标准化，意思是跨行/滑手:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="3c1e" class="nu ma iq nn b gy oj ok l ol om">normed_skater_scores = (skater_scores - skater_scores.mean(axis=0)) / skater_scores.std(axis=0)</span></pre><p id="a57e" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">最后，我们可以使用来自<code class="fe nk nl nm nn b">itertools</code>模块的<code class="fe nk nl nm nn b"><a class="ae lt" href="https://docs.python.org/2/library/itertools.html#itertools.combinations" rel="noopener ugc nofollow" target="_blank">combinations</a></code>函数在规范化矩阵中生成有序的行对，其中第一行总是在第二行之上。结果是，从第一行减去第二行，将计算出在世界锦标赛中排名高于另一名选手(选手 B)的一名选手(选手 A)之间的潜在分数差异。</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="d4c0" class="nu ma iq nn b gy oj ok l ol om">X = np.array([row1 - row2 for row1, row2 in combinations(normed_skater_scores, 2)])</span></pre><p id="c299" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">这将为我们提供用于逻辑回归的预测矩阵，其中 6 行代表 6 个有序对，2 列代表我们示例中两个因素的潜在得分差异(见下文)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/e2ac62834e6fdbdc0895189cce2070a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUjoJl9JiUSbjOOpqF7ejA.png"/></div></div></figure><p id="75cc" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">一旦预测矩阵准备好了，我们就可以开始编写逻辑回归的梯度上升公式了。</p><h2 id="6fc9" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">步骤 1:初始化每个因子模型系数</h2><p id="d76f" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">因为在这个例子中有 2 个因子，我们可以初始化两个系数<code class="fe nk nl nm nn b">β_1</code>和<code class="fe nk nl nm nn b">β_2</code>，两者的值都是 0.5，并且包含在大小为(2)的 numpy 数组<code class="fe nk nl nm nn b">beta</code>中</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="c263" class="nu ma iq nn b gy oj ok l ol om">beta = np.full(2, 0.5)</span></pre><h2 id="f52e" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">步骤 2:计算梯度并更新系数</h2><p id="92c7" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">对于学习速率<code class="fe nk nl nm nn b">alpha = 0.01</code>，我们让梯度上升运行 100 次迭代。如下所示，算法的核心非常简单，所有重要的步骤只用了 3 行代码就完成了！</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="a04f" class="nu ma iq nn b gy oj ok l ol om">alpha = 0.01</span><span id="1feb" class="nu ma iq nn b gy ox ok l ol om"># Step 2: Repeat unitl convergence<br/>for i in range(100):<br/>    # a. Calculate predicted probabilities<br/>    prob = 1 / (1 + np.exp(-X @ beta))</span><span id="cfdb" class="nu ma iq nn b gy ox ok l ol om">    # b. Calculate gradients<br/>    gradient = (1 - prob) @ X</span><span id="da08" class="nu ma iq nn b gy ox ok l ol om">    # c. Update factor coefficients<br/>    beta = beta + alpha * gradient</span></pre><p id="0399" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">我已经在之前的<a class="ae lt" rel="noopener" target="_blank" href="/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2?source=friends_link&amp;sk=132ba842d95afc92d4e3a0dc6accc7e5">项目</a>中详细解释了上面的代码块是如何工作的，该项目也使用了逻辑回归。该项目中的梯度上升与上面的代码之间的唯一区别是:</p><ul class=""><li id="b6ae" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">这些系数现在被称为<code class="fe nk nl nm nn b">beta</code>，而不是<code class="fe nk nl nm nn b">theta</code>，因为符号θ已经被潜在因子占用</li><li id="a7c0" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">当计算梯度(<code class="fe nk nl nm nn b">y - prob</code>)时，不用算法中的响应 y，我们可以像梯度公式规定的那样使用<code class="fe nk nl nm nn b">1 - prob</code>，因为我们知道我们的地面真实响应都是 1</li></ul><p id="7868" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">下图概述了梯度上升算法第一次迭代的算法工作原理:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/bcd4afb860c145272ae09d9996431d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2X1spTrT3cyYTydRzMWQRw.png"/></div></div></figure><p id="4907" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">每次迭代后的平均对数似然性可以通过对所有概率的对数求和并除以训练样本中的对数(在本例中为 6)来轻松检查:<code class="fe nk nl nm nn b">np.log(prob).sum() / len(X)</code>。经过 100 次迭代后，平均对数似然为-0.337，迭代与迭代之间的差异为 1e-4。</p><h2 id="39eb" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">模型输出</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/94a45bae2e70558f9eeb48fbf7e7d4c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*NDOtSuxf7HUByJjOOJ_pGg.png"/></div></figure><p id="6fd3" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">对于我们的玩具示例，在梯度上升收敛之后，两个因子的模型系数对于第一个因子是 0.745，对于第二个因子是 0.367。</p><p id="8628" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">使用这些学习到的系数，我们可以最终预测在我们的训练数据中的每对选手中，第一名选手(选手 A)在世界锦标赛中排名第二名选手(选手 B)的概率。此外，如果这个概率高于 0.5，我们预测滑冰者 A 的排名将超过滑冰者 B；如果没有，我们的预测正好相反:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="8bfe" class="nu ma iq nn b gy oj ok l ol om">prob = 1 / (1 + np.exp(-X @ beta))<br/>y_pred = prob &gt; 0.5</span></pre><p id="5127" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">以下是我们玩具示例的预测概率和成对排序的结果:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/21ecd87d6d6c43ab6a6683013264ee4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kHqXaPmjsmdyOu0qTivy5w.png"/></div></div></figure><p id="28a6" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的结果中，我们可以看到预测的排名在世界锦标赛排名的 6 对有序对中得到了 5 对正确。换句话说，对于 5 个一致对和 1 个不一致对，该预测排序的肯德尔τ为(5–1)/6 = 0.67。</p><h2 id="f917" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">重建预测排名</h2><p id="c3ea" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">从每个预测的成对排序的结果(上表中最右边的一列)可以清楚地看出，唯一可以创建的预测排序是费尔南德斯&gt;葛&gt; MURA &gt;马约罗夫。让我们看看如何使用代码得出这个结论:</p><p id="3a62" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">方法 1:根据两两排名</strong></p><p id="bf51" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">首先，我们建立一个列表<code class="fe nk nl nm nn b">counter</code>来统计每个选手的分数。都将从 0 分开始。</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="719b" class="nu ma iq nn b gy oj ok l ol om">counter = [0] * 4<br/># [0, 0, 0, 0]</span></pre><p id="1f0b" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">然后，我们生成对应于六个有序对中的每一个的有序索引对。指数对的第一个数字是第一个滑手的世锦赛排名(从 0 开始)，第二个数字是第二个滑手的排名。使用<code class="fe nk nl nm nn b">combinations</code>很容易做到这一点，从技术上讲，它将创建一个生成器，但是为了清楚起见，我将它放在一个列表中。</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="797a" class="nu ma iq nn b gy oj ok l ol om">index_pairs = list(combinations(range(n_skaters), 2))<br/># [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]</span></pre><p id="bd92" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">接下来，使用<code class="fe nk nl nm nn b">zip</code>，我们将每个指数对与预测的成对排名关联起来——在<code class="fe nk nl nm nn b">y_pred</code>中的<code class="fe nk nl nm nn b">True</code>或<code class="fe nk nl nm nn b">False</code>。如果预测的成对排名是<code class="fe nk nl nm nn b">True</code>，我们在 counter 中第一个滑手的指标上加 1 分；如果预测排名是<code class="fe nk nl nm nn b">False</code>，我们给第二滑手的指数加一分。</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="b7c5" class="nu ma iq nn b gy oj ok l ol om">for y, (i, j) in zip(y_pred, index_pairs):<br/>    if y == True:<br/>        counter[i] += 1<br/>    else:<br/>        counter[j] += 1</span></pre><p id="06c3" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">下面是循环在迭代<code class="fe nk nl nm nn b">y_pred</code>和<code class="fe nk nl nm nn b">index_pairs</code>的每个元素时如何工作的示意图:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/f20377a9d198c14938a9464e98e46c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BdHbzAlYNaCGoarr8EbKlg.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">True ranking:</strong> FERNANDEZ &gt; MURA &gt; GE &gt; MAJOROV</figcaption></figure><p id="cbae" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">最后，我们根据每位选手在<code class="fe nk nl nm nn b">counter</code>中的分数重新排列世界排名，从最高到最低(因此有了<code class="fe nk nl nm nn b">reverse=True</code>的说法)。这将从逻辑回归的成对排序输出中给出我们最终的预测排序。</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="fa3a" class="nu ma iq nn b gy oj ok l ol om">world_ranking<br/>predicted_ranking = [skater for rank, skater in sorted(zip(counter, world_ranking), reverse=True)]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/6700d639e7536baade9b1d21b0fbb801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9hTrgtUTQ6FVGqiLYIeRg.png"/></div></div></figure><p id="f6f6" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">方法二:从综合因素得分</strong></p><p id="e704" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">给定<code class="fe nk nl nm nn b">beta</code>中学习到的模型系数，我们可以将其乘以标准化潜在得分的<code class="fe nk nl nm nn b">normed_skater_scores</code>矩阵，以获得每位选手在 2 个因素上的综合得分:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="94b7" class="nu ma iq nn b gy oj ok l ol om">combined_scores = normed_skater_scores @ beta</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/e9083470e8cdf64536d1820eeadb535b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4fhHTG2Uk7_5X7a1bpO-0g.png"/></div></div></figure><p id="114d" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因此，现在每个溜冰者都由一个单独的分数来表示，类似于所有以前的模型。通过将这些综合得分从最高到最低排序，我们可以得到最终的预测排名:</p><pre class="kp kq kr ks gt of nn og oh aw oi bi"><span id="ecb4" class="nu ma iq nn b gy oj ok l ol om">sorted_combined_scores = pd.Series(combined_scores, index=world_ranking).sort_values(ascending=False)<br/># Javier, FERNANDEZ     1.028974<br/># Misha, GE             0.205300<br/># Takahito, MURA        0.026682<br/># Alexander, MAJOROV   -1.260957</span><span id="1aae" class="nu ma iq nn b gy ox ok l ol om">predicted_ranking = list(sorted_combined_scores.index)<br/># ['Javier, FERNANDEZ', 'Misha, GE', 'Takahito, MURA', 'Alexander, MAJOROV']</span></pre><p id="4b04" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">两种方法给出相同排名的原因是，如果一个滑手的综合得分高于另一个滑手，那么这两个滑手的有序对的预测概率将大于 0.5，这意味着预测对将在世界锦标赛排名中成立:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pf"><img src="../Images/090bb81207e2007cbe1f351e9912ef1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8wOYkck5vtC1DOc3TU_5w.png"/></div></div></figure><p id="e62b" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">换句话说，根据运动员的综合得分对他们进行排名等同于通过前面方法中所有预测的成对排名对他们进行排名。然而，很明显，这种方法不仅更简单，而且有利于将所有因素浓缩为每个滑冰运动员的单一组合分数。</p><h1 id="848f" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">结果</h1><p id="cfbc" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">我们首先将梯度上升算法应用于 2017 赛季男性滑冰运动员的熟悉例子，每个例子有 5 个潜在因素。回想一下项目的第 3 部分, 5 个因素中没有一个可以单独产生一个像样的排名，所以让我们看看使用逻辑回归将它们结合起来是否可以使预测的排名更好。</p><p id="1678" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">首先，对于梯度上升的每次迭代，我们不仅可以跟踪平均可能性，还可以跟踪该时间点的预测排名(使用上面概述的方法)，以及来自该排名的肯德尔τ。对于梯度上升的前 250 次迭代(学习率α = 0.001)，这些可以在下面的动画仪表板中看到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/36c59eae4e08743ef7fa97145182effb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*77eSXCuDUBshjSC0Jo_VOg.gif"/></div></div></figure><p id="7b6e" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的仪表板可以看出:</p><ul class=""><li id="1c9c" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">随着梯度上升的进行，模型的平均对数似然性如预期的那样增加。250 次迭代后，对数似然收敛到-0.260，迭代与迭代之间的差异为 1e-5。肯德尔的 tau 也收敛到 0.768，即来自世界锦标赛的 276 对有序对中的 244 对正确。</li><li id="9ee6" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">这个 Kendall 的 tau 高于以前的模型，以前的模型的最高性能是 239 个正确对(来自加法和乘法模型)，以及季节平均值的基线模型，它有 234 个正确对。</li></ul><h2 id="b74f" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">可能性与准确性</h2><p id="bfeb" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">然而，在梯度上升过程中会发生一件奇怪的事情:在第 30 次迭代附近，肯德尔的τ值达到峰值 0.783(或 276 对中的 246 对)。之后，在 250 次迭代后，它收敛到只有 244 个正确对。为什么肯德尔的τ值下降，尽管只是轻微下降，而平均对数似然继续增加？</p><ul class=""><li id="18f1" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">原因在于，虽然逻辑回归直接最大化了数据的联合(对数)似然性，但这通常会(但并不总是)提高模型的预测准确性。在这种情况下，准确性意味着预测排名的肯德尔τ:正确预测的成对排名越多(一致对)，预测排名的肯德尔τ越高。</li><li id="1fdc" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">例如，假设我们的训练数据中只有 2 对，它们的真实响应都是 1。在梯度上升的一些迭代中，这两对的预测概率是 0.51 和 0.52，这给出了 0.51×0.52=0.27 的联合似然性。然而，这两对都将被正确分类，因为它们的预测概率都大于 0.5。</li><li id="7f04" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">相反，当梯度上升收敛时，预测概率为 0.49 和 0.99。这给出了 0.49×0.99=0.49 的联合可能性。虽然这种联合可能性比前一个大得多，但只有一对(预测概率为 0.99 的一对)被正确分类。</li></ul><p id="66cf" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">简而言之，与我先前的想法相反，逻辑回归经常会，但并不总是，增加模型输出的准确性。我们将很快讨论如何提高精确度，即模型的肯德尔τ。</p><h2 id="fb7e" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">综合得分</h2><p id="6c20" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">一旦我们的梯度上升算法收敛，我们就获得每个因子的模型系数(存储在<code class="fe nk nl nm nn b">beta</code>中，并显示在附图的底部)。然后，我们使用这些系数，按照前面介绍的方法，计算出每位选手的综合得分。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/dc067e382e842dae3200037b1189f7bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*JLr5lUm96iTQClws-IXmHA.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">First 5 columns:</strong> normalized scores in each factor. <strong class="bd nt">Last column:</strong> combined score from logistic regression model. <strong class="bd nt">Heatmap color:</strong> rank of a skater in each factor. <strong class="bd nt">Text color:</strong> rank of a skater in the world championship</figcaption></figure><ul class=""><li id="ac4d" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">在 5 个潜在因素中，第一个因素的<code class="fe nk nl nm nn b">β</code>系数最高。这意味着，对于任何两名选手来说，他们在这一因素上的潜在得分差异是预测一名选手是否会在世界锦标赛中超越另一名选手的最重要因素。</li><li id="6402" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">这与项目的<a class="ae lt" rel="noopener" target="_blank" href="/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&amp;sk=48c2971de1a7aa77352eb96eec77f249">第 3 部分</a>结束时的结果非常吻合，当时根据每个单独的因素对选手进行排名:仅根据第一个因素进行排名的选手在所有 5 个因素中获得了最高的肯德尔τ。这也反映在附图中:第一个因素中的等级颜色是 5 个因素中“最平滑”的。</li><li id="840f" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">然而，这与综合得分的预测排名相比就相形见绌了:一般来说，一个运动员的综合得分越高，他在世界锦标赛中的排名就越高(见随附的热图的最后一栏)。这解释了当对 5 个潜在因素应用逻辑回归时，如前所述的相对高的肯德尔τ(0.768，或 276 对中的 244 对)。然而，让我们看看这个令人鼓舞的结果是否可以进一步改善。</li></ul><h1 id="3e3a" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">增加因子的数量</h1><p id="2f46" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">由于我们可以调整每个选手的潜在因素的数量，也许更多的因素将有助于我们更好地排列选手。当我们将因子的数量增加到 50 时，结果证明这是正确的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/5b84561929cce28bcb0576d2ec65fa5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ma41eQfXZV8FgtZ0mZ_U_g.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Dashed lines:</strong> converged values (after 250 iterations) at 5 factors for comparison</figcaption></figure><ul class=""><li id="6f26" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">随着梯度上升算法的运行，其平均对数似然性迅速超过 5 因子模型，并在 250 次迭代后最终为-0.052，迭代与迭代之间的差异为 1e-4(见上图左图)。</li><li id="e564" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">更重要的是，与 5 因子模型相比，它的 Kendall 的 tau 要优越得多:它在每次迭代后都不断攀升，最终达到 1(中间面板)的完美值。这一点从动画接近尾声时预测排名和世界排名之间的完全一致可以看出(右图)。</li></ul><p id="9f34" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">然而，如果某件事看起来好得不像是真的，它很可能就是真的。这是因为:</p><ul class=""><li id="e9e1" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">通过 logistic 回归模型，我们已经使用了 2017 年世锦赛的实际成绩来训练模型系数。因此，尽管产生了一个完美的预测排名，这些系数无疑严重过度拟合了该赛季的世界锦标赛结果，并且不能很好地推广到其他赛季。</li><li id="bcc6" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">此外，即使我们要使用这些系数来预测其他赛季的排名，很明显我们应该使用许多赛季来学习它们，而不仅仅是 2017 年。</li></ul><h2 id="da74" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">模型验证计划</h2><p id="d697" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">上述警告意味着我们需要将训练集中的 10 个赛季分成两个独立的组:</p><ul class=""><li id="7c99" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="lc ja">训练组</strong>:logistic 回归模型被训练的季节</li><li id="adca" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated"><strong class="lc ja">验证组</strong>:剩余的赛季，在这些赛季中，一旦对训练组中的那些人进行了训练，就对肯德尔的τ进行评估</li></ul><p id="73d2" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">我们将使用以下步骤验证逻辑回归模型，包括对模型进行的任何改进:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pi"><img src="../Images/f54372b7c45f2b7c3a16e763873e04b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wGXLIjyIBjEMKHL2l9xgnw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Blue:</strong> train group, <strong class="bd nt">purple: </strong>validation group. After the switch in step 4, the colors are reverse — <strong class="bd nt">blue:</strong> validation group, <strong class="bd nt">purple:</strong> train group</figcaption></figure><p id="fe31" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">第一步:</strong>对于 10 个赛季中的每一个赛季，我们对赛季得分运行多因素模型，以获得该赛季的潜在选手得分。然后，我们将这些因素标准化到相同的尺度，并考虑运动员之间所有因素的差异。</p><p id="4304" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">步骤 2: </strong>对于训练组中的季节，我们将它们的差异矩阵垂直堆叠成单个预测矩阵，并使用它来训练逻辑回归模型。在梯度上升收敛之后，我们可以使用模型系数来对这些季节中的每一个进行排名，并评估该排名的肯德尔τ。从现在开始，我们将这些<strong class="lc ja">训练称为肯德尔的 taus </strong>，因为用于产生排名的模型系数是直接从世界锦标赛结果中训练出来的。</p><p id="51b0" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">第三步:</strong>类似地，对于验证组中的季节，我们也将它们的差矩阵堆叠成单个预测矩阵。然后，我们使用从步骤 2 中学习的模型系数对这些季节中的每一个进行排名，并评估该排名的肯德尔τ。从现在开始，我们将对这些<strong class="lc ja">肯德尔的 taus </strong>进行验证，因为用于产生排名的模型系数没有经过训练，而只是在这些季节进行了验证。</p><p id="bd91" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">步骤 4: </strong>为了简单起见，我们将使用 2 重<a class="ae lt" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation" rel="noopener ugc nofollow" target="_blank">交叉验证</a>来划分季节:对于 10 个季节，这意味着随机选择 5 个季节属于训练组，剩余的 5 个属于步骤 2 中的验证组。然而，在步骤 3 之后，每组中的季节被交换:那些在训练组中的人现在在验证组中，反之亦然。然后，我们重复第 2 步和第 3 步，以获得各自的训练和验证肯德尔的 tau。</p><p id="01b6" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">由于这种转换，每个赛季都将有一个相应的训练肯德尔的 tau，这涉及到一个直接从该赛季的世界冠军(在其他 4 个冠军中)训练的逻辑回归模型。每个赛季也将有一个相应的验证肯德尔的 tau，这涉及到一个在其他 5 个赛季训练的逻辑回归模型。</p><p id="3dd6" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated"><strong class="lc ja">步骤 5: </strong>对于每个季节，我们可以用基线模型的肯德尔τ减去其训练或验证的肯德尔τ(使用季节平均值)，以获得肯德尔τ的相应改善。最后，我们可以简单地对 10 个训练肯德尔的 tau 的改进进行平均，并将其与 10 个验证肯德尔的 tau 的平均改进进行比较。</p><p id="830b" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因此，前一个平均值代表直接从世界锦标赛排名训练的逻辑回归模型的排名改进(从基线模型),而后者代表间接在其他赛季训练的逻辑回归模型的改进。后者也是对该模型的更现实的评估，因为该模型将用于预测未来赛季的世界锦标赛排名，而这样的排名当然首先还不可用。</p><h2 id="9396" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">结果</h2><p id="a6eb" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">根据上面概述的模型验证计划，我们对不同数量的因子运行所有这些步骤(在α=0.005 和 1000 次迭代时)，并从基线模型获得它们在肯德尔τ中的平均训练和验证改进:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pj"><img src="../Images/809546a7a3f83eb1526018845339257c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuU_piRzXhvuREr2fQOOZw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Bold lines:</strong> average improvement in Kendall’s tau across 10 years. <strong class="bd nt">Lighter lines: </strong>improvement in Kendall’s tau for each year</figcaption></figure><p id="ea06" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">因子数增加 2 倍(从 2 一直到 128 个因子)的结果如上图所示。从这个图表中，我们可以看到:</p><ul class=""><li id="0947" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">当对直接训练的季节(蓝线)进行逻辑回归评估时，随着因子数量的增加，Kendall tau 从基线的平均改善稳步增加，并且从 16 个因子开始显著增加:训练 Kendall tau 改善的 95%置信区间在 16 个因子后飙升至水平线以上零。</li><li id="5570" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">然而，当逻辑回归被评估到它没有被训练的季节(红线)时，肯德尔的 tau 的平均改善从 2 个因素向前增加。然而，在 16 个因素之后，平均验证肯德尔的 tau 改善显著下降。</li><li id="c9ae" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">换句话说，很明显，更多的潜在因素并不总是更好:根据这些因素训练的逻辑回归模型可能在它被训练的季节表现得非常好，但在其他季节给出可怕的排名预测——这是模型过度拟合的典型标志。</li><li id="6c47" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">然而，即使在 8 个因素下，当模型在肯德尔τ中具有最高的平均验证改进时，它仍然是-0.025 的负改进。换句话说，多因素模型的表现甚至不如基线模型！诚然，这种排名预测的不良表现在统计上是微不足道的，因为其 95%的置信区间包含了零水平。</li></ul><p id="260b" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">也就是说，我们如何减少模型过度拟合，如上图所示？对于关注该项目的前几部分的读者来说，答案应该是熟悉的:提前停止。</p><h1 id="91d5" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">提前停止</h1><h2 id="aed4" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">与模型惩罚的比较</h2><p id="45de" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">在项目的前面部分，用于减少模型过度拟合的策略包括模型惩罚和早期停止。</p><ul class=""><li id="3963" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">对于项目的这一部分，模型惩罚意味着修改多因素模型的目标函数和梯度下降，以防止潜在因素变得过大，这可能会过度拟合它们所训练的赛季得分。这在项目的第 2 部分的<a class="ae lt" rel="noopener" target="_blank" href="/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&amp;sk=86881d127654ece260be2e3029dfbad2">中用单因素(混合)模型进行了演示，但是可以很容易地适应多个因素。</a></li><li id="7980" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">此外，逻辑回归模型和用于训练它的梯度上升算法也可以被罚分。实际上，这将缩小每个潜在得分的模型系数，以便逻辑回归模型不会过于适合用于训练它的世界锦标赛排名，并且可以更好地推广到其他赛季。我已经解释了 L2 惩罚(也称为<a class="ae lt" href="https://en.wikipedia.org/wiki/Tikhonov_regularization" rel="noopener ugc nofollow" target="_blank"> L2 正则化</a>)是如何实现的，以及它在我之前的<a class="ae lt" rel="noopener" target="_blank" href="/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2?source=friends_link&amp;sk=132ba842d95afc92d4e3a0dc6accc7e5">项目</a>中涉及到逻辑回归的影响。</li><li id="2095" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">每个模型都有自己的惩罚参数，控制每个模型被惩罚的程度。然而，正如在项目的第 2 部分中提到的，模型惩罚有两个主要缺点:我们必须在每次改变惩罚参数时重新运行模型，并且我们需要寻找最佳的惩罚参数。在这一部分中，对两个模型进行惩罚会变得非常繁琐。</li></ul><h2 id="4007" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">早期停止方法</h2><p id="3b7d" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">因此，减少模型过度拟合的一个更方便的方法是提前停止多因子模型的梯度下降算法和其后的逻辑回归模型的梯度上升算法。通过阻止这些算法完全收敛，我们可能不会获得最佳的训练性能，但希望这些模型不会过度适应训练数据，并更好地进行概括。</p><p id="940c" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">换句话说，我们将看到，对于任一算法，在哪个停止迭代时，我们将具有最佳验证性能，即，与基线模型相比，肯德尔τ的平均验证改进最高。因此，我们的两个模型(多因素和逻辑回归)现在总共有 3 个超参数:</p><ol class=""><li id="d56f" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln pk lp lq lr bi translated">因素数量</li><li id="40e2" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln pk lp lq lr bi translated">多因素模型梯度下降的停止迭代</li><li id="6ab9" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln pk lp lq lr bi translated">logistic 回归模型梯度上升的停止迭代</li></ol><h2 id="a43c" class="nu ma iq bd mb nv nw dn mf nx ny dp mj lh nz oa ml lj ob oc mn ll od oe mp iw bi translated">结果</h2><p id="24b9" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">对于这 3 个超参数的每个组合，我们可以记录其在肯德尔τ中与基线模型相比的平均训练和验证改进。这些结果绘制如下:</p><ul class=""><li id="9f12" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">多因子模型，停止迭代次数从 0 到 1000，间隔 20 次迭代</li><li id="3d1a" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">从 0 到 1000 停止迭代，间隔 20 次迭代的逻辑回归模型</li><li id="f103" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">因子数量以 2 的倍数增加，从 2 到 128 个因子</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pl"><img src="../Images/6203611733f85133c7a32b701b47f5fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpCJ55q5_P4v2O-dTtpE4A.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Left to right:</strong> Average train and validation Kendall’s tau improvement from baseline as number of factors increase (2 to 128)</figcaption></figure><p id="3033" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的情节中，我们可以看出:</p><ul class=""><li id="fcdd" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">除了 2 个因子，增加多因子模型的迭代次数对 Kendall 的 tau 改进几乎没有影响，在训练和验证中都是如此。这是有意义的，因为多模型仅旨在降低赛季得分的 RMSE，而不是直接降低预测排名的肯德尔τ。</li><li id="714f" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">相比之下，增加逻辑回归的迭代次数可以改善训练期间的 Kendall，特别是在因子数较高的情况下:在顶行的大多数方块中，颜色从左到右变蓝。然而，这在验证期间恶化了肯德尔τ:在底部行的大多数方块中，颜色从左到右变得更红。这表明，我们让逻辑回归模型运行的时间越长，它在训练集中对季节的拟合就越多，在验证集中对新季节的表现就越差。</li><li id="d7e2" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">然而，对肯德尔τ最显著的影响是增加因子的数量。随着因子数量的增加，在训练集中，Kendall 的 tau 的改善是显著的，这由靠近顶行末端的正方形变得更蓝来证明。不幸的是，这转化为验证集中 Kendall tau 的显著下降:接近底行末尾的方块变得更红。这与早期的观察一致，即增加因子的数量，特别是在 16 之后，将使训练季节过度拟合，并在验证集中给出新季节的可怕预测。</li></ul><p id="8bfb" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">最后，对于每个因子数，我们记录多因子和逻辑回归模型的停止迭代，其在平均验证肯德尔τ中给出最高改进:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/0dd408157e7a42824cf4921f0bfaa016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*jecAh6AYKbcXYEOIsWQZrA.png"/></div></figure><p id="3c2c" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">从上面的结果表中，一个有趣的结果立即浮现出来:</p><ul class=""><li id="e0a7" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">除了 2 个因素外，验证集中肯德尔τ的最高平均改善出现在逻辑回归的第 0 次迭代。这意味着，尽管逻辑回归成功地提高了它所训练的赛季的预测排名，但对于它所应用的新赛季，不应用逻辑回归比应用它更好！</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pn"><img src="../Images/8c7d4ac50c5b109959fcdcabe8d32ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*27bkLYWGhdDIlLEEF9toLg.png"/></div></div></figure><ul class=""><li id="6ec7" class="la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">更具体地说，回想一下，我们在梯度上升算法中将模型系数初始化为 0.5。因此，当不运行逻辑回归时，这些系数保持为 0.5。这意味着每位选手的综合得分仅仅是潜在得分相加的一半(见所附公式)。</li><li id="27a9" class="la lb iq lc b ld lu lf lv lh lw lj lx ll ly ln lo lp lq lr bi translated">换句话说，学习如何通过逻辑回归将运动员的潜在得分结合起来，似乎并不比简单地将它们相加并根据这些总和对运动员进行排名更好！</li></ul><p id="c2ca" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">在项目的下一部分中，我将解释为什么会出现这种情况，以及我们如何解决这个问题。</p><h1 id="df02" class="lz ma iq bd mb mc md me mf mg mh mi mj kf mk kg ml ki mm kj mn kl mo km mp mq bi translated">资源</h1><p id="78ee" class="pw-post-body-paragraph mr ms iq lc b ld mt ka mu lf mv kd mw lh mx my mz lj na nb nc ll nd ne nf ln ij bi translated">你可以从<a class="ae lt" href="https://see.stanford.edu/Course/CS229/" rel="noopener ugc nofollow" target="_blank"> CS229 </a>(我极力推荐的吴恩达教授讲授的机器学习课程)的相应<a class="ae lt" href="https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf" rel="noopener ugc nofollow" target="_blank">讲义</a>和<a class="ae lt" href="https://see.stanford.edu/Course/CS229/42" rel="noopener ugc nofollow" target="_blank">视频</a> <a class="ae lt" href="https://see.stanford.edu/Course/CS229/49" rel="noopener ugc nofollow" target="_blank">讲座</a>中找到 logistic 回归的推导及其梯度上升法。请注意，由于我们的训练数据只有一类预测值(全为 1)，因此之前导出的公式比典型逻辑回归模型的公式更简单。</p><p id="8cc3" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">接下来，我们使用逻辑回归来学习如何根据运动员的潜在得分对他们进行排名。这项任务属于信息检索系统中经常使用的名副其实的“学习排序”策略。例如，在向每个用户显示排名靠前的文章之前，搜索引擎需要基于某些属性对文章进行排名。更具体地说，通过利用 Kendall 的 tau 的排序度量的成对性质，我们的方法属于学习排序策略的成对子集。</p><p id="3601" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">此外，一旦计算出每个潜在因素的成对差异，我们可以使用其他分类方法，而不仅仅是逻辑回归，来预测每个观察/有序对的成对排序。例如，这里有一篇<a class="ae lt" href="http://www.herbrich.me/papers/icann99_ordinal.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>使用 SVM 来预测成对排名(也称为 RankSVM)，还有一篇可读性更强的<a class="ae lt" href="http://fa.bianp.net/blog/2012/learning-to-rank-with-scikit-learn-the-pairwise-transform/" rel="noopener ugc nofollow" target="_blank">博客文章</a>解释了它是如何工作的。</p><p id="0615" class="pw-post-body-paragraph mr ms iq lc b ld le ka mu lf lg kd mw lh ng my mz lj nh nb nc ll ni ne nf ln ij bi translated">最后，当我<a class="ae lt" href="https://stats.stackexchange.com/questions/436467/logistic-regression-does-not-seem-to-maximize-model-accuracy" rel="noopener ugc nofollow" target="_blank">问</a>关于在 Stackoverflow 上逻辑回归收敛到更高可能性但更低准确性的特殊现象时，我得到的答案链接到几个有趣的讨论。例如，这个<a class="ae lt" href="https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models" rel="noopener ugc nofollow" target="_blank">线程</a>强调了准确性实际上是一个独立于统计的问题，在本例中是逻辑回归模型。此外，准确度不仅是预测概率的函数，也是用于分类样本的阈值的函数。因此，对于许多问题来说，仅仅基于准确性来评估模型可能不是一个好主意。</p></div></div>    
</body>
</html>