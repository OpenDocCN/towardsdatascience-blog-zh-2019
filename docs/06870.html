<html>
<head>
<title>Multi-Label Image Classification with Neural Network | Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经网络的多标签图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-image-classification-with-neural-network-keras-ddc1ab1afede?source=collection_archive---------3-----------------------#2019-09-30">https://towardsdatascience.com/multi-label-image-classification-with-neural-network-keras-ddc1ab1afede?source=collection_archive---------3-----------------------#2019-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a46688981f209397b01467f522da1965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COb_VJDhaOXLh1dPlV2-DA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Image by <a class="ae kf" href="https://besthqwallpapers.com" rel="noopener ugc nofollow" target="_blank">besthqwallpapers</a></figcaption></figure><p id="3877" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本指南中，我们将介绍<strong class="ki iu">多标签</strong>分类以及我们在实施时可能面临的<strong class="ki iu">挑战</strong>。在<strong class="ki iu">多标签</strong>分类中，一个数据样本可以属于多个类别(标签)。其中在<strong class="ki iu">多类</strong>分类中，一个数据样本只能属于一个<strong class="ki iu"> </strong>类。</p><h2 id="3913" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">例子</h2><ul class=""><li id="54f8" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">根据<code class="fe mi mj mk ml b">animal image</code>预测<code class="fe mi mj mk ml b">animal</code>类是多类分类的一个例子，其中每种动物只能属于一个类别。</li><li id="28ac" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated">从<code class="fe mi mj mk ml b">movie poster</code>预测<code class="fe mi mj mk ml b">movie genre</code>是多标签分类的一个例子，一部电影可以有多种类型。</li></ul><p id="600c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在转向多标签之前，让我们先了解一下<strong class="ki iu">多类</strong>分类，因为两者有一些相似之处。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="d986" class="my lf it bd lg mz na nb lj nc nd ne lm nf ng nh lp ni nj nk ls nl nm nn lv no bi translated">多类分类</h1><p id="f306" class="pw-post-body-paragraph kg kh it ki b kj lz kl km kn ma kp kq kr np kt ku kv nq kx ky kz nr lb lc ld im bi translated">在多类别分类中，神经网络的输出节点数与类别数相同。每个输出节点属于某个类，并输出该类的分数。</p><figure class="nt nu nv nw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/9e97dc8c045ab540772b2e158cd54fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*la8LPcaBNKai5oMkR6U_xQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Multi-Class Classification (4 classes)</figcaption></figure><p id="fb46" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来自最后一层的分数通过一个<strong class="ki iu"> softmax </strong>层。softmax 层将分数转换成<strong class="ki iu">概率</strong>值。最后，数据被分类到具有最高概率值的相应类别中。下面是 softmax 函数的代码片段。</p><pre class="nt nu nv nw gt nx ml ny nz aw oa bi"><span id="65ec" class="le lf it ml b gy ob oc l od oe">def softmax(scores):</span><span id="a615" class="le lf it ml b gy of oc l od oe">    exp = np.exp(scores)<br/>    scores = exp / np.sum(exp)<br/>    return scores</span><span id="140b" class="le lf it ml b gy of oc l od oe">softmax([5, 7, 4, 6])</span><span id="0245" class="le lf it ml b gy of oc l od oe">&gt; [0.0871 0.6439 0.0320  0.2368]</span></pre><h2 id="26ef" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">损失函数</h2><ul class=""><li id="3973" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">我们一般用<code class="fe mi mj mk ml b">categorical_crossentropy</code>损失进行多类分类。</li></ul><h2 id="73f0" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">目标向量</h2><ul class=""><li id="26c0" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">我们必须向神经网络输入一个<code class="fe mi mj mk ml b">one-hot</code>编码向量作为目标。例如，如果数据属于类别 2，我们的目标向量如下。</li></ul><pre class="nt nu nv nw gt nx ml ny nz aw oa bi"><span id="47ce" class="le lf it ml b gy ob oc l od oe">[0 1 0 0]</span></pre><p id="470d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以在 Keras 中建立一个用于多类分类的神经网络，如下所示。</p><figure class="nt nu nv nw gt ju"><div class="bz fp l di"><div class="og oh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Network for Multi-Class Classification</figcaption></figure><p id="a62a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是我们如何做一个多类分类。现在让我们跳到多标签分类。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="63cc" class="my lf it bd lg mz na nb lj nc nd ne lm nf ng nh lp ni nj nk ls nl nm nn lv no bi translated">多标签分类</h1><p id="6e83" class="pw-post-body-paragraph kg kh it ki b kj lz kl km kn ma kp kq kr np kt ku kv nq kx ky kz nr lb lc ld im bi translated">唯一的区别是一个数据样本可以属于多个类。在多标签分类中，我们必须以不同的方式处理一些事情。</p><h2 id="e417" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">激活功能</h2><ul class=""><li id="dff4" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">每门课的最终分数应该是相互独立的。因此，我们不能应用<strong class="ki iu"> softmax </strong>激活，因为 softmax 将分数转换为考虑其他分数的概率。</li><li id="f1ad" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated">最终得分独立的原因显而易见。如果电影类型是<code class="fe mi mj mk ml b">action</code>，那么它不应该影响电影是否也是<code class="fe mi mj mk ml b">thriller</code>。</li><li id="2ccc" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated">我们在最后一层使用<strong class="ki iu"> sigmoid </strong>激活函数。Sigmoid 将最终节点的每个分数在 0 到 1 之间转换，而与其他分数无关。</li><li id="149f" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated">如果某一类的得分超过 0.5，则该数据被归入该类。并且可以有多个独立的得分超过 0.5 的类别。因此，数据可以分为多个类别。以下是 sigmoid 激活的代码片段。</li></ul><pre class="nt nu nv nw gt nx ml ny nz aw oa bi"><span id="cf37" class="le lf it ml b gy ob oc l od oe">def sigmoid(scores):<br/>   <br/>    scores = np.negative(scores)<br/>    exp = np.exp(scores)<br/>    scores = 1 / (1 + exp)<br/>    return scores</span><span id="df47" class="le lf it ml b gy of oc l od oe">sigmoid([2, -1, .15, 3]))</span><span id="9f3b" class="le lf it ml b gy of oc l od oe">&gt; [0.8807 0.2689 0.5374 0.9525]</span></pre><h2 id="60e1" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">损失函数</h2><ul class=""><li id="d6df" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">由于我们使用了一个<code class="fe mi mj mk ml b">sigmoid</code>激活函数，我们不得不使用<code class="fe mi mj mk ml b">binary_crossentropy</code>损失。</li></ul><h2 id="b40a" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">目标向量</h2><ul class=""><li id="51e7" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">这里我们也必须输入一个<code class="fe mi mj mk ml b">one-hot</code>编码的向量，但是可能有多个。例如，如果数据属于类别 2 和类别 4，我们的目标向量如下。</li></ul><pre class="nt nu nv nw gt nx ml ny nz aw oa bi"><span id="392d" class="le lf it ml b gy ob oc l od oe">[0 1 0 1]</span></pre><p id="4464" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图说明了多标签分类。</p><figure class="nt nu nv nw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/0696fd73a0b3016ac688f8884abeccd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgKMR74dhQi85kLx2zLC9Q.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Multi-Label Classification (4 classes)</figcaption></figure><p id="2d7e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以在 Keras 中为多标签分类建立如下的神经网络。</p><figure class="nt nu nv nw gt ju"><div class="bz fp l di"><div class="og oh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Network for Multi-Label Classification</figcaption></figure><p id="ed9a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些都是我们必须为多标签分类做出的重要改变。现在，让我们来探讨一下在多标签分类中可能面临的挑战。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="2ad8" class="my lf it bd lg mz na nb lj nc nd ne lm nf ng nh lp ni nj nk ls nl nm nn lv no bi translated">多标签分类中的数据不平衡</h1><p id="80d3" class="pw-post-body-paragraph kg kh it ki b kj lz kl km kn ma kp kq kr np kt ku kv nq kx ky kz nr lb lc ld im bi translated">多标签分类的主要挑战是数据不平衡。我们不能像在多类分类中那样简单地使用抽样技术。</p><p id="9f48" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据不平衡是机器学习中众所周知的问题。其中数据集中的一些类比其他类更频繁，神经网络只是学习预测频繁的类。</p><p id="7b0a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，如果数据集包含 100 幅猫和 900 幅狗的图像。如果我们根据这些数据训练神经网络，它每次都会学习预测狗。在这种情况下，我们可以使用采样技术轻松平衡数据。</p><ul class=""><li id="f595" class="lx ly it ki b kj kk kn ko kr oj kv ok kz ol ld me mf mg mh bi translated">通过移除一些狗的例子(下采样)</li><li id="83b6" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated">通过使用图像增强或任何其他方法创建更多的 cat 示例(上采样)。</li></ul><p id="d724" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，当我们有多标签数据时，这个问题就变得很现实。让我们看看下面的<a class="ae kf" href="https://www.kaggle.com/neha1703/movie-genre-from-its-poster" rel="noopener ugc nofollow" target="_blank">电影类型</a>数据集(40K 样本)，其中我们必须从一部电影<code class="fe mi mj mk ml b">poster</code>中预测电影<code class="fe mi mj mk ml b">genre</code>。一部电影可以属于多个类型。总共有 16 种类型的体裁。</p><figure class="nt nu nv nw gt ju gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3629db68fa4cbe4dbc34e67f8ed49b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*HNCUFXPuj7e8tNLaNzCaXQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Movie Genre Count</figcaption></figure><h2 id="8f24" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">缩减采样挑战</h2><ul class=""><li id="e6c4" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">在这个数据中，标签<code class="fe mi mj mk ml b">drama</code>和<code class="fe mi mj mk ml b">comedy</code>出现的频率非常高。但是我们不能简单地丢弃带有多数标签的数据样本，因为这些数据样本也可能与其他标签相关联。丢弃这些样本也会导致其他标签的丢失。</li></ul><h2 id="a6a6" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">上采样挑战</h2><ul class=""><li id="abde" class="lx ly it ki b kj lz kn ma kr mb kv mc kz md ld me mf mg mh bi translated">如果我们用少数类产生相似的例子，那么将会有多个具有相似模式的标签。这将增加过度拟合的机会。</li></ul></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><p id="d458" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使我们有一个理想的电影类型数据集(40K 样本)，其中所有类型在数量上是相等的。每部电影平均有两种类型。那么每个流派会出现(40000*2)/16 = 5000 次左右。我们仍然有一个不平衡的数据集，因为网络只看到每个流派的 12.5%的时间。在这种情况下，网络只是学习预测根本没有流派。</p><p id="8af8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解，下面是一步一步的计算。</p><pre class="nt nu nv nw gt nx ml ny nz aw oa bi"><span id="1820" class="le lf it ml b gy ob oc l od oe">Total samples =&gt; 40000</span><span id="2520" class="le lf it ml b gy of oc l od oe">Total genre =&gt; 16</span><span id="0d03" class="le lf it ml b gy of oc l od oe">Avg genre in one sample =&gt; 2</span><span id="2ad6" class="le lf it ml b gy of oc l od oe">Occurance of one genre in all samples =&gt; (40000*2)/16 =&gt; 5000</span><span id="1ca9" class="le lf it ml b gy of oc l od oe">Percentage of one genre per sample =&gt; 5000/40000 =&gt; 0.125 =&gt; 12.5%</span></pre><p id="57fd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决多标签分类中的数据不平衡问题，已经做了大量的研究。以下是几篇关于多标签分类和数据不平衡的论文。</p><ul class=""><li id="2dac" class="lx ly it ki b kj kk kn ko kr oj kv ok kz ol ld me mf mg mh bi translated"><a class="ae kf" href="https://www.ntu.edu.sg/home/elpwang/PDF_web/08_PPSN.pdf" rel="noopener ugc nofollow" target="_blank">用神经网络改进多标记</a></li><li id="09c1" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated"><a class="ae kf" href="https://link.springer.com/chapter/10.1007/978-3-662-44851-9_28" rel="noopener ugc nofollow" target="_blank">大规模多标签文本分类</a></li><li id="76ec" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated"><a class="ae kf" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320312001471" rel="noopener ugc nofollow" target="_blank">逆随机欠采样</a></li><li id="a3de" class="lx ly it ki b kj mm kn mn kr mo kv mp kz mq ld me mf mg mh bi translated"><a class="ae kf" href="https://link.springer.com/content/pdf/10.1007/978-3-642-41822-8_42.pdf" rel="noopener ugc nofollow" target="_blank">使用 SMOTE 管理数据不平衡</a></li></ul></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><blockquote class="on oo op"><p id="d975" class="kg kh oq ki b kj kk kl km kn ko kp kq or ks kt ku os kw kx ky ot la lb lc ld im bi translated">在我的下一篇博客中，我将会从海报项目中做<strong class="ki iu">电影类型预测</strong> <strong class="ki iu">。即多标签分类项目。在此之前，请保持联系，并准备好您的 GPU。</strong></p></blockquote></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h2 id="61d9" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">更多来自作者</h2><div class="ou ov gp gr ow ox"><a href="https://shiva-verma.medium.com/understanding-self-supervised-learning-with-examples-d6c92768fafb" rel="noopener follow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">理解自我监督学习，并举例说明</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">迈向艾将军的一步？</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">shiva-verma.medium.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl jz ox"/></div></div></a></div></div></div>    
</body>
</html>