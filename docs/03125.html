<html>
<head>
<title>Using Deep learning to save lives by ensuring driver’s attention</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习通过确保驾驶员的注意力来拯救生命</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-deep-learning-to-save-lives-by-ensuring-drivers-attention-e9ab39c03d07?source=collection_archive---------18-----------------------#2019-05-19">https://towardsdatascience.com/using-deep-learning-to-save-lives-by-ensuring-drivers-attention-e9ab39c03d07?source=collection_archive---------18-----------------------#2019-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fbe5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">现实生活中的卷积神经网络</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/64dd67187c84fac43ff9bc73b30ffa51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xMcM5J9ePF3vFL66"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@melissamj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">melissa mjoen</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="kz la lb"><p id="4cea" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">仅在 2017 年，就有 3166 人在涉及分心司机的机动车事故中丧生。— <a class="ae ky" href="https://www.nhtsa.gov/risky-driving/distracted-driving" rel="noopener ugc nofollow" target="_blank"> NHTSA </a></p></blockquote><p id="0a51" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">驾驶机动车本身就是一项复杂的任务。然而，当我们把注意力分散加入其中时，它会变得更加困难，因为道路上的司机缺乏注意力。那么，如果我们能识别司机何时分心呢？这样做将有助于我们发现它，并提醒司机，以防止事故发生！</p><p id="88e7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在这篇文章中，我将使用<strong class="lf iu">卷积神经网络</strong>来解决检测分心驾驶员的问题，甚至将他们除安全驾驶之外所做的活动分类。这里有一个<a class="ae ky" href="https://www.kaggle.com/bhanotkaran22/cnn-to-detect-driver-actions?scriptVersionId=14365759" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>的链接。</p><h1 id="bedc" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">导入库</h1><p id="6d75" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">我使用 Keras 和 Tensorflow 作为后端来创建卷积神经网络，因此，我导入了必要的库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d870" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><code class="fe nb nc nd ne b">os.environ[‘KERAS_BACKEND’] = ‘tensorflow’</code>将<code class="fe nb nc nd ne b">keras</code>后端设置为<code class="fe nb nc nd ne b">tensorflow</code>，<code class="fe nb nc nd ne b">os.environ[‘TF_CPP_MIN_LOG_LEVEL’] = ‘3’</code>隐藏所有 tensorflow 日志。</p><h1 id="f35b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">导入数据集</h1><p id="cdda" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">csv 文件<code class="fe nb nc nd ne b">driver_imgs_list.csv</code>包含所有训练图像的列表，以及对人和类名的引用。类名是对图像中的人正在进行的活动类型的引用。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/51cdb19adf5bf6b3f5f7bb1d4ae47849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*ByrPGJEuWD8xkz8hRgyCpA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Top 5 rows of the dataframe</figcaption></figure><h1 id="e127" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">图像概述</h1><p id="3414" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">我决定通过显示每个类的图像来查看图像数据集。由于标签<code class="fe nb nc nd ne b">classname</code>不是描述性的，我决定用一张地图给每张图片添加标题。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="6a2f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><code class="fe nb nc nd ne b">train</code>文件夹有 10 个文件夹，每个文件夹对应一类图像。我遍历所有文件夹，并从每个文件夹中绘制第一幅图像。使用<code class="fe nb nc nd ne b">plt.subplot(5, 2, image_count)</code>，我定义将有 10 个图像组成 5 行和 2 列。image_count 定义了从 1 到 10 范围内的图像计数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/88ac56f1489473253284cfd924a3c07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bb_x6o9QZMh4y4D-Mg4AkA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Drivers doing different things</figcaption></figure><h1 id="2ff9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">构建模型</h1><p id="9ad3" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">我将创建一个具有 3 个<code class="fe nb nc nd ne b">Conv2D</code>层(每个层后面是<code class="fe nb nc nd ne b">MaxPooling2D</code>层)、1 个<code class="fe nb nc nd ne b">Flatten</code>层和 3 个<code class="fe nb nc nd ne b">Dense</code>层的卷积神经网络。在进行了几次试验并从其他内核中获得线索后，我最终确定了神经元。因为这是一个多类问题，我有最后一个密集层，有 10 个神经元，损失是使用<code class="fe nb nc nd ne b">categorical_crossentropy</code>识别的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/2737e8c4afef53833fac0aa8630001ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2UsWrlZZRvVebmsgrWNh9g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Classifier model</figcaption></figure><h1 id="2fff" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">创建培训数据</h1><p id="ccf0" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">使用<code class="fe nb nc nd ne b">ImageDataGenerator</code>，我将增加我可以训练模型的图像数量。此外，我将使用<code class="fe nb nc nd ne b">flow_from_directory</code>方法从相应的文件夹中读取对应于每个类的图像，并创建 80%和 20%的训练和验证分割。请注意，我通过将所有值除以 255 来重新调整每张图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="3d70" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在，我将根据这些数据训练模型，并获得验证准确性和损失。</p><h1 id="51e8" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">训练模型</h1><p id="f5c4" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">用<code class="fe nb nc nd ne b">fit_generator</code>，我来训练模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><blockquote class="ni"><p id="3ab8" class="nj nk it bd nl nm nn no np nq nr ly dk translated">该模型达到了 97%的验证准确率。</p></blockquote><h1 id="c2c5" class="mc md it bd me mf mg mh mi mj mk ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/3451e7513662434884d904d8cc364b01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T63oQM0CMds3Gv1P"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@maxwellridgeway?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Maxwell Ridgeway</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ed78" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">使用<strong class="lf iu">卷积神经网络</strong>，我能够以 97% 的准确率识别驾驶员何时分心驾驶。下一步，我们可以通过增加 CNN 的复杂性和层数来进一步改进模型，并实现其对最终输出的影响。</p></div></div>    
</body>
</html>