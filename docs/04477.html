<html>
<head>
<title>All Tensors Secretly Wish to be Themselves</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">所有张量都暗暗希望做自己</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/all-tensors-secretly-wish-to-be-themselves-1ccc836df41c?source=collection_archive---------16-----------------------#2019-07-10">https://towardsdatascience.com/all-tensors-secretly-wish-to-be-themselves-1ccc836df41c?source=collection_archive---------16-----------------------#2019-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi jx"><img src="../Images/fc95aa32fd5bfe53f9d1206be1519cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olGFeWZ7FOg8237qP9oRWg.jpeg"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">Photo by <a class="ae kn" href="https://unsplash.com/@olav_ahrens?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Olav Ahrens Røtne</a>on <a class="ae kn" href="https://unsplash.com/search/photos/rubix-cube?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9a06" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">16 绝不是个大数字。计算一个卷积神经网络(CNN)需要多少 MAC 单元才能在 64 个时钟周期内从 16 深度 3×3 张量卷积中产生 16 个 16×16 区块的输出通道？</p><p id="6e7e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果不使用快速算法，将需要至少 9216 个 MAC 单元。9，216 个 MAC 单元通常用于构建 96×96 脉动阵列，但是计算 96×96 矩阵乘法(MM)至少需要 96 个时钟的等待时间。将需要一长串 96×96×96 的矩阵乘法来保持脉动阵列被占用。</p><p id="0f28" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">欢迎来到人工智能中的张量世界。现在是时候习惯维度的诅咒了。</p><h1 id="d307" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">张量与矩阵</strong></h1><p id="ef8a" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">这篇文章的标题是受 Charles F. Van Loan 教授在他 2010 年关于张量展开的<a class="ae kn" href="http://www.cs.cornell.edu/cv/SummerSchool/Unfold.pdf" rel="noopener ugc nofollow" target="_blank">演讲</a>中的一句话的启发和回应。</p><blockquote class="mp"><p id="3d13" class="mq mr it bd ms mt mu mv mw mx my ll dk translated"><em class="mz">所有张量都暗暗希望自己是矩阵！</em></p></blockquote><p id="4301" class="pw-post-body-paragraph ko kp it kq b kr na kt ku kv nb kx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">这一陈述表明了张量研究团体通过首先将张量展开成矩阵，然后利用成熟的矩阵理论框架来研究张量的愿望。即使张量被认为是所有主要人工智能框架中最基本的数据类型，将张量展平到矩阵以利用高度优化的矩阵乘法(MM)或 MM 加速器(MMA)库也是一种行业标准做法。矩阵一般被 AI 界认为是张量的特例。</p><p id="abe9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">传统智慧可能会说:</p><ol class=""><li id="c14f" class="nf ng it kq b kr ks kv kw kz nh ld ni lh nj ll nk nl nm nn bi translated">MM 中有非常好的并行性和数据共享模式可以利用。</li><li id="3d53" class="nf ng it kq b kr no kv np kz nq ld nr lh ns ll nk nl nm nn bi translated">矩阵比张量更适合可编程硬件。</li><li id="135c" class="nf ng it kq b kr no kv np kz nq ld nr lh ns ll nk nl nm nn bi translated">有一个本机硬件加速解决方案，脉动阵列，用于 MM。</li></ol><p id="00b2" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然而，</p><ol class=""><li id="fb12" class="nf ng it kq b kr ks kv kw kz nh ld ni lh nj ll nk nl nm nn bi translated">CNN 在结构上相当于 MMs。没有必要展平张量来利用 MM 等价的并行性和数据共享模式。</li><li id="f4f1" class="nf ng it kq b kr no kv np kz nq ld nr lh ns ll nk nl nm nn bi translated">当沿着存储器层级向上攀升时，矩阵针对时间局部性被递归地分块，并且针对空间局部性被打包。它们最终成为微面板，即小块行或列，由软件微内核或 GPU 着色器内核使用。</li><li id="a5ea" class="nf ng it kq b kr no kv np kz nq ld nr lh ns ll nk nl nm nn bi translated">在我对谷歌的 256x256 脉动阵列的 TPU v1 的<a class="ae kn" href="https://medium.com/@CPLu/should-we-all-embrace-systolic-array-df3830f193dc" rel="noopener">评论</a>中，解决了脉动阵列的方形诅咒的可扩展性问题。此后，使用多个相对较小的脉动阵列似乎成为主流。由于这个原因，矩阵在成为可以被脉动阵列消耗的正方形矩阵形状之前，必须被类似地分块和打包。</li></ol><p id="299e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">因此，来自展平张量的矩阵实际上被分块并打包成适当的结构，以实现高性能执行，如下图所示。前者可以称为平面展开，后者称为块展开。由于几十年来对高性能 MM 实现的研究、构建和利用块矩阵框架的努力，矩阵通常成为 CNN 和 AI 的默认数据类型。</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/e10911292a5c82d847dc8783b8dee7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o9dwlEQD9RHzLC8aPH6aqQ.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">Block-unfolding of a MM</figcaption></figure><p id="aed9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">按照传统观点，CNN 中的特征映射被强制为某个矩阵的列，卷积滤波器被展平为列中的一些连续矩阵元素。由于平面展开，失去了在空间和时间上重复使用特征图中相邻像素的可能性。</p><h1 id="969d" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">阻止张量救援</h1><p id="6c0d" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">MM 中递归矩阵块展开的一个关键特征是当矩阵靠近硬件的裸机时，高级时间和空间局部性被保留。看看 CNN 中的数据位置是否也能以张量的形式保存下来，这应该是很有趣的。</p><p id="2ed3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">合理的设计选择是将特征地图划分为分块，并保持分块结构以重复使用过滤器，利用小分块的快速算法，并实现细粒度的 SIMD 式并行。在接近裸机时，张量应保持为张量，以保持要素地图中的切片结构和数据位置不变。</p><p id="d10e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">此外，必须解决输入特征地图和输出特征地图之间的位置模式。前者允许共享来自多个输入要素地图的数据，以便计算多个输出要素地图。后者使更多的受众能够共享输入要素地图。问题是你不能共享所有的特征图，因为产生一个输出像素并不需要所有的输入特征图，并且将所有的特征图保存在芯片上是不切实际的。总结一下，所有维度都需要进行一定程度的划分或分块，这样的考虑导致张量被划分成更小的，成为<strong class="kq iu">块张量</strong>。</p><p id="d599" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">块张量是指其项是张量的张量。它是块矩阵的对等物。块张量的概念可用于解决维数灾难并保持 CNN 中的数据局部性，类似于高性能计算(HPC)行业如何采用 MM 的块矩阵概念。<strong class="kq iu">张量包</strong>，相当于 MM 中的微面板或子方阵，被定义为基本张量单元，必须对其进行原子处理以利用所有维度的空间局部性。由张量包组成的<strong class="kq iu">张量块</strong>被定义为必须在计算单元和外部存储器之间整体传输的张量单元，以促进张量包之间的时间局部性。</p><p id="982e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">原子张量包操作被定义为从最小足够数量的输入通道产生最小足够数量的最小足够大小的瓦片的输出通道。由于张量中的维数灾难，即使每个张量包在每个维度上都很小，处理这样的张量包也会变得很费力。它可以在张量块内迭代或同时应用，以解决更大的问题。这些想法在文章的其余部分得到了半正式的阐述。</p><h1 id="1a3e" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">块张量形式的 CNN</h1><p id="7c21" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">CNN 的输入<em class="nu"> A </em> <strong class="kq iu"> <em class="nu"> </em> </strong>和输出<em class="nu"> C </em> <strong class="kq iu"> <em class="nu"> </em> </strong>分别由多个输入特征图(IFM)和输出特征图(ofm)组成。它们可以被认为是三维张量，特征图的维度为<em class="nu"> x </em>，<em class="nu"> y </em> <strong class="kq iu"> <em class="nu"> </em> </strong>，索引 IFM 的输入深度为<em class="nu"> w </em> <strong class="kq iu"> <em class="nu"> </em> </strong>，索引 ofm 的输出深度为<em class="nu"> z </em>。为了实现细粒度的 SIMD 并行性并利用具有空间局部性的快速算法，每个特征图可以沿着<em class="nu"> x </em> <strong class="kq iu"> <em class="nu"> </em> </strong>和<em class="nu"> y </em> <strong class="kq iu"> <em class="nu"> </em> </strong>维度进一步划分成瓦片。复合索引<strong class="kq iu"> </strong> ( <em class="nu"> tx </em>，<em class="nu"> ty </em>)分别用于识别输入图块和输出图块。对于每一对唯一的 IFM <em class="nu"> w </em>和 OFM <em class="nu"> z </em>，都有一个滤波器<em class="nu"> B </em> ( <em class="nu"> w </em>，<em class="nu"> z </em>)，通常由 3×3 的滤波器参数组成。输入和输出张量成为图块的块张量，如下图所示</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/3e5a2cb8f3e0e85601dfc38f561b9d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qX488pPVOlmRB2t56Z65KA.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">CNN in terms of block tensors of tiles</figcaption></figure><p id="85dd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">平铺的 CNN 可以用张量理论符号更紧凑和精确地表示如下:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/4510169e0f7bd053db34369fd1b4facf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*009sTyVyvWx8hRmlSj9bUA.png"/></div></div></figure><p id="078c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">冒号表示从该维度获取所有数据。<em class="nu"> A </em>(:，:，<em class="nu"> w </em> ) <strong class="kq iu"> </strong>代表 IFM <em class="nu"> w </em>，因为它从 IFM 中取出所有的图块。</p><h1 id="c414" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">CNN 在结构上等同于 MMs</h1><p id="7cc2" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">传统观点认为，我们必须将张量展开成矩阵，以利用 MMs 中的并行性和数据共享模式。然而，实际上是反过来的。就并行性和数据共享模式而言，CNN 在结构上等同于 MMs，如下所示，这就是 MMs 在 CNN 中如此普遍使用的原因。</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/0c58db3469887759c4fdef8de8f6fd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V7HU4skA8yUQW4K1AFQJSA.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">CNNs are structurally equivalent to MMs</figcaption></figure><p id="447f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于<em class="nu"> C </em>中的行的计算是独立的，所以<em class="nu"> A </em>的行可以被阻塞。等效地，特征图可以被平铺，因为像素可以被独立计算。</p><blockquote class="nv nw nx"><p id="439a" class="ko kp nu kq b kr ks kt ku kv kw kx ky ny la lb lc nz le lf lg oa li lj lk ll im bi translated">MM 等效并行度和数据共享模式相对于切片保持不变。</p></blockquote><p id="b64e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">同一要素地图中的输出切片共享相同的过滤器，但不共享相同的输入切片。沿着输出维度的输出切片共享相同的输入切片，但不共享相同的过滤器。MMs 和 CNN 之间的等价性可以在下表中用张量理论符号更简洁地描述:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/6e49e3d97afab3b61aee46169bf60a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMEVWUm5fH6R8WA_j7eZuw.png"/></div></div></figure><h1 id="8f9c" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">深度也需要平铺(阻塞)</h1><p id="37a7" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">现在，片上存储器的成像尺寸受到限制，我们希望在片上数据块中的 IFM、ofm 和滤波器之间充分利用 CNN 中的 MM 等效数据共享模式。数据块的几何结构应该是什么样的？它必须有足够的(<em class="nu"> x </em>、<em class="nu"> y </em> ) <strong class="kq iu"> </strong>来重用过滤器，足够的<em class="nu"> w </em> <strong class="kq iu"> <em class="nu"> </em> </strong>来共享足够的输入数据，以及足够的<em class="nu"> z </em> <strong class="kq iu"> <em class="nu"> </em> </strong>来有效地共享输入数据，如下图所示:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/4726172b23ec251258a1aef34bd8ad34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cWzBIoAugUJZy2VVQOfcFQ.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">On-chip buffers must have sufficient coverages along all dimensions</figcaption></figure><p id="3013" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这个观察导致除了阻塞<em class="nu"> x </em>和<strong class="kq iu"> </strong> <em class="nu"> y </em>维度之外，阻塞<em class="nu"> w </em> <strong class="kq iu"> <em class="nu"> </em> </strong>和<em class="nu"> z </em> <strong class="kq iu"> <em class="nu"> </em> </strong>维度，这个我们已经做过了。这是为了确保输入和输出数据块分别覆盖足够数量的 IFM 和 ofm。引入新的索引<em class="nu"> tw </em>和<em class="nu"> tz </em>分别标识一组 IFM 和一组 ofm。我们将输入张量包<em class="nu"> A </em> ( <em class="nu"> tx </em>，<em class="nu"> ty </em>，<em class="nu"> tw </em>)定义为来自 IFM 组<em class="nu"> tw 的一组(<em class="nu"> tx </em>，<em class="nu"> ty </em>)对齐的图块。</em> <strong class="kq iu"> <em class="nu"> </em> </strong>同样，我们将<em class="nu"> C </em> ( <em class="nu"> tx </em>，<em class="nu"> ty </em>，<em class="nu"> tz </em> ) <strong class="kq iu"> </strong>定义为一组来自 OFM 组<em class="nu"> tz </em>的(<em class="nu"> tx </em>，<em class="nu"> ty </em>)对齐瓷砖。<em class="nu"> B </em> ( <em class="nu"> tw </em>，<em class="nu"> tz </em> ) <strong class="kq iu"> </strong>代表一组滤波器，每组用于一对来自组<em class="nu"> tw </em>的 IFM 和来自组<em class="nu"> tz </em>的 OFM。它被称为滤子张量包。输入、输出和过滤张量现在是张量包的块张量，如下所示</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/66efa40f74fb2ed6100baee3dadef346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fSn2Gk-ZcCf2xzWuofdFEA.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">CNN in terms of block tensors of tensor packets</figcaption></figure><blockquote class="nv nw nx"><p id="f953" class="ko kp nu kq b kr ks kt ku kv kw kx ky ny la lb lc nz le lf lg oa li lj lk ll im bi translated">MM 等价并行性和数据共享模式相对于张量包保持不变。</p></blockquote><p id="f3da" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">软件中的<strong class="kq iu">张量微内核</strong>或硬件中的<strong class="kq iu">张量包引擎</strong>可以被设计成处理将输入张量包<em class="nu"> A </em> ( <em class="nu"> tx </em>，<em class="nu"> ty </em>，<em class="nu"> tw </em> ) <strong class="kq iu"> </strong>与过滤张量包<em class="nu"> B </em> ( <em class="nu"> tw </em>，<em class="nu"> tz </em> ) <strong class="kq iu"> </strong>进行卷积的原子操作</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/6e864ec6ad9b36a03783d080ee8b2efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ockmZ4DNxuxDUWePJoxgYA.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">Atomic tensor packet operation</figcaption></figure><p id="3e6a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">假设输入和输出图块分别为 6x6 和 4x4，并使用 8 作为 IFM 组和 OFM 组的大小。在不使用 3×3 卷积的快速算法的情况下，在 4 个时钟内完成该运算需要 2304 个 MAC 单元。2304 路并行度在所有尺寸中相当平均地投入，包括沿特征图的<em class="nu"> x </em>和<strong class="kq iu"/>y，输入深度<em class="nu"> w </em>，输出深度<em class="nu"> z </em>。使用诸如 4x4 之类的小块尺寸的分块使得能够使用诸如 Winograd 之类的快速算法，从而仅使用 576 个 MAC 单元就可以实现 2，304 路并行。</p><h1 id="be2d" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">张量的递归分块</h1><p id="b4ff" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">张量包是计算单元整体消费的基本单位。为了保持切片之间的数据局部性和平铺结构，我们在全张量和张量包之间引入了一个中间块级别，张量块，<strong class="kq iu"> </strong>，以包括我们希望整体带到芯片上的张量包。<strong class="kq iu"> </strong>当有足够的计算单元、片上存储器和提供带宽时，它是片间时间局部性和空间局部性的基本单元。一个张量块沿<em class="nu"> x </em>、<em class="nu">、</em> <strong class="kq iu">、<em class="nu">、</em>、<strong class="kq iu">、<em class="nu">、</em>、</strong>、<em class="nu">、</em>、<em class="nu"> z </em>、<em class="nu">、</em>、</strong>维度用(<em class="nu"> bx </em>、<em class="nu"> by </em>、<em class="nu">BZ<strong class="kq iu">、<em class="nu">、</em>。</strong></em></p><p id="6141" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下面是一个张量递归分块的例子。整体张量是 4x4 瓦片的 4x 4 块张量的 4x2 块张量，4x 4 瓦片的 1x1x8 块张量，其中(<em class="nu"> dx </em>，<em class="nu"> dy </em>)是在瓦片内寻找像素的偏移，<em class="nu"> dz </em>是标识组内特定特征图的索引。</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/9c5d99baf48081328575249e7070037b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*khKdOUjgvtG3myY-XguSQw.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">Recursive blocking of tensors to preserve locality in a feature map</figcaption></figure><p id="3986" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">张量块线性存储在内存中。我们不需要担心它们是如何准确排序的。对于张量块，将有两种不同的块展开顺序，一种优化为将张量块存储到 DRAM，另一种优化为将其呈现给计算单元。如下所示，将需要软件和/或硬件中的转置机制来动态地从一种格式转置到另一种格式。</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="gh gi nt"><img src="../Images/87aa66ebaf739b47315a898e931826b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1E0PQ2aIzE_CNLDroNQvyw.png"/></div></div><figcaption class="kj kk gj gh gi kl km bd b be z dk">Transposition of a tensor block</figcaption></figure><p id="0cb6" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">执行转置的等待时间可以由双缓冲来覆盖。当张量块被呈现给计算单元时，它被展开成(<em class="nu"> tx </em>、<em class="nu"> ty </em>)主顺序的张量包，因此张量包可以在(<em class="nu"> x </em>、<em class="nu"> y </em>)域中并行处理，计算单元相应地排列。</p><h1 id="3bc8" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">所有张量都暗暗希望做自己</h1><p id="9a61" class="pw-post-body-paragraph ko kp it kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk ll im bi translated">Van Loan 教授在关于块张量的块展开的<a class="ae kn" href="https://www.cs.cornell.edu/cv/OtherPdf/CVLTahoe.pdf" rel="noopener ugc nofollow" target="_blank">演讲</a>中也说过:</p><blockquote class="mp"><p id="ed9a" class="mq mr it bd ms mt mu mv mw mx my ll dk translated"><em class="mz">块展开保留了数据的结构和局部性。…在我看来，分块最终会在张量计算中产生与矩阵计算相同的影响。</em></p></blockquote><p id="bfbc" class="pw-post-body-paragraph ko kp it kq b kr na kt ku kv nb kx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">张量被分块展开成用于多维中的时间局部性的张量块，使得当被带到芯片上时，数据可以在多维中共享。张量块被进一步分块展开成张量包，这些张量包在所有维度上具有最低限度的足够覆盖。在本例中，处理这样的张量包需要 2304 路并行处理。MM 等价并行和数据共享模式应用于张量块中的张量包。</p><p id="ee28" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">据我们所知，这篇文章中所讨论的可能是计算史上第一次尝试在裸机上采用块张量的概念。对于处理高分辨率视频/图像的应用，可以实现跨越<em class="nu"> x </em>和<em class="nu"> y </em>维度的可扩展和更大的并行性。CNN 凭借其革命性的力量和在张量中的根深蒂固，可能会成为 block tensors 的第一个杀手级应用。</p><blockquote class="mp"><p id="2f32" class="mq mr it bd ms mt mu mv mw mx my ll dk translated">所有张量都暗暗希望自己是 block 张量，期待自己的潜力得到释放，实现 AI 硬件的突破。</p></blockquote></div></div>    
</body>
</html>