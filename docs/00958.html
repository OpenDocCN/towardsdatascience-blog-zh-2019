<html>
<head>
<title>Review: Highway Networks — Gating Function To Highway (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:高速公路网络-高速公路的门控功能(影像分类)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5?source=collection_archive---------4-----------------------#2019-02-13">https://towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5?source=collection_archive---------4-----------------------#2019-02-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8fe9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">高速公路网，受 LSTM 启发，使用门控功能，超过 1000 层。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e724e0dad0a35573bca908a1dfcb13e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NZca6-4NId0eT9Dm.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Gating Function to Highway</strong></figcaption></figure><p id="ea07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">在</span>这个故事中，<strong class="ky ir">高速公路网</strong>被简要介绍。这是 2015 年的作品。此时，发现很难优化非常深的神经网络。然而，为什么深度网络难以优化仍然是一个公开的问题。(当然后来很可能是因为渐变消失问题。)受长短期记忆(LSTM)的启发，作者由此<strong class="ky ir">利用选通函数来自适应地转换或绕过信号，以便网络可以更深入。【1000 层以上的深度网络也可以优化。我选择提交这篇论文是为了介绍门控函数。</strong></p><p id="295f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">公路网络最初出现在<strong class="ky ir"> 2015 年 ICML 深度学习研讨会</strong>上，并作为<strong class="ky ir"> 2015 arXiv </strong>技术报告发布，引用超过<strong class="ky ir"> 600 次</strong>。随后在<strong class="ky ir"> 2015 NIPS </strong>进行了扩展和发布，引用超过<strong class="ky ir"> 500 次</strong>。(<a class="mb mc ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----5a33833797b5--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="e05e" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">概述</h1><ol class=""><li id="42a7" class="nc nd iq ky b kz ne lc nf lf ng lj nh ln ni lr nj nk nl nm bi translated"><strong class="ky ir">公路网</strong></li><li id="7d20" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr nj nk nl nm bi translated"><strong class="ky ir">结果</strong></li><li id="7d97" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr nj nk nl nm bi translated"><strong class="ky ir">分析</strong></li></ol></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="af5b" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak"> 1。公路网</strong></h1><h2 id="3076" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">1.1.普通网络</h2><ul class=""><li id="e1cc" class="nc nd iq ky b kz ne lc nf lf ng lj nh ln ni lr oe nk nl nm bi translated">在谈论公路网之前，让我们从由<em class="of"> L </em>层组成的平面网络开始，其中第<em class="of"> l </em>层(省略层的符号):</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/66b055a9a5e4ff5bef77c5b2e8eeea29.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*YhZvuvA3R2SlCYfr33-tDg.png"/></div></figure><ul class=""><li id="fc3d" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">其中<em class="of"> x </em>为输入，<em class="of"> WH </em>为权重，<em class="of"> H </em>为转换函数，后接激活函数，<em class="of"> y </em>为输出。对于第<em class="of"> i </em>个单元:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/3d9ae38c3b6e566e1b6152cd6c1f678e.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*PS49eKYiLkCaNaV40jPBkQ.png"/></div></figure><ul class=""><li id="49f1" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">我们计算<em class="of"> yi </em>并将其传递给下一层。</li></ul><h2 id="f042" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">1.2.公路网</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/33088b2d49fc38122347b426ed48840e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*qHf_AHv8yJJsKQok4KS4Jw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Highway Circuit</strong></figcaption></figure><ul class=""><li id="698f" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">在公路网络中，引入了两种非线性变换<strong class="ky ir"> <em class="of"> T </em> </strong>和<strong class="ky ir"> <em class="of"> C </em> </strong>:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e5691ea79b9507bec6ba82e05fcc79ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*9bWianQfCF3Kkc9qJZEL6A.png"/></div></figure><ul class=""><li id="ee84" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">其中<strong class="ky ir"> <em class="of"> T </em>是转换门</strong>，而<strong class="ky ir"> C 是进位门</strong>。</li><li id="b4bf" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">特别是<strong class="ky ir"><em class="of">C</em>= 1-<em class="of">T</em></strong>:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/22d041007d14497dde6c5a3b0d31e80b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*GbI3ZOBVjrP_tdx7Nmzw-A.png"/></div></figure><ul class=""><li id="755c" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">对于特定的<em class="of"> T </em>值，我们可以有以下条件:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/1be74f7b63648750e7b54e013b0ece1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*6BqqE5Leg4ad7dx4dWwWTA.png"/></div></figure><ul class=""><li id="b3ea" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">当 T = 0 时，我们将输入作为输出直接传递，这就创建了一条信息高速公路。所以才叫高速公路网！！！</li><li id="1680" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">当<em class="of"> T </em> =1 时，我们使用非线性激活的变换输入作为输出。</li><li id="483c" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">在此，对比平面网络中的第<em class="of"> i </em>个单元，作者引入了<strong class="ky ir"> <em class="of">块</em> </strong>的概念。对于第<strong class="ky ir"><em class="of">I</em>-第</strong>块，有一个<strong class="ky ir">块状态<em class="of"> Hi </em> ( <em class="of"> x </em> ) </strong>，<strong class="ky ir">变换门输出<em class="of"> Ti </em> ( <em class="of"> x </em> ) </strong>。与相应的<strong class="ky ir">块输出<em class="of">yi</em>T25】:</strong></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/97bab8b485ca122219bd6e1f7947d5c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*g-ELP2-gARx37EeTN_3ddQ.png"/></div></figure><ul class=""><li id="473e" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">其连接到下一层。</li><li id="a5d6" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">形式上，<strong class="ky ir"> T( <em class="of"> x </em>)是 sigmoid 函数</strong>:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/e2ac4ea92bcca68e9e78d80f928b18c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*Tmr0VX6wDmlQcJ_drYVF4w.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl or"><img src="../Images/8d3a49da2bff65a9087b998c76daacaf.png" data-original-src="https://miro.medium.com/v2/format:webp/1*sOtpVYq2Msjxz51XMn1QSA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Sigmoid Function</strong></figcaption></figure><ul class=""><li id="f11e" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">如果我们记得，sigmoid 函数将输出限制在 0 到 1 之间。当输入值太小时，它变成 0。当输入值太大时，它会变成 1。<strong class="ky ir">因此，通过学习<em class="of"> WT </em>和<em class="of"> bT </em>，网络可以自适应地传递<em class="of"> H </em> ( <em class="of"> x </em>)或者只是传递<em class="of"> x </em>到下一层。</strong></li><li id="f2fc" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">作者声称这有助于为<em class="of"> WT </em>提供一个简单的初始化方案，该方案独立于<em class="of"> H </em>的性质。</li><li id="9748" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated"><em class="of"> bT </em>可以用负值初始化(如-1，-3 等。)使得网络最初偏向进位行为。</li><li id="7576" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">上述想法是作者提到的 LSTM 的启发。(LSTM 是一个非常著名的模块，主要用于自然语言处理(NLP))</li><li id="5f14" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">而<strong class="ky ir">随机梯度下降(SGD)对于超过 1000 层的网络并没有失速。</strong>然而，确切的结果尚未提供。</li></ul></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="11a9" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">2.结果</h1><h2 id="c706" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">2.1.MNIST</h2><ul class=""><li id="37e1" class="nc nd iq ky b kz ne lc nf lf ng lj nh ln ni lr oe nk nl nm bi translated">第一个图层是完全连接的平原图层，随后是 9、19、49 或 99 个完全连接的平原或公路图层。最后，网络输出由 softmax 层产生。</li><li id="cfbb" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">所有网络都很薄:<strong class="ky ir">高速公路网络的每层有 50 个块</strong>而普通网络的每层有 71 个单元，每层产生大致相同数量的参数(5000)。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/6f8d1024360aa2b7f06a8d496e68aaa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KL1tKMvoOeNbV618BaJuqQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">The best training curves for Plain Networks (Left) The best training curves for Highway Networks (Right) Mean performance of top 10 (out of 100) hyperparameter settings.</strong></figcaption></figure><ul class=""><li id="45df" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">如上所示，公路网得到的误差总是小于平面网得到的误差。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/9addcf8a8b2309360a81dfd1f8ac4a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2kYXTk_SxO_nyIYLtfvpWQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">MNIST Test Accuracy</strong></figcaption></figure><ul class=""><li id="ccf7" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">MNIST 的 10 层卷积高速公路网络使用两种架构进行训练，每种架构有 9 个卷积层，后跟一个 softmax 输出。所有图层的<strong class="ky ir">滤镜贴图数量(宽度)设置为 16 和 32 </strong>。</li><li id="11aa" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">与 Maxout 和 DSN 相比，<strong class="ky ir">公路网获得了相似的精度，但参数数量要少得多。</strong>(如果有兴趣，请访问我关于 NoC 的评论，了解关于 Maxout 的非常简要的介绍。)</li></ul><h2 id="d0ff" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">2.2.西法尔-10 和西法尔-100</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/a77d99cf69cc57dd4c4b2de9c2e000a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4CAIntvaaKyQ4_A5vgLjQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">CIFAR-10 Test Accuracy</strong></figcaption></figure><ul class=""><li id="3eef" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">当网络很深时，Fitnet 不能直接优化网络。它需要两个阶段的训练。</li><li id="c49f" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">通过使用门控功能，Highway 可以直接优化深层网络。特别是，高速公路 B 以 19 层获得了最高的精度。</li><li id="132d" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">虽然公路 C 不如公路 B，但由于门控函数的存在，它仍然可以直接优化。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/2c278429f6ac81f60e31d19d99786c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nl4LGt3CSJ6v6TmheMX0SQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">CIFAR-10, CIFAR-100 Test Accuracy</strong></figcaption></figure><ul class=""><li id="87a2" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">这里，先前实验中网络中使用的全连接层被替换为具有大小为 1 的感受域的卷积层和全局平均池层。</li><li id="4e34" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated"><strong class="ky ir">公路网在 CIFAR-10 上可以获得相当的性能，在 CIFAR-100 上可以获得最高的精度。</strong></li></ul></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="704f" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">3.<strong class="ak">分析</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/ecd7f648bca34cecbf0f976c93e06109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0bx93p0s_LKEmdLeN6Rplw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Visualization of best 50 hidden-layer highway networks trained on MNIST (top row) and CIFAR-100 (bottom row)</strong></figcaption></figure><ul class=""><li id="7225" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">上图分别显示了偏差、所有训练样本的平均活动以及每个变换门的单个随机样本的活动。同一单个样本的块输出显示在最后一列。</li><li id="9227" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">对于 CIFAR-100 网络，<strong class="ky ir">偏差随着深度增加</strong>形成梯度。在较低深度的强负偏压不是用来关闭闸门，而是使它们更有选择性。这使得单个示例(列 3)的转换门活动非常稀疏。</li><li id="8990" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">对于 CIFAR-100 情况，大多数转换门平均都是活动的，而对于单个示例，它们显示出非常有选择性的活动。这意味着对于每个样本，只有几个块执行变换，但是不同的样本使用不同的块。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/173e8a9a9f5164a386cef71c92d1fa3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Basod4iJGAO_HocYJUrUw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Visualization showing the extent to which the mean transform gate activity for certain classes differs from the mean activity over all training samples</strong></figcaption></figure><ul class=""><li id="db45" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">对于 MNIST 数字 0 和 7，在前 15 层中可以看到显著的差异。</li><li id="8faa" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">对于 CIFAR 类编号 0 和 1，差异更小，并且分布在所有层上。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/7412598312335480ed78667fbd11a578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AYDefmVEQNxZeTUbJJFMLA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Lesioned training set performance</strong></figcaption></figure><ul class=""><li id="499d" class="nc nd iq ky b kz la lc ld lf oh lj oi ln oj lr oe nk nl nm bi translated">通过破坏，它意味着手动将一个层的所有变换门设置为 0，强制它简单地复制其输入。如上所示，对于每一层，在该层的门关闭的情况下，在完整的训练集上评估网络。</li><li id="2ad3" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">对于 MNIST(左)，可以看出，如果移除任何一个早期层，则<strong class="ky ir">误差显著上升，但是</strong> <strong class="ky ir">层 15-45 似乎对最终性能几乎没有影响。</strong>大约 60%的图层不会影响最终结果，可能是因为<strong class="ky ir"> MNIST 是一个简单的数据集，不需要太多深度。</strong></li><li id="7a2b" class="nc nd iq ky b kz nn lc no lf np lj nq ln nr lr oe nk nl nm bi translated">虽然 CIFAR-10 是一个相对复杂的数据集，但误差会更大。</li></ul></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="0ef1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过查看高速公路网络，我们可以了解使用 Sigmoid 的<strong class="ky ir">门控功能。希望我能在未来回顾循环公路网。</strong></p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h2 id="d734" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">参考</h2><p id="cbf8" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf oz lh li lj pa ll lm ln pb lp lq lr ij bi translated">【2015】【arXiv】<br/><a class="ae pc" href="https://arxiv.org/abs/1505.00387" rel="noopener ugc nofollow" target="_blank">公路网</a></p><p id="a755" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【2015】【NIPS】<br/><a class="ae pc" href="https://arxiv.org/abs/1507.06228" rel="noopener ugc nofollow" target="_blank">训练非常深的人脉</a></p><h2 id="6c87" class="ns ml iq bd mm nt nu dn mq nv nw dp mu lf nx ny mw lj nz oa my ln ob oc na od bi translated">我以前的评论</h2><p id="4da9" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf oz lh li lj pa ll lm ln pb lp lq lr ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(们)(还)(不)(想)(到)(这)(些)(人)(们)(,)(我)(们)(们)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(们)(还)(没)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(里)(来)(。 )(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(里)(去)(,)(我)(们)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(里)(去)(了)(,)(我)(们)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(到)(这)(里)(来)(。</p><p id="8b77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">物体检测<br/></strong><a class="ae pc" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae pc" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae pc" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae pc" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae pc" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a>】<a class="ae pc" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae pc" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766">离子</a><a class="ae pc" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径网</a><a class="ae pc" href="https://medium.com/datadriveninvestor/review-noc-winner-in-2015-coco-ilsvrc-detection-object-detection-d5cc84e372a" rel="noopener">NoC</a> yolo 9000[<a class="ae pc" rel="noopener" target="_blank" href="/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6">yolov 3</a>][<a class="ae pc" rel="noopener" target="_blank" href="/review-fpn-feature-pyramid-network-object-detection-262fc7482610">FPN</a>][<a class="ae pc" rel="noopener" target="_blank" href="/review-retinanet-focal-loss-object-detection-38fba6afabe4">retina net</a>][<a class="ae pc" rel="noopener" target="_blank" href="/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44">DCN</a>]</p><p id="6582" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">语义切分<br/></strong><a class="ae pc" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a><a class="ae pc" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a><a class="ae pc" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplab v1&amp;deeplab v2</a><a class="ae pc" rel="noopener" target="_blank" href="/review-segnet-semantic-segmentation-e66f2e30fb96">SegNet</a>】<a class="ae pc" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a><a class="ae pc" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a><a class="ae pc" rel="noopener" target="_blank" href="/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d">PSP net</a><a class="ae pc" rel="noopener" target="_blank" href="/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74">deeplab v3</a></p><p id="fc65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">生物医学图像分割<br/> </strong> [ <a class="ae pc" href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" rel="noopener">累计视觉 1 </a> ] [ <a class="ae pc" href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" rel="noopener">累计视觉 2/DCAN</a>][<a class="ae pc" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760">U-Net</a>][<a class="ae pc" href="https://medium.com/datadriveninvestor/review-cfs-fcn-biomedical-image-segmentation-ae4c9c75bea6" rel="noopener">CFS-FCN</a>][<a class="ae pc" href="https://medium.com/datadriveninvestor/review-u-net-resnet-the-importance-of-long-short-skip-connections-biomedical-image-ccbf8061ff43" rel="noopener">U-Net+ResNet</a>]</p><p id="3134" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 实例分段 <br/> </strong> <a class="ae pc" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a> <a class="ae pc" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a> <a class="ae pc" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413"> MultiPathNet </a> <a class="ae pc" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a> <a class="ae pc" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92"> InstanceFCN </a> <a class="ae pc" rel="noopener" target="_blank" href="/review-fcis-winner-in-2016-coco-segmentation-instance-segmentation-ee2d61f465e2"> FCIS </a>】</p><p id="58de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">)(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p></div></div>    
</body>
</html>