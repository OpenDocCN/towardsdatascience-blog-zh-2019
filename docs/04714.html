<html>
<head>
<title>The proper way of handling mixed-type data. State-of-the-art distance metrics.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理混合型数据的正确方式。最先进的距离度量。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-proper-way-of-handling-mixed-type-data-state-of-the-art-distance-metrics-505eda236400?source=collection_archive---------9-----------------------#2019-07-18">https://towardsdatascience.com/the-proper-way-of-handling-mixed-type-data-state-of-the-art-distance-metrics-505eda236400?source=collection_archive---------9-----------------------#2019-07-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9879" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">有趣的事实:</strong> Scikit-Learn 没有<em class="ko">任何能够处理分类和连续数据的</em> <strong class="js iu"> </strong>距离度量！如果我们有一个混合类型变量的数据集，那么我们如何使用聚类算法，例如 k-NN？</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/6a7879fe47c64d23342a3d219bc52493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Tf8ufZ5cYwdWeiG1"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Photo by <a class="ae lf" href="https://unsplash.com/@thefredyjacob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Fredy Jacob</a> on <a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d4a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">更新(27/07/19) </strong> —该包已在 PyPI 发布为<a class="ae lf" rel="noopener" target="_blank" href="/distython-5de10f342c93"> Distython </a>。我已经发表了一篇<a class="ae lf" rel="noopener" target="_blank" href="/distython-5de10f342c93">文章</a>来解释它是如何工作的。</p><p id="a605" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在<a class="ae lf" href="http://www.it-innovation.soton.ac.uk/" rel="noopener ugc nofollow" target="_blank"> IT 创新中心</a>的暑期实习期间遇到的一个大问题是，缺乏既能处理混合类型数据又能处理缺失值的距离度量的现有实现。它开始了我对能够满足这些要求的算法的长期探索。在几篇研究论文之后，我发现了非常有趣的距离度量，当处理混合类型的数据、缺失值或两者兼而有之时，这些度量可以帮助提高机器学习模型的准确性。我在业余时间实现了它们，并在<a class="ae lf" href="https://github.com/KacperKubara/heterogeneous_dist_metrics" rel="noopener ugc nofollow" target="_blank"> Github </a>上发布了它们的代码实现，所以你可以通过 Scikit-Learn 轻松使用它们。但是怎么做呢？我将在本教程中解释这一点！</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><p id="b5ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我喜欢数据科学的原因是，它吸引了许多对人工智能和数据科学充满热情的志同道合的人。这就是为什么我想在 Linkedin 上与你联系！您也可以通过我的<a class="ae lf" href="http://www.kacperkubara.com" rel="noopener ugc nofollow" target="_blank">个人网站</a>留下任何反馈和问题。</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h1 id="e4ad" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">异构距离度量概述</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ml"><img src="../Images/e77a121253745f4aefa5c2e9db616c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZWstOu2SrFDflR8l"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Photo by <a class="ae lf" href="https://unsplash.com/@anniespratt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Annie Spratt</a> on <a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5e67" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们开始之前，我想推荐看一下<a class="ae lf" href="https://arxiv.org/pdf/cs/9701101.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文</a>，如果你想更深入地了解我将要谈到的算法。我在这里的主要目标是为您提供对这些算法的直观理解，以便您可以将我的文章用作快速参考表。你可以在文章的最后找到实用的部分，并附上代码。我们开始吧！</p><h2 id="b009" class="mm lo it bd lp mn mo dn lt mp mq dp lx kb mr ms mb kf mt mu mf kj mv mw mj mx bi translated">距离度量</h2><p id="6e49" class="pw-post-body-paragraph jq jr it js b jt my jv jw jx mz jz ka kb na kd ke kf nb kh ki kj nc kl km kn im bi translated">但是等等……距离度量实际上是什么？距离度量测量数据集中两个实例之间的距离。它们根据实例的特征来度量它们之间的相似性。比如，假设某医院的病人有两个属性:<em class="ko">身高</em>和<em class="ko">年龄</em>。那么，我们可以说，某个医院的老病人和矮病人会非常相似，而一个年轻的高个子病人不会与老病人和矮病人有那么多相似之处。</p><p id="33d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">距离度量只是算法，它可以根据属性告诉你两个实例之间的相似性。一些最流行的距离度量是欧几里德距离、曼哈顿距离、汉明距离和余弦距离。它们通常用于聚类，例如最近邻算法。</p><p id="1bf8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大多数流行的距离度量只能处理一种类型的变量。如果您将它们用于包含混合类型变量或缺失值的数据集，它们会非常失败。幸运的是，研究人员一直在试图解决这个问题，而且很少有有趣的最先进的算法来帮助你克服这个问题。</p><h2 id="96aa" class="mm lo it bd lp mn mo dn lt mp mq dp lx kb mr ms mb kf mt mu mf kj mv mw mj mx bi translated">异质欧几里德重叠度量(HEOM)</h2><p id="d80c" class="pw-post-body-paragraph jq jr it js b jt my jv jw jx mz jz ka kb na kd ke kf nb kh ki kj nc kl km kn im bi translated">HEOM 可以处理异构数据以及缺失值。简单地说，它结合了 3 种不同的算法来处理每种情况。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nd"><img src="../Images/7fb5f99d87461fa0044b2faa186eb740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uWTDixScxJv-6njSgCJOIw.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">HEOM, overview [1]</figcaption></figure><p id="1318" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">HEOM 查看实例的每个属性(<em class="ko"> x </em>和<em class="ko"> y </em>)，并根据数据类型进行以下计算:</p><ul class=""><li id="92b2" class="ne nf it js b jt ju jx jy kb ng kf nh kj ni kn nj nk nl nm bi translated">如果分类-如果属性属于同一类，则返回 0，否则返回 1</li><li id="f1ec" class="ne nf it js b jt nn jx no kb np kf nq kj nr kn nj nk nl nm bi translated">If numerical 使用归一化欧几里得度量计算距离</li><li id="084d" class="ne nf it js b jt nn jx no kb np kf nq kj nr kn nj nk nl nm bi translated">如果缺失—返回 1</li></ul><p id="4b48" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们获得一个存储每个属性的距离的结果向量。为了计算最终结果，可以使用以下等式:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ns"><img src="../Images/6a357f750e2e419498c5668a34640039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3vvCfx_N_l9QZOdmyku30A.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">The final result of HEOM [1]</figcaption></figure><p id="0fa8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它是每个距离平方的和，并存储在结果向量中。不需要使用平方根，因为它不会改变两个实例之间的相似性(即，如果<strong class="js iu"> <em class="ko"> a &gt; b </em> </strong>则这也成立:<strong class="js iu"><em class="ko">sqrt(a)&gt;sqrt(b)</em></strong>)，并且减少了必要的计算总量。</p><p id="0bad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">算法实现可以在我的 Github 库<a class="ae lf" href="https://github.com/KacperKubara/heterogeneous_dist_metrics/blob/master/HEOM.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="5fc2" class="mm lo it bd lp mn mo dn lt mp mq dp lx kb mr ms mb kf mt mu mf kj mv mw mj mx bi translated">价值差异度量(VDM)</h2><p id="c8b4" class="pw-post-body-paragraph jq jr it js b jt my jv jw jx mz jz ka kb na kd ke kf nb kh ki kj nc kl km kn im bi translated">这一个实际上不直接处理异构数据，但是一些异构距离度量使用它作为他们算法的一部分。这就是为什么对它的工作原理有一个直观的理解是有好处的。这里的数学可能有点复杂，但算法的一般概念并不困难。这个等式是基于条件概率的。对于数据中的特定列(属性)，满足值<strong class="js iu"> <em class="ko"> x </em> </strong>和<strong class="js iu"> <em class="ko"> y </em> </strong>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nt"><img src="../Images/9d499eaf6bf8d8852f158d2094e4a983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ygb59ZAEfJsi-wBQ7vAbIA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">VDM algorithm [1]</figcaption></figure><p id="df28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<strong class="js iu"> <em class="ko"> P a，x，c </em> </strong>是在给定列(属性)<strong class="js iu"><em class="ko"/></strong><em class="ko"/>和输出类<em class="ko"> </em> <strong class="js iu"> <em class="ko"> c. </em> </strong>的情况下，出现值<strong class="js iu"> <em class="ko"> x </em> </strong> <em class="ko"> </em>的条件概率如果你仍然感到困惑，请参考<a class="ae lf" href="https://arxiv.org/pdf/cs/9701101.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文</a>以获得更好的理解！</p><p id="11f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该指标只能处理分类数据，因此特征和结果变量都必须是分类的。稍后，您将看到围绕此问题的一些解决方法，包括离散化线性要素或将其用作更复杂算法的一部分。</p><h2 id="4d5f" class="mm lo it bd lp mn mo dn lt mp mq dp lx kb mr ms mb kf mt mu mf kj mv mw mj mx bi translated">异类值差异度量(HVDM)</h2><p id="a8d9" class="pw-post-body-paragraph jq jr it js b jt my jv jw jx mz jz ka kb na kd ke kf nb kh ki kj nc kl km kn im bi translated">与 HEOM 类似，该指标使用不同的算法处理每种数据类型(分类、数值或缺失)。你可以把它看作是赫姆和 VDM 的结合。对于连续数据，使用归一化距离，它基本上是两个值之间的距离除以 4 *方差。对于 HEOM 也是如此，但唯一的区别是分母(使用方差是更好的选择，因为它处理数据集中的异常值)。对于分类数据，使用归一化 VDM。最终距离如下所示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/27b84ff703fa1b2a6854daedf6f417ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*eMAwtP3wkm9wkSc2Uf34Tg.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">HVDM — final distance [1]</figcaption></figure><p id="bcaf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这三种情况中的每一种都可以用下面的等式来描述:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/833dfa1a481247c9639e29d4bf9b308a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*OKJE1o_AbtHN7pDyl5tYQg.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">HVDM — distance metric for each case [1]</figcaption></figure><p id="e73d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据这篇论文，归一化的 VDM 有 3 种不同的类型:n1、n2 或 n3。我不会在这里详细讨论——这超出了本文的范围，也没有必要对算法有一个很好的、直观的理解。你要知道的是，论文作者声称 n2 是最准确的。</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h1 id="2fc2" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">实用部分</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nw"><img src="../Images/e69ecbcc64c782cc514c4f37eae71066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5uGRXQHJzxZKRnHf"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Photo by <a class="ae lf" href="https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Chris Ried</a> on <a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c5f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用那个<a class="ae lf" href="https://github.com/KacperKubara/heterogeneous_dist_metrics" rel="noopener ugc nofollow" target="_blank"> Github 库</a>进行实践。到目前为止，我已经实现了 HEOM，VDM 正在开发中。请随意在 Github 上创建一个 PR 来为项目做贡献。从头开始编写这些算法并确保它们正确运行需要花费大量时间，因此非常感谢您的帮助！</p><p id="8852" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要安装存储库，请按照自述文件中的说明进行操作。只需要使用一个简单的命令<em class="ko"> git clone、</em>和可选的<a class="ae lf" href="https://realpython.com/pipenv-guide/" rel="noopener ugc nofollow" target="_blank"><em class="ko">pipenv</em></a><em class="ko">install</em>来安装必要的包。</p><p id="0135" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些指标被设计成可以直接应用于 Scikit-Learn 中的最近邻(和其他聚类算法)类。您可以将它与 Scikit-Learn 类一起用于您的个人项目，只要它们提供一个调用定制度量函数的接口。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Importing necessary libraries</figcaption></figure><p id="8d42" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面的代码中，我们导入了必要的库和 HEOM 度量。我们还将使用波士顿房价数据集，因为它同时具有分类和数字特征。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Define the indices for categorical variables and NaN equivalent</figcaption></figure><p id="97e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里，我们导入数据并将其定义为 boston_data。这里重要的部分是我们必须告诉 HEOM 度量什么列是分类的。<em class="ko"> nan_eqv </em>在这里用来告诉 HEOM<em class="ko">NaN</em>是如何表示的。需要注意的重要一点是:最近邻不能直接处理<em class="ko"> np.nan </em>，所以我们<em class="ko">必须</em>声明某些 nan 等价。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Introducing missingness to dataset</figcaption></figure><p id="f66b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面的代码部分中，我们将缺失引入数据(出于示例的目的)并将其指定为<em class="ko"> nan_eqv。</em></p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Defining heom_metric and neighbor</figcaption></figure><p id="86da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们定义我们的<em class="ko"> heom_metric </em>并提供必要的参数。它必须在<em class="ko">最近邻居</em>之前定义，因为我们必须提供一个从<em class="ko"> heom_metric </em>到<em class="ko">邻居</em>实例<em class="ko">的可调用度量函数。</em>这就是将 HEOM 与 Scikit-Learn 一起使用的全部内容。这很简单，不是吗？有关使用 Scikit-Learn 的自定义距离度量的更多信息，可在<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Fitting the data and printing the results</figcaption></figure><p id="e151" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在最后一步中，我们拟合模型，并使用 HEOM 作为距离度量函数返回 5 个最近邻。</p><p id="8e07" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是处理具有异构距离度量的混合类型数据集的全部工作。我希望你现在配备了一些新的工具，可以帮助你建立更准确的机器学习模型，也希望你对处理缺失数据更有信心！</p><h2 id="afe6" class="mm lo it bd lp mn mo dn lt mp mq dp lx kb mr ms mb kf mt mu mf kj mv mw mj mx bi translated">参考</h2><p id="93a9" class="pw-post-body-paragraph jq jr it js b jt my jv jw jx mz jz ka kb na kd ke kf nb kh ki kj nc kl km kn im bi translated">[1] D. Randall Wilson，Tony R. Martinez，“改进的异质距离函数”</p></div></div>    
</body>
</html>