<html>
<head>
<title>How to Generate Prediction Intervals with Scikit-Learn and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Scikit-Learn 和 Python 生成预测区间</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-generate-prediction-intervals-with-scikit-learn-and-python-ab3899f992ed?source=collection_archive---------0-----------------------#2019-05-08">https://towardsdatascience.com/how-to-generate-prediction-intervals-with-scikit-learn-and-python-ab3899f992ed?source=collection_archive---------0-----------------------#2019-05-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ece7e8ca44f8814d0b61639bb2540934.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9DfJMKRbzKClTEdHPOz_tw.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://www.pexels.com/photo/adventure-clouds-daylight-fog-551876/" rel="noopener ugc nofollow" target="_blank">(Source)</a></figcaption></figure><div class=""/><div class=""><h2 id="d00e" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">使用梯度推进回归器显示机器学习估计中的不确定性</h2></div><p id="5305" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“所有的模型都是错误的，但有些是有用的”——乔治·博克斯。当我们提出机器学习预测时，记住这个明智的建议至关重要。所有的机器学习管道都有局限性:影响目标的特征不在数据中<a class="ae jd" href="https://en.wikipedia.org/wiki/Latent_variable" rel="noopener ugc nofollow" target="_blank">(潜在变量)</a>，或者模型做出的假设与现实不符。当我们显示一个预测的精确数字时，这些都被忽略了——房子将是 450，300.01 美元——这给人的印象是我们完全相信我们的模型是真实的。</p><p id="c164" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">显示模型预测的一种更诚实的方式是估计范围:可能有一个最可能的值，但也有一个真实值可能存在的较大区间。这不是数据科学课程中通常涉及的主题，但我们在预测中展示不确定性，并且不要过度吹嘘机器学习的能力，这一点至关重要。虽然人们渴望确定性，但我认为展示一个包含真实值的宽预测区间比一个远离现实的精确估计要好。</p><p id="3082" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将介绍一种在 Scikit-Learn 中产生不确定性区间的方法。完整的代码可以在 GitHub 的<a class="ae jd" href="https://github.com/WillKoehrsen/Data-Analysis/tree/master/prediction-intervals" rel="noopener ugc nofollow" target="_blank">上找到，在 nbviewer 上有一个互动版的</a><a class="ae jd" href="https://nbviewer.jupyter.org/github/WillKoehrsen/Data-Analysis/blob/master/prediction-intervals/prediction_intervals.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本。</a>我们将主要关注<em class="lr">的实现</em>，在最后有一个简短的部分和理解<em class="lr">理论</em>的资源。生成预测区间是数据科学工具箱中的另一个工具，对于赢得非数据科学家的信任至关重要。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ls"><img src="../Images/d5d5ddeaa08115063a3919595fc5247c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aFE7c-4k1JRuRkBG2XXUUQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Prediction intervals we’ll make in this walkthough.</figcaption></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="50a1" class="me mf jg bd mg mh mi dn mj mk ml dp mm le mn mo mp li mq mr ms lm mt mu mv mw bi translated">问题设置</h2><p id="cce2" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">在这次演练中，我们将使用在<a class="ae jd" href="https://drivendata.org" rel="noopener ugc nofollow" target="_blank"> DrivenData </a>上举办的机器学习竞赛中的真实建筑能源数据。你可以在这里获得原始数据<a class="ae jd" href="https://www.drivendata.org/competitions/51/electricity-prediction-machine-learning/" rel="noopener ugc nofollow" target="_blank">，但是我已经在 GitHub </a>中提供了一个<a class="ae jd" href="https://github.com/WillKoehrsen/Data-Analysis/tree/master/prediction-intervals/data" rel="noopener ugc nofollow" target="_blank">清理过的版本，它具有以 15 分钟为间隔测量的能量和八个特征。</a></p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="0072" class="me mf jg nd b gy nh ni l nj nk">data.head()</span></pre><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/c3ed9532238a1c79d24477a3ecfbbd7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHY-Mtodp_cAplzVeVAhiA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Cleaned building energy data</figcaption></figure><p id="5f83" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">目标是从特征中预测能量消耗。(这是我们在<a class="ae jd" href="http://get.cortexintel.com" rel="noopener ugc nofollow" target="_blank"> Cortex Building Intel 每天都要做的实际工作！)</a>。毫无疑问，我们的数据中存在未捕捉到的影响能源消耗的隐藏特征(潜在变量),因此，我们希望通过预测能源使用的上限和下限<em class="lr">来显示我们估计中的不确定性。</em></p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="bf54" class="me mf jg nd b gy nh ni l nj nk"># Use plotly + cufflinks for interactive plotting<br/>import cufflinks as cf</span><span id="44a1" class="me mf jg nd b gy nm ni l nj nk">data.resample('12 H').mean().iplot()</span></pre><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/fed8f5e1ca306b328281534a2307eed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D_oJ-EZPlj-4TKDUakkzxQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Building energy data from DrivenData (hosting machine learning competitions for good!)</figcaption></figure><h2 id="785b" class="me mf jg bd mg mh mi dn mj mk ml dp mm le mn mo mp li mq mr ms lm mt mu mv mw bi translated">履行</h2><p id="d6d7" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">为了在 Scikit-Learn 中生成预测区间，我们将使用<a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" rel="noopener ugc nofollow" target="_blank">梯度推进回归器</a>，从文档中的<a class="ae jd" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html" rel="noopener ugc nofollow" target="_blank">这个示例</a>开始工作。基本想法很简单:</p><ol class=""><li id="77ee" class="no np jg kx b ky kz lb lc le nq li nr lm ns lq nt nu nv nw bi translated">对于较低的预测，使用<code class="fe nx ny nz nd b">GradientBoostingRegressor(loss=<br/>"quantile", alpha=lower_quantile)</code>和代表下限的<code class="fe nx ny nz nd b">lower_quantile</code>，比如 0.1 代表第 10 个百分位数</li><li id="5439" class="no np jg kx b ky oa lb ob le oc li od lm oe lq nt nu nv nw bi translated">对于上限预测，使用带有代表上限的<code class="fe nx ny nz nd b">upper_quantile</code>的<code class="fe nx ny nz nd b">GradientBoostingRegressor(loss=<br/>"quantile", alpha=upper_quantile)</code>，比如 0.9 代表第 90 百分位</li><li id="56ab" class="no np jg kx b ky oa lb ob le oc li od lm oe lq nt nu nv nw bi translated">对于中间预测，使用预测中间值的<code class="fe nx ny nz nd b">GradientBoostingRegressor(loss="quantile", alpha=0.5)</code>，或预测平均值的默认<code class="fe nx ny nz nd b">loss="ls"</code>(对于<a class="ae jd" href="https://en.wikipedia.org/wiki/Least_squares" rel="noopener ugc nofollow" target="_blank">最小二乘法)。文档中的例子使用了后一种方法，我们也将这样做。</a></li></ol><p id="a293" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在高层次上，损失是由模型优化的函数。当我们将损失改变为分位数并选择α(分位数)时，我们能够得到对应于百分位数的预测。如果我们使用较低和较高的分位数，我们可以产生一个估计范围。(我们不会在这里讨论分位数损失的细节——参见下面分位数损失的背景。)</p><p id="5d1f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在将数据分成训练集和测试集之后，我们构建模型。我们实际上必须使用 3 个独立的梯度推进回归器，因为每个模型都在优化不同的函数，并且必须单独训练。</p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="b7cc" class="me mf jg nd b gy nh ni l nj nk">from sklearn.ensemble import GradientBoostingRegressor</span><span id="10f1" class="me mf jg nd b gy nm ni l nj nk"># Set lower and upper quantile<br/>LOWER_ALPHA = 0.1<br/>UPPER_ALPHA = 0.9</span><span id="3354" class="me mf jg nd b gy nm ni l nj nk"># Each model has to be separate<br/>lower_model = GradientBoostingRegressor(loss="quantile",                   <br/>                                        alpha=LOWER_ALPHA)<br/># The mid model will use the default loss<br/>mid_model = GradientBoostingRegressor(loss="ls")</span><span id="7634" class="me mf jg nd b gy nm ni l nj nk">upper_model = GradientBoostingRegressor(loss="quantile",<br/>                                        alpha=UPPER_ALPHA)</span></pre><p id="05fe" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练和预测使用熟悉的 Scikit-Learn 语法:</p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="f1de" class="me mf jg nd b gy nh ni l nj nk"># Fit models<br/>lower_model.fit(X_train, y_train)<br/>mid_model.fit(X_train, y_train)<br/>upper_model.fit(X_train, y_train)</span><span id="814b" class="me mf jg nd b gy nm ni l nj nk"># Record actual values on test set<br/>predictions = pd.DataFrame(y_test)</span><span id="d6b2" class="me mf jg nd b gy nm ni l nj nk"># Predict<br/>predictions['lower'] = lower_model.predict(X_test)<br/>predictions['mid'] = mid_model.predict(X_test)<br/>predictions['upper'] = upper_model.predict(X_test)</span></pre><p id="179d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就这样，我们有了预测区间！</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/e8a038cd460cfa4af9a7e4105081052b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FvUnkmLwTf6RcDOPYUenww.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Prediction intervals from three Gradient Boosting models</figcaption></figure><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/3a73e4eae026525b4d01678ce73b912a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qJ6LM2gVYqe8eXDkjYu-eQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Prediction intervals visualized</figcaption></figure><p id="2a4e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用一点点 plotly 的<a class="ae jd" href="https://plot.ly/python/" rel="noopener ugc nofollow" target="_blank">，我们可以生成一个很好的交互剧情。</a></p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/38ba81622cc1944605eeba3b6511e20e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kopq21brXj38XnDQxsSBPw.gif"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Interactive plot produced with plotly</figcaption></figure><h2 id="ce4b" class="me mf jg bd mg mh mi dn mj mk ml dp mm le mn mo mp li mq mr ms lm mt mu mv mw bi translated">计算预测误差</h2><p id="d06a" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">与任何机器学习模型一样，我们希望在测试集(我们有实际答案的地方)上量化我们预测的误差。测量预测区间的误差比点预测稍微复杂一点。我们可以计算实际值在该范围内的时间百分比，但这可以通过使间隔非常宽来容易地优化。因此，我们还需要一个考虑到预测值与实际值有多远的度量，比如绝对误差。</p><p id="6dc8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在笔记本中，我提供了一个函数来计算下、中和上预测的绝对误差，然后对“区间”绝对误差的上下误差进行平均。我们可以对每个数据点都这样做，然后绘制误差的箱线图(边界内的百分比在标题中):</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/8794e072571efc8b767d3125447cbac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvZ_46jnKJ1bDX3VSVGfqA.png"/></div></div></figure><p id="73fb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有趣的是，对于这个模型，较低预测的中值绝对误差实际上小于中间预测。这个模型没有很高的精度，可能会受益于优化(调整模型超参数)。实际值有一半以上的时间处于下限和上限之间，我们可以通过降低下分位数和提高上分位数来提高这个指标的精度。</p><p id="8bba" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可能有更好的指标，但我选择了这些，因为它们计算简单，易于解释。您使用的实际指标应该取决于您试图解决的问题和您的目标。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="37ef" class="me mf jg bd mg mh mi dn mj mk ml dp mm le mn mo mp li mq mr ms lm mt mu mv mw bi translated">预测区间模型</h2><p id="3dd9" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">用 3 个独立的模型进行拟合和预测有些繁琐，因此我们可以编写一个模型，将梯度推进回归量包装到一个类中。它源自 Scikit-Learn 模型，因此我们使用相同的语法进行训练/预测，只是现在它在一个调用中:</p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="c66a" class="me mf jg nd b gy nh ni l nj nk"># Instantiate the class<br/>model = GradientBoostingPredictionIntervals(<br/>    lower_alpha=0.1, upper_alpha=0.9<br/>)</span><span id="6ab7" class="me mf jg nd b gy nm ni l nj nk"># Fit and make predictions<br/>_ = model.fit(X_train, y_train)<br/>predictions = model.predict(X_test, y_test)</span></pre><p id="8bff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型还带有一些绘图工具:</p><pre class="lt lu lv lw gt nc nd ne nf aw ng bi"><span id="a0fe" class="me mf jg nd b gy nh ni l nj nk">fig = model.plot_intervals(mid=True, start='2017-05-26', <br/>                           stop='2017-06-01')<br/>iplot(fig)</span></pre><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/3f2a5a48e29f69521c6ad9628660bf90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1laBTVzA2UvFe1P7tdwjxQ.png"/></div></div></figure><p id="720b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请按照您认为合适的方式使用和调整模型！这只是进行不确定性预测的一种方法，但我认为它很有用，因为它使用了 Scikit-Learn 语法(意味着一条浅的学习曲线)，我们可以根据需要对它进行扩展。一般来说，这是解决数据科学问题的好方法:从简单的解决方案开始，只在需要时增加复杂性！</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="2558" class="me mf jg bd mg mh mi dn mj mk ml dp mm le mn mo mp li mq mr ms lm mt mu mv mw bi translated">背景:分位数损失和梯度推进回归变量</h2><p id="5a50" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">梯度推进回归器是一个集合模型，由单独的决策树/回归树组成。(模型的原解释见<a class="ae jd" href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" rel="noopener ugc nofollow" target="_blank">弗里德曼 1999 年的论文《贪婪函数逼近:一种梯度助推机》</a>。)与并行训练树的随机森林相反，梯度增强机器顺序训练树，每棵树从当前集合的错误(残差)中学习。树对模型的贡献是通过最小化模型预测和训练集中实际目标的损失函数来确定的。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7e40287ac37605ca3dd66fb1b7a26792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*hOlfwj8qHYNhygocwtm7Eg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Each iteration of the gradient boosting machine trains a new decision/regression tree on the residuals <a class="ae jd" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwji_obJmIziAhVhT98KHUEDAbYQjhx6BAgBEAM&amp;url=https%3A%2F%2Fmedium.com%2Fmlreview%2Fgradient-boosting-from-scratch-1e317ae4587d&amp;psig=AOvVaw1gY1KBEhTRQtlp8NI7oSOa&amp;ust=1557413755162687" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><p id="903a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用默认损失函数-最小二乘法-梯度推进回归器预测平均值。理解的关键点是最小平方损失<em class="lr">同等地惩罚低误差和高误差</em>:</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ol"><img src="../Images/214630e0034086b59f8b7f6c18d8b8e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9uQqtlppKe-yWr1AVndh3g.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Least squares loss versus error</figcaption></figure><p id="86d1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相反，<a class="ae jd" href="https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0" rel="noopener ugc nofollow" target="_blank">分位数损失</a>基于分位数以及误差是正(实际&gt;预测)还是负(实际&lt;预测)来惩罚误差。这允许梯度推进模型不是针对平均值而是针对百分位数进行优化。分位数损失为:</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/b5bec67139bb97d0674d201cf946fa49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFxYODNn1-HIkGqVSTlLAQ.png"/></div></div></figure><p id="6b55" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中<strong class="kx jh"> α </strong>是分位数。让我们快速地看一个例子，实际值为 10，分位数为 0.1 和 0.9:</p><ol class=""><li id="e854" class="no np jg kx b ky kz lb lc le nq li nr lm ns lq nt nu nv nw bi translated">如果<strong class="kx jh"> α </strong> = 0.1，预测值= 15，那么损失=(0.1–1)*(10–15)= 4.5</li><li id="8cec" class="no np jg kx b ky oa lb ob le oc li od lm oe lq nt nu nv nw bi translated">如果<strong class="kx jh"> α </strong> = 0.1，预测值= 5，那么损失= 0.1 *(10–5)= 0.5</li><li id="ae30" class="no np jg kx b ky oa lb ob le oc li od lm oe lq nt nu nv nw bi translated">如果<strong class="kx jh"> α </strong> = 0.9，预测= 15，那么损耗=(0.9–1)*(10–15)= 0.5</li><li id="55ea" class="no np jg kx b ky oa lb ob le oc li od lm oe lq nt nu nv nw bi translated">如果<strong class="kx jh"> α </strong> = 0.9，预测值= 5，那么损失= 0.9 *(10–5)= 4.5</li></ol><p id="92a5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于分位数&lt; 0.5, if the prediction is greater than the actual value (case 1), the loss is greater than for a prediction an equal distance above the actual value. For a quantile &gt; 0.5，如果预测小于实际值(情况 4)，则损失大于低于实际值相等距离的预测。如果分位数== 0.5，那么高于和低于实际值的预测会产生相等的误差，并且<em class="lr">模型会针对中值进行优化。</em></p><p id="97c5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(对于 mid 模型，我们可以使用<code class="fe nx ny nz nd b">loss="quantile", alpha=0.5</code>表示中值，或者使用<code class="fe nx ny nz nd b">loss="ls"</code>表示平均值)。</p><p id="7e24" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">分位数损失最好用损失与误差的关系图来说明:</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi on"><img src="../Images/1ff1d7d04a703dc1ebd1ce353d2ceec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FeAVKaY8_-rxLWBktjbDbQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Quantile loss versus error for different quantiles</figcaption></figure><p id="b94b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">分位数&lt; 0.5 drive the predictions below the median and quantiles &gt; 0.5 驱动预测高于中位数。这是一个很好的提醒，机器学习方法的<em class="lr">损失函数决定了你要优化什么！</em></p><p id="b758" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据我们想要的输出，我们可以优化平均值(最小平方)、中值(alpha == 0.5 的分位数损失)或任何百分位数(alpha ==百分位数/ 100 的分位数损失)。这是分位数损失的一个相对简单的解释，但它足以让您开始通过模型演练生成预测间隔。为了更进一步，查看这篇文章或者从维基百科页面<a class="ae jd" href="https://en.wikipedia.org/wiki/Quantile_regression" rel="noopener ugc nofollow" target="_blank">开始</a>并查看源代码。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="616c" class="oo mf jg bd mg op oq or mj os ot ou mm km ov kn mp kp ow kq ms ks ox kt mv oy bi translated">结论</h1><p id="fc99" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">从机器学习模型预测单个数字会给人一种错觉，即我们对整个建模过程有很高的信心。然而，当我们记住任何模型都只是一个近似值时，我们看到了在进行估计时需要用<em class="lr">来表示不确定性。</em>一种方法是使用 Scikit-Learn 中的梯度推进回归器生成预测区间。这只是预测范围的一种方法(例如，参见<a class="ae jd" href="https://stats.stackexchange.com/questions/85560/shape-of-confidence-interval-for-predicted-values-in-linear-regression" rel="noopener ugc nofollow" target="_blank">线性回归的置信区间</a>)，但它相对简单，可以根据需要进行调整。在本文中，我们看到了一个完整的实现，并了解了分位数损失函数背后的一些理论。</p><p id="9599" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">解决数据科学问题就是在你的工具箱中有许多工具可以根据需要应用。生成预测间隔是一项有用的技术，我鼓励您阅读本演练并将其应用于您的问题。(学习任何技术的最好方法是通过实践！)我们知道机器学习可以做一些非常不可思议的事情，但它并不完美，我们不应该这样描述它。为了获得决策者的信任，我们通常需要给出的不是一个单一的数字作为我们的估计，而是一个预测范围，表明所有模型中固有的不确定性。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ls"><img src="../Images/4e1377743b59a4ce38178732e652a4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_HpxMeqg51l-eaOkcxFRQ.png"/></div></div></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="81c6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我写数据科学，偶尔也写一些其他有趣的话题。你可以在 twitter 上关注我<a class="ae jd" href="http://twitter.com/@koehrsen_will" rel="noopener ugc nofollow" target="_blank">以获得有用的技术和工具。如果拯救世界同时帮助底线对你有吸引力，那么请联系我们</a><a class="ae jd" href="http://get.cortexintel.com" rel="noopener ugc nofollow" target="_blank"> Cortex。</a></p></div></div>    
</body>
</html>