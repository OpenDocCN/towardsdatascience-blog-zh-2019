<html>
<head>
<title>Must-Read Papers on GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于 GANs 的必读论文</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/must-read-papers-on-gans-b665bbae3317?source=collection_archive---------10-----------------------#2019-03-04">https://towardsdatascience.com/must-read-papers-on-gans-b665bbae3317?source=collection_archive---------10-----------------------#2019-03-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0de8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成对抗网络是深度学习最有趣和最流行的应用之一。本文将列出 10 篇关于 GAN 的论文，它们将为您提供关于 GAN 的精彩介绍以及理解最新技术水平的基础。让我们来看看这份列表吧！</p><p id="6a83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你对阅读每篇论文的描述不感兴趣，这里有一个快速列表:</p><p id="5704" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1—dcgan</p><p id="7a8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2 —训练 GANs 的改进技术</p><p id="a206" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3—有条件的 GANs</p><p id="1e55" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4 —逐渐增长的天然气水合物</p><p id="9b5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5 —比根</p><p id="d94f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">6 — StyleGAN</p><p id="5d90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">7 — CycleGAN</p><p id="33bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">8 像素 2 像素</p><p id="390e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">9 —堆栈根</p><p id="3fba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">10 —生成性敌对网络</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="b07f" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">拉德福德等人(2015 年)</h1><p id="7dd0" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">我建议您从 DCGAN 白皮书开始您的 GAN 之旅。本文展示了如何将卷积层用于 GANs，并为此提供了一系列额外的架构指南。论文还讨论了诸如 GAN 特征可视化、潜在空间插值、使用鉴别器特征训练分类器以及结果评估等主题。所有这些额外的主题一定会出现在你的 GAN 研究中。总之，DCGAN 论文是一篇必须阅读的 GAN 论文，因为它以如此清晰的方式定义了架构，以至于很容易从一些代码开始，并开始开发 GAN 的直觉。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lw"><img src="../Images/79d1015970eafb15efb653d7b1a0ab46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2NFOGSwW8XCZfMzu2gz-DA.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">DCGAN model — generator architecture with upsampling convolutional layers</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1511.06434" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">深度卷积生成对抗网络的无监督表示学习</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">近年来，卷积网络的监督学习(CNN)在计算机视觉领域得到了广泛应用…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="5cbf" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">训练 GANs 的改进技术——Salimans 等人(2016 年)</h1><p id="cd22" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">这篇文章(作者包括 Ian Goodfellow)提供了一系列建议，用于在上面的 DCGAN 文章中列出的体系结构指南的基础上进行构建。本文将帮助你理解 GAN 不稳定性的最佳假设。此外，本文还提供了许多旨在稳定 DCGANs 训练的附加技术。这些包括特征匹配、小批量鉴别、历史平均、单侧标签平滑和虚拟批量标准化。使用这些建议构建一个简单的 DCGANs 实现是学习更多关于 gan 的一个很好的练习。</p><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1606.03498" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">训练 GANs 的改进技术</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们提出了各种新的建筑特点和培训程序，我们适用于生成性对抗…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="fa5b" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">有条件的 GANs — Mirza 和 Osindero (2014 年)</h1><p id="255f" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">这是一篇很棒的论文，可以快速阅读。有条件的 GANs 是最先进的 GANs 的核心主题。本文展示了集成数据的类别标签如何产生更稳定的 GAN 训练。这种用先验信息调节 GAN 的概念在 GAN 研究的未来工作中是一个反复出现的主题，对于专注于图像到图像或文本到图像的论文尤其重要。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nd"><img src="../Images/d0067b153ebdc3d2cbeb2c24004d88c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bDTxgALN7bRXMOMSXXfCCA.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Architecture of the Conditional GANs, in addition to the random noise vector z, the class label y is concatenated together as input to the network</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1411.1784" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">条件生成对抗网</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">生成对抗网[8]是最近引入的一种训练生成模型的新方法。在这项工作中，我们…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="b9ff" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">逐步种植 gan 以提高质量、稳定性和变化性——Karras 等人(2017 年)</h1><p id="63fd" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">由于其令人印象深刻的结果和解决 GAN 问题的创造性方法，日益增长的 GAN 架构是必读的。本文使用多尺度架构，其中 GAN 的分辨率从 4 到 8，最高可达 1024。GAN 不稳定性相对于目标图像分辨率大小大大增加，本文给出了解决该问题的方法。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/950a4464265a30e1ed3eda1ec06d7a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*-yWq7Pps_0wzRcM-tMOBfQ.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">This image depicts the multi-scale architecture of the Progressively Growing GAN architecture. The model goes from 4² progressively up to 1024²</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1710.10196" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">为了提高质量、稳定性和多样性而逐步种植甘蔗</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们描述了一种新的生成式对抗网络的训练方法。关键的想法是增长发电机…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="2324" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">比根-布洛克等人(2019 年)</h1><p id="dfe0" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">BigGAN 模型是 ImageNet 生成的最新技术。这个模型很难在本地机器上实现，该架构有许多组件，如自关注、光谱归一化和带投影鉴别器的 cGAN，这些组件在各自的论文中有更好的解释。然而，这篇文章提供了一个很好的概述，包括当前最先进的基础论文的思想。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nf"><img src="../Images/6a956436776af94de5e74070f23216fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sxmw8DbslfqgBVuFe2sUuA.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Unbelievable samples from the BigGAN state-of-the-art model</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1809.11096" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">用于高保真自然图像合成的大规模 GAN 训练</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">尽管最近在生成图像建模方面取得了进展，但成功地从图像生成高分辨率、多样化的样本…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="273a" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">StyleGAN-Karras 等人(2019 年)</h1><p id="e970" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">StyleGAN 模型可以说是最先进的，尤其是在潜在空间控制方面。这个模型借用了一种被称为自适应实例规范化(AdaIN)的神经风格转移机制，来控制潜在空间向量 z，这与之前的任何东西都不同。映射网络和 AdaIN 调节在整个生成器模型中的分布相结合，使得自己实现起来相当困难，但它仍然是一个很好的读物，包含许多有趣的想法。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/3d3a30ccc04654875c117b5927316a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*ZXDIjsL3c8y1q53AOPjwQw.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">StyleGAN architecture that allows for state-of-the-art latent space control</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1812.04948" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">一种基于风格的生成对抗网络生成器体系结构</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们借鉴风格转移理论，提出了一种新的生成对抗网络生成器结构</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="488f" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">CycleGAN —朱等(2017)</h1><p id="8349" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">CycleGAN 的论文不同于前面提到的 6 篇论文，因为它讨论的是图像到图像的转换问题，而不是从随机向量合成图像。CycleGAN 更具体地处理图像到图像转换的情况，其中没有成对的训练样本。然而，这是一篇值得一读的好文章，仅仅是因为周期一致性损失公式的优雅和这如何稳定 GAN 训练的直觉。CycleGAN 还可以用于许多很酷的应用，如超分辨率、风格转换和马到斑马。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1a33bf0ed591466b97953b915cba56c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*bzUSPC5h6I7QdMgdJD85Pg.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Central Idea behind the Cycle Consistency Loss, a sentence translated from French to English and back to French should be the same sentence</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1703.10593" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">使用循环一致对抗网络的不成对图像到图像翻译</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">图像到图像的翻译是一类视觉和图形问题，其目标是学习图像和图形之间的映射</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="0a2d" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">Pix2Pix — Isola 等人(2016 年)</h1><p id="db3a" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Pix2Pix 是另一种图像到图像转换 GAN 模型。该框架使用成对的训练样本，并在 GAN 模型中用许多不同的配置进行研究。在阅读这篇论文时，我最感兴趣的事情之一是关于 PatchGAN 的讨论。PatchGAN 查看图像的 70 x 70 个区域来确定它们是真的还是假的，而不是查看整个图像。这个模型还展示了一个有趣的 U-Net 风格的生成器架构，以及在生成器模型中使用 ResNet 风格的跳过连接。这有许多很酷的应用，如边缘映射到照片般逼真的图像。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/7e5001cfe16aeeb72e5ff7a49e625cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*hE0JuFziPLUo-sc1eG0RbA.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Image-to-Image translation with paired training samples</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1611.07004" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">基于条件对抗网络的图像到图像翻译</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们研究条件对抗网络作为图像到图像翻译问题的通用解决方案…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="0a1f" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">StackGAN —张等(2017)</h1><p id="d465" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">StackGAN 的论文与列表中的前几篇论文非常不同。它非常类似于有条件的 gan 和渐进增长的 gan。StackGAN 模型的工作原理类似于渐进式增长的 GAN，因为它适用于多种规模。StackGAN 首先输出分辨率为 64 的图像，然后将其作为先验信息来生成分辨率为 256 的图像。StackGAN 与其他论文非常不同，因为它是从自然语言文本到图像的。这是通过改变文本嵌入来实现的，以便它捕获视觉特征。这是一篇非常有趣的论文，如果能看到 StyleGAN 中展示的潜在空间控制与 StackGAN 中定义的自然语言接口相结合，那将是令人惊讶的。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nj"><img src="../Images/a45196d37f3289c01f1bf06945cc3a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J0gBWPmkvHgrG75cZiE-0g.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Idea behind the StackGAN multi-scale architecture conditioned on a text embedding</figcaption></figure><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1612.03242" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">StackGAN:利用堆叠生成式对抗网络进行文本到照片的真实感图像合成</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">从文本描述中合成高质量的图像是计算机视觉中一个具有挑战性的问题，有许多应用前景</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><h1 id="9975" class="kt ku iq bd kv kw my ky kz la mz lc ld le na lg lh li nb lk ll lm nc lo lp lq bi translated">生成性对抗网络——good fellow 等人(2014 年)</h1><p id="978a" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Ian Goodfellow 的原始论文是任何研究 GANs 的人的必读之作。本文定义了 GAN 框架并讨论了“非饱和”损失函数。本文还给出了最佳鉴别器的推导，这一证明在最近的 GAN 论文中经常出现。本文还在 MNIST、TFD 和 CIFAR-10 图像数据集上验证了 GAN 的有效性。</p><div class="mm mn gp gr mo mp"><a href="https://arxiv.org/abs/1406.2661" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">生成对抗网络</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们提出了一个新的框架，通过一个对抗的过程来估计生成模型，在这个过程中，我们同时…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">arxiv.org</p></div></div></div></a></div><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="2b4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读！我提供了许多发表在 TowardsDataScience 上的这些论文的博文摘要，如下所列:</p><div class="mm mn gp gr mo mp"><a rel="noopener follow" target="_blank" href="/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">深度卷积生成对抗网络</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">生成对抗网络最有趣的部分之一是生成网络的设计。的…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr mg mp"/></div></div></a></div><div class="mm mn gp gr mo mp"><a rel="noopener follow" target="_blank" href="/deeper-into-dcgans-2556dbd0baac"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">深入到 DCGANs</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">进一步探索 GAN 过拟合、GAN 特征可视化和潜在空间插值等主题。</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="ns l no np nq nm nr mg mp"/></div></div></a></div><div class="mm mn gp gr mo mp"><a href="https://medium.com/@connorshorten300/generating-basketball-shoes-with-dcgans-6cd72d521c01" rel="noopener follow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">用 DCGANs 生成篮球鞋</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">在 Keras 中实现 DCGANs 以生成 45x45 篮球鞋图像的代码、结果和分析。</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="nt l no np nq nm nr mg mp"/></div></div></a></div><div class="mm mn gp gr mo mp"><a href="https://medium.com/@connorshorten300/conditional-gans-639aa3785122" rel="noopener follow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">条件甘斯</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">条件 GAN[1]是 GAN 框架的一个非常有趣的扩展。这种架构扩展了原有的…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="nu l no np nq nm nr mg mp"/></div></div></a></div><div class="mm mn gp gr mo mp"><a rel="noopener follow" target="_blank" href="/pix2pix-869c17900998"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">Pix2Pix</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">本文将解释一篇关于图像到图像翻译的流行论文的基本机制</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nv l no np nq nm nr mg mp"/></div></div></a></div><div class="mm mn gp gr mo mp"><a rel="noopener follow" target="_blank" href="/progressively-growing-gans-9cb795caebee"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">渐进增长的甘斯</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">NVIDIA 发布并在 ICLR 2018 上发布的逐步增长的 GAN 架构已经成为主要的…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nw l no np nq nm nr mg mp"/></div></div></a></div></div></div>    
</body>
</html>