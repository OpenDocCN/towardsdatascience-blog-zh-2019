<html>
<head>
<title>An easy introduction to Pytorch for Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络 Pytorch 的简单介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-easy-introduction-to-pytorch-for-neural-networks-3ea08516bff2?source=collection_archive---------8-----------------------#2019-08-07">https://towardsdatascience.com/an-easy-introduction-to-pytorch-for-neural-networks-3ea08516bff2?source=collection_archive---------8-----------------------#2019-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="638a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">感受 Pytorch 之火！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/56e4710e9fcf34eb980e8b675f0e2472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7eUdjYzAbpu4AzreQF2A3w.jpeg"/></div></div></figure><blockquote class="ku kv kw"><p id="0e1a" class="kx ky kz la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">想获得灵感？快来加入我的<a class="ae lu" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="eb4f" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">深度学习重新点燃了公众对人工智能的兴趣。原因很简单:深度学习<em class="kz">就是管用</em>。它让我们有能力建立以前无法建立的技术。它创造了新的商业机会，从整体上改善了技术世界。</p><p id="ef92" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">为了进行深度学习，你需要知道如何编码，尤其是用 Python。从那里，有一个不断增长的深度学习库可供选择:TensorFlow，Keras，MXNet，MatConvNet，以及最近的 Pytorch！</p><p id="eb31" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">Pytorch 发行后不久就迅速流行起来。人们称它为<em class="kz"> TensorFlow 杀手</em>，因为它更加用户友好和易于使用。事实上，您将看到使用 Pytorch 启动和运行深度学习是多么容易。</p><h1 id="d85d" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">Pytorch 入门</h1><p id="2ca4" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">Pytorch 开发的核心目标是尽可能地与 Python 的 Numpy 相似。这样做可以让常规 Python 代码、Numpy 和 Pytorch 之间的交互变得简单流畅，从而实现更快更简单的编码。</p><p id="c6c8" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">首先，我们可以通过 pip 安装 Pytorch:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="4933" class="na lz it mw b gy nb nc l nd ne">pip3 install torch torchvision</span></pre><p id="2bef" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">如果你对具体的特性感兴趣，Pytorch 文档非常棒。</p><h2 id="6acf" class="na lz it bd ma nf ng dn me nh ni dp mi lv nj nk mk lw nl nm mm lx nn no mo np bi translated">张量</h2><p id="0afe" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">任何深度学习库最基本的构建块都是<em class="kz">张量</em>。张量是类似矩阵的数据结构，在功能和属性上非常类似于 Numpy 数组。事实上，在大多数情况下，您可以将它们想象成 Numpy 数组。两者最重要的区别在于，现代深度学习库中张量的实现可以在 CPU 或 GPU 上运行(非常快)。</p><p id="8a48" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">在 PyTorch 中，可以使用简单的张量对象来声明张量:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="0de7" class="na lz it mw b gy nb nc l nd ne">import torch <br/>x = torch.Tensor(3, 3)</span></pre><p id="c82b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">上面的代码创建了一个大小为(3，3)的张量，即 3 行 3 列，用浮点零填充:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="1f9a" class="na lz it mw b gy nb nc l nd ne">0.  0.  0.<br/>0.  0.  0.<br/>0.  0.  0.<br/>[torch.FloatTensor of size 3x3]</span></pre><p id="d854" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">我们还可以创建张量填充的随机浮点值:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="1612" class="na lz it mw b gy nb nc l nd ne">x = torch.rand(3, 3)<br/>print(x)</span><span id="88e5" class="na lz it mw b gy nq nc l nd ne">"""<br/>Prints out:</span><span id="2859" class="na lz it mw b gy nq nc l nd ne">tensor([[0.5264, 0.1839, 0.9907],<br/>        [0.0343, 0.9839, 0.9294],<br/>        [0.6938, 0.6755, 0.2258]])<br/>"""</span></pre><p id="0dac" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">使用 Pytorch，张量相乘、相加和其他基本数学运算非常简单:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="0163" class="na lz it mw b gy nb nc l nd ne">x = torch.ones(3,3)<br/>y = torch.ones(3,3) * 4<br/>z = x + y<br/>print(z)</span><span id="898f" class="na lz it mw b gy nq nc l nd ne">"""<br/>Prints out:</span><span id="9ce5" class="na lz it mw b gy nq nc l nd ne">tensor([[5., 5., 5.],<br/>        [5., 5., 5.],<br/>        [5., 5., 5.]])<br/>"""</span></pre><p id="fd55" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">Pytorch 张量甚至提供了类似 Numpy 的切片功能！</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="ef17" class="na lz it mw b gy nb nc l nd ne">x = <!-- -->torch.ones(3,3) * 5<br/>y = x[:, :2]<br/>print(y)</span><span id="3062" class="na lz it mw b gy nq nc l nd ne">"""<br/>Prints out:</span><span id="4a3e" class="na lz it mw b gy nq nc l nd ne">tensor([[5., 5.],<br/>        [5., 5.],<br/>        [5., 5.]])<br/>"""</span></pre><p id="4fbd" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">所以 Pytorch 张量可以像 Numpy 数组一样被使用和处理。现在，我们将看看如何使用这些简单的 Pytorch 张量作为构建模块来构建深度网络！</p><h1 id="1b6d" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">用 Pytorch 构建神经网络</h1><p id="5f0c" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">在 Pytorch 中，神经网络被定义为 Python 类。定义网络的类从 torch 库中扩展了<em class="kz"> torch.nn.Module </em>。让我们为卷积神经网络(CNN)创建一个类，我们将应用于 MNIST 数据集。</p><p id="5d6d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">查看下面定义我们网络的代码！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="43b4" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">Pytorch 网络类中最重要的两个函数是<em class="kz"> __init__() </em>和<em class="kz"> forward() </em>函数。<em class="kz"> __init__() </em>用于定义您的模型将使用的任何网络层。在<em class="kz"> forward() </em>函数中，您实际上是通过将所有层堆叠在一起来建立模型。</p><p id="873b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">对于我们的模型，我们在 init 函数中定义了 2 个卷积层，其中一个我们将重复使用几次(conv2)。我们有一个最大池层和一个全局平均池层，将在最后应用。最后，我们有我们的全连接(FC)层和一个 softmax 来获得最终的输出概率。</p><p id="14b0" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">在 forward 函数中，我们确切地定义了我们的层如何堆叠在一起以形成完整的模型。这是一个标准网络，具有堆叠的 conv 层、池层和 FC 层。Pytorch 的美妙之处在于，我们可以在<em class="kz"> forward() </em>函数中的任何地方，通过简单的 print 语句打印出中间层中任何张量的形状和结果！</p><h1 id="bb49" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">培训、测试和保存</h1><h2 id="4e4a" class="na lz it bd ma nf ng dn me nh ni dp mi lv nj nk mk lw nl nm mm lx nn no mo np bi translated">加载数据</h2><p id="e332" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">是时候为训练准备好我们的数据了！我们将开始，但准备好必要的导入，初始化参数，并确保 Pytorch 设置为使用 GPU。下面使用<code class="fe nt nu nv mw b">torch.device()</code>的一行检查 Pytorch 是否安装了 CUDA 支持，如果是，则使用 GPU！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="c5b5" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">我们可以直接从 Pytroch 检索 MNIST 数据集。我们将下载数据，并将训练集和测试集放入单独的张量中。一旦数据被加载，我们将把它传递给 torch <em class="kz"> DataLoader </em>，它只是准备好以特定的批量和可选的混洗传递给模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="580f" class="na lz it bd ma nf ng dn me nh ni dp mi lv nj nk mk lw nl nm mm lx nn no mo np bi translated">培养</h2><p id="b8a7" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">训练时间到了！</p><p id="9849" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">optimzer(我们将使用 Adam)和 loss 函数(我们将使用交叉熵)的定义与其他深度学习库非常相似，如 TensorFlow、Keras 和 MXNet。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="eba1" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">在 Pytorch 中，所有的网络模型和数据集都必须明确地从 CPU 转移到 GPU。我们通过将<code class="fe nt nu nv mw b">.to()</code>函数应用于下面的模型来实现这一点。稍后，我们将对图像数据进行同样的操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="bd40" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">最后，我们可以写出我们的训练循环。查看下面的代码，看看它是如何工作的！</p><ol class=""><li id="f1c7" class="nw nx it la b lb lc le lf lv ny lw nz lx oa lt ob oc od oe bi translated">所有 Pytorch 训练循环将在训练数据加载器中经历每个时期和每个批次。</li><li id="445f" class="nw nx it la b lb of le og lv oh lw oi lx oj lt ob oc od oe bi translated">在每次循环迭代中，图像数据和标签都被传输到 GPU。</li><li id="69b7" class="nw nx it la b lb of le og lv oh lw oi lx oj lt ob oc od oe bi translated">每个训练循环还明确应用向前传递、向后传递和优化步骤。</li><li id="5fc9" class="nw nx it la b lb of le og lv oh lw oi lx oj lt ob oc od oe bi translated">将该模型应用于该批中的图像，然后计算该批的损失。</li><li id="a908" class="nw nx it la b lb of le og lv oh lw oi lx oj lt ob oc od oe bi translated">计算梯度并通过网络反向传播</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="8297" class="na lz it bd ma nf ng dn me nh ni dp mi lv nj nk mk lw nl nm mm lx nn no mo np bi translated">测试和保存</h2><p id="d942" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">在 Pytorch 中测试网络的性能会建立一个与训练阶段类似的循环。主要的区别是我们不需要做梯度的反向传播。我们仍将进行前向传递，只在网络的输出端获取具有最大概率的标签。</p><p id="e87d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">在这种情况下，经过 10 个时期后，我们的网络在测试集上获得了 99.06%的准确率！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="1caa" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lv li lj lk lw lm ln lo lx lq lr ls lt im bi translated">要将模型保存到磁盘以备后用，只需使用<code class="fe nt nu nv mw b">torch.save()</code>功能，瞧！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="08d8" class="ly lz it bd ma mb or md me mf os mh mi jz ot ka mk kc ou kd mm kf ov kg mo mp bi translated">喜欢学习？</h1><p id="6f0c" class="pw-post-body-paragraph kx ky it la b lb mq ju ld le mr jx lg lv ms lj lk lw mt ln lo lx mu lr ls lt im bi translated">在<a class="ae lu" href="https://twitter.com/GeorgeSeif94" rel="noopener ugc nofollow" target="_blank"> twitter </a>上关注我，我会在那里发布所有最新最棒的人工智能、技术和科学！也在 LinkedIn 上与我联系！</p></div></div>    
</body>
</html>