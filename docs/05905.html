<html>
<head>
<title>K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k 均值聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-13430ff3461d?source=collection_archive---------11-----------------------#2019-08-28">https://towardsdatascience.com/k-means-clustering-13430ff3461d?source=collection_archive---------11-----------------------#2019-08-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dc04" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">更简单直观的解释。</h2></div><p id="9ad4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">K-means 是最简单的无监督学习算法之一。该算法遵循一种简单易行的方法，将给定的数据集分组为一定数量的相关子集，称为<strong class="kk iu">簇</strong>。这个想法是找到<strong class="kk iu"> K </strong>个中心，称为<strong class="kk iu">簇质心</strong> <em class="le">，</em>一个对应一个<strong class="kk iu">簇</strong>，因此得名 K-均值聚类<em class="le">。</em>当看到一个新示例时，该算法根据距离度量(如欧几里德距离)报告该示例所属的最接近的聚类。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="lk ll l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">The dataset used for illustration. The dataset consists of 8 points — those 8 points are plotted as blue circles in the graph below.</figcaption></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/20a31e5ca9cd24ef4bd82cffda2a1a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fh9pYDARo2aPg6-qtZJRtw.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">The diagram is a typical illustration of clustering, with <strong class="bd lt">K=2 clusters</strong> and their <strong class="bd lt">cluster centroids</strong> shown evidently with a green and a yellow cross respectively. The circles correspond to the dataset and the crosses correspond to the cluster centroids.</figcaption></figure><p id="b1c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解，让我们考虑一个例子——假设一个社交网站想要找到具有相似兴趣的人群，并向他们投放相关广告。解决这个问题的一种方法是通过聚类，该公司可以使用喜欢的页面、分享的帖子和登记的位置等特征来建立数据集，并通过聚类算法来运行它，以识别相关的群体。不过需要注意的一点是，数据集是未标记的。</p><pre class="lf lg lh li gt lu lv lw lx aw ly bi"><span id="b168" class="lz ma it lv b gy mb mc l md me">A note on the notation. x_{i} means x subscript i, x_{^th} means x superscript th and x_{^th}{i} means x superscript th and subscript i.</span></pre><h1 id="e67a" class="mf ma it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">算法</h1><p id="4011" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">K 均值聚类算法从初始化步骤开始，称为<strong class="kk iu">随机初始化</strong>步骤。该步骤的目标是为每个 K-聚类随机选择一个质心，<em class="le"> u_{i} i </em> ∈ {1，2，3…K}。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/f1c4c7a1b2ed3d80b302b20b951fc6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGMkRcuBaHjPbqj3mtk-ZA.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">For the sake of simplicity only 8 data points have been considered. Out of these 8 points two points, drawn as a cross have been randomly chosen as cluster centroids illustrating <strong class="bd lt">random initialisation step</strong>.</figcaption></figure><p id="9d7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后使用迭代算法将这 K 个质心收敛到最优值。迭代的每一步都执行以下两步—</p><ul class=""><li id="f079" class="nb nc it kk b kl km ko kp kr nd kv ne kz nf ld ng nh ni nj bi translated">集群分配</li><li id="6aac" class="nb nc it kk b kl nk ko nl kr nm kv nn kz no ld ng nh ni nj bi translated">移动质心</li></ul><p id="8714" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">聚类分配</strong>步骤遍历数据集中的每个示例<em class="le"> x_{^i} </em>，并基于距离度量(比如欧几里德距离)将其分配给其最近的聚类质心。对于下面讨论的例子，可以说——给定一个例子，聚类分配步骤根据该例子离聚类质心的距离将其分配给一种颜色，绿色或黄色。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="np ll l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Cluster Assignment Step</figcaption></figure><p id="b9a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">移动质心</strong>步骤通过取分配给相同聚类质心的样本的平均值来计算新的聚类质心。或者，用黄色和绿色着色的所有点的平均值给出聚类质心的新值。为了清楚起见，这是负责随机初始化的群集质心收敛到最佳值的步骤。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="np ll l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Move Centroid Step.</figcaption></figure><p id="3d10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该算法一直持续到收敛，也就是说，直到两次后续迭代没有给出几乎相同的聚类质心值。</p><h1 id="0221" class="mf ma it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">改进随机初始化</h1><p id="e965" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">如前所述，该算法从随机初始化步骤开始，但随机初始化可能会导致算法陷入局部最优。</p><p id="b9f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一种提高我们以更好的聚类质心值结束的几率的方法是多次执行随机初始化步骤，并选择一组值，该组值导致由下式给出的<strong class="kk iu">失真成本函数<em class="le"> </em> </strong>的最小值—</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/6929ba87d6fc30dee5dbc85db2f0e18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*efcmZ7_-AGr3UA-37rJA8w.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">||a-b|| implies the Euclidean distance between vectors <strong class="bd lt">a</strong> and <strong class="bd lt">b</strong>. Interpret u_{^i}{c} as — cluster centroid of the cluster, to which example x_{^i} has been assigned. Concretely, u_{^ 3}{2} means, the third example is closest to the 2nd cluster centroid.</figcaption></figure><p id="cbd0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的成本函数正在计算每个训练示例<em class="le"> x_{^i} </em>和它被分配到的集群<em class="le"> u_{^i}{c}.之间的平方距离的平均值</em>平方是为了完全避免欧几里德距离引起的平方根。显然，较小的成本函数值对应于较好的初始化。</p><p id="2478" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种技术对于 K≤10 的值有效，但是已经观察到，对于较大的 K 值，它不会产生显著的差异。对于较大的 K 值，K-means 算法将几乎收敛到可接受的聚类质心值。此外，这种优化随机初始化步骤的方法计算量很大。</p><h1 id="efa4" class="mf ma it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">选择 K 的值</h1><p id="eace" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">到目前为止，您一定已经对 K-means 聚类算法有了直观的了解，但还有一个方面需要处理，即参数 K。让我们看看如何知道数据集需要划分的聚类数。</p><p id="cb71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">肘形法</strong>可用于寻找 K 的最佳值。该方法根据失真成本函数值绘制聚类数，并在图形向外弯曲或急转弯处选择 K 值。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/6832a30940151c1ca01cbe2a17e28036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Dh-aAYz3I3vRTb49nJq1Q.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Elbow method : The optimal value of K is 3 from the above graph as graph elbows out at 3.</figcaption></figure><p id="9206" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但实际上这种方法用得不多，因为当绘制真实世界的数据时，图形通常没有一个显著的拐点来选择 k 值。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/9b55ce6db1fdcdafe74d146de66f968b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5O5b-BV00i58ueZEw8Rv5A.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Elbow method : Real world plot where it is hard to point out any elbow.</figcaption></figure><p id="4176" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不幸的是，没有自动选取 K 值的方法。大多数情况下，参数 K 的值是通过查看可视化来手动选取的。</p></div></div>    
</body>
</html>