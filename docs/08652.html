<html>
<head>
<title>How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding Layers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过深度学习和嵌入层获得表格数据的最新结果</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c?source=collection_archive---------8-----------------------#2019-11-21">https://towardsdatascience.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c?source=collection_archive---------8-----------------------#2019-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="52e1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">卡格尔蓝皮书推土机竞赛的另一种方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e7b230bb97e49c0703c19e52c9400492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iYOn4JtwX9d4pj-U.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Embeddings can be use other than word representations</figcaption></figure><h1 id="202e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">动机</h1><p id="e22c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated"><span class="l mn mo mp bm mq mr ms mt mu di"> T </span>基于 ree 的模型，如 Random Forest 和 XGBoost，在解决表格(结构化)数据问题中非常流行，并在最近的 Kaggle 竞赛中获得了很多关注。这是有其充分理由的。然而，在本文中，我想介绍一种不同于 fast.ai 的<strong class="ls iu">表格</strong>模块的方法，它利用了:</p><blockquote class="mv mw mx"><p id="dcd9" class="lq lr my ls b lt mz ju lv lw na jx ly nb nc mb mc nd ne mf mg nf ng mj mk ml im bi translated"><strong class="ls iu">深度学习和嵌入层。</strong></p></blockquote><p id="c9d7" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">这有点违背行业共识，即深度学习更多地用于图像、音频或 NLP 等非结构化数据，通常不适合处理表格数据。然而，分类数据的嵌入层的引入改变了这种观点，我们将尝试在<a class="ae nh" href="https://www.kaggle.com/c/bluebook-for-bulldozers/overview" rel="noopener ugc nofollow" target="_blank">蓝皮书推土机竞赛</a>上使用<a class="ae nh" href="http://fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>的表格模块，并看看这种方法能走多远。</p><p id="3fcf" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">你可以找到 Kaggle 笔记本📔 <a class="ae nh" href="https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning" rel="noopener ugc nofollow" target="_blank"> <em class="my">此处</em> </a> <em class="my">。</em></p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="7b60" class="ky kz it bd la lb np ld le lf nq lh li jz nr ka lk kc ns kd lm kf nt kg lo lp bi translated">加载数据</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/fbb45b05f67f22344a3fa065f8eab646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxZSbdIS_g_6A5vydjOBdg.png"/></div></div></figure><p id="120f" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">首先，让我们导入必要的模块。这里最核心的一个是<code class="fe nv nw nx ny b"><strong class="ls iu">fastai.tabular</strong></code>:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="49e3" class="od kz it ny b gy oe of l og oh">from fastai import *<br/>from fastai.tabular import *</span></pre><p id="edfc" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">然后我们将数据读入熊猫数据帧。您可以在本文顶部的 Kaggle 笔记本链接中找到具体的代码，但在这里，我将只展示必要的代码片段，以尽可能保持简洁。我们将 CSV 文件读入<code class="fe nv nw nx ny b">train_df</code>，这将是我们主要工作的数据帧。我们还将在<code class="fe nv nw nx ny b">test_df</code>中读到测试集。</p><p id="efce" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">让我们简单看一下我们正在处理的数据:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="b13a" class="od kz it ny b gy oe of l og oh">len(train_df), len(test_df)<br/>(401125, 12457)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/f27e770da4e99719e010ec37025c0a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-NlhS8DO3zNgsGA5TG3x8A.png"/></div></div></figure><h1 id="985e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">对训练集排序</h1><p id="997f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated">这是为了创建一个好的验证集。一个好的验证集对于一个成功的模型的重要性怎么强调都不为过。因为我们要预测未来的销售价格数据，所以我们需要建立一个验证集，确保所有数据都在训练集的“未来”收集。因此，我们需要首先对训练集进行排序，然后将“未来”部分拆分为验证集。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="3a65" class="od kz it ny b gy oe of l og oh">train_df = train_df.sort_values(by='saledate', ascending=False)<br/>train_df = train_df.reset_index(drop=True)</span></pre></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="1de0" class="ky kz it bd la lb np ld le lf nq lh li jz nr ka lk kc ns kd lm kf nt kg lo lp bi translated">数据预处理</h1><p id="4455" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">比赛的评估方法使用 RMSLE(均方根对数误差)。所以如果我们取预测的对数，我们可以用老 RMSE 作为我们的损失函数。只是这样更容易。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="c9c5" class="od kz it ny b gy oe of l og oh">train_df.SalePrice = np.log(train_df.SalePrice)</span></pre><p id="c6f4" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">对于<strong class="ls iu">特征工程</strong>，由于我们将使用深度学习来解决问题，并且它非常擅长特征提取，所以我们将只在<code class="fe nv nw nx ny b">saledate</code>进行。这是使用深度学习方法的优势，它需要更少的功能工程和更少的领域知识。我们将使用 fast.ai 的<code class="fe nv nw nx ny b">add_datepart</code>函数来添加更多与销售日期相关的功能。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="6ff5" class="od kz it ny b gy oe of l og oh"># The only feature engineering we do is add some meta-data from the sale date column, using 'add_datepart' function in fast.ai<br/>add_datepart(train_df, "saledate", drop=False)<br/>add_datepart(test_df, "saledate", drop=False)</span></pre><p id="7ab0" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated"><code class="fe nv nw nx ny b">add_datepart</code>所做的是，它接受<code class="fe nv nw nx ny b">saledate</code>列，并添加了一堆其他列，如<code class="fe nv nw nx ny b">day of week</code>、<code class="fe nv nw nx ny b">day of month</code>，无论是月、季、年的开始还是结束，等等。这些添加的功能将提供对日期的更多洞察，并与用户购买行为相关。例如，在年底，公司通常会开展促销活动，价格通常会降低。</p><p id="be55" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">让我们检查是否所有这些与日期相关的特征都被添加到我们的数据框架中:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="8d13" class="od kz it ny b gy oe of l og oh"># check and see whether all date related meta data is added.<br/>def display_all(df):<br/>    with pd.option_context("display.max_rows", 1000, "display.max_columns", 1000): <br/>        display(df)<br/>        <br/>display_all(train_df.tail(10).T)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/bd72a53e99ed90d42ba3e27982352b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oUayXXrPx9t-Wdtb4VmPYw.png"/></div></div></figure><p id="2bb6" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">他们确实被加了进去。很好。现在我们需要做一些数据预处理，因为这个数据帧有相当多的缺失数据，我们还想对列进行分类和规范化。有了 fast.ai 库，这就相当简单了。我们只需在 Python 列表中指定我们想要的预处理方法，就像这样:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="1364" class="od kz it ny b gy oe of l og oh"># Defining pre-processing we want for our fast.ai DataBunch<br/>procs=[FillMissing, Categorify, Normalize]</span></pre><p id="ed5a" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">这个变量<code class="fe nv nw nx ny b">procs</code>稍后将被用于创建用于训练的 fast.ai 数据束。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="26ab" class="ky kz it bd la lb np ld le lf nq lh li jz nr ka lk kc ns kd lm kf nt kg lo lp bi translated">构建模型</h1><p id="7b56" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated"><span class="l mn mo mp bm mq mr ms mt mu di"> L </span>让我们看看每一列的数据类型，以决定哪些是分类的，哪些是连续的:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="41fe" class="od kz it ny b gy oe of l og oh">train_df.dtypes<br/>g = train_df.columns.to_series().groupby(train_df.dtypes).groups<br/>g</span></pre><p id="2918" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/9d389c96ca9fc738851406e66900d86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5tpHQuP9t2XjvX3z9mgPXA.png"/></div></div></figure><p id="f0b4" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">然后，我们将所有分类列放入一个列表<code class="fe nv nw nx ny b">cat_vars</code>中，所有连续列放入一个列表<code class="fe nv nw nx ny b">cont_vars</code>中。这两个变量也将用于构造 fast.ai DataBunch。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="0b44" class="od kz it ny b gy oe of l og oh"># prepare categorical and continous data columns for building Tabular DataBunch.<br/>cat_vars = ['SalesID', 'YearMade', 'MachineID', 'ModelID', 'datasource', 'auctioneerID', 'UsageBand', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc', 'fiModelSeries', 'fiModelDescriptor', 'ProductSize', <br/>            'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc', 'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control', 'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension', <br/>            'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics', 'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size', 'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow', <br/>            'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb', 'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type', 'Travel_Controls', 'Differential_Type', 'Steering_Controls', <br/>            'saleYear', 'saleMonth', 'saleWeek', 'saleDay', 'saleDayofweek', 'saleDayofyear', 'saleIs_month_end', 'saleIs_month_start', 'saleIs_quarter_end', 'saleIs_quarter_start', 'saleIs_year_end', <br/>            'saleIs_year_start'<br/>           ]</span><span id="472d" class="od kz it ny b gy ol of l og oh">cont_vars = ['MachineHoursCurrentMeter', 'saleElapsed']</span></pre><p id="2527" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">我们将创建另一个数据帧<code class="fe nv nw nx ny b">df</code>来馈入数据集中。我们还将因变量指定为<code class="fe nv nw nx ny b">dep_var</code>。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="5fb7" class="od kz it ny b gy oe of l og oh"># rearrange training set before feed into the databunch<br/>dep_var = 'SalePrice'<br/>df = train_df[cat_vars + cont_vars + [dep_var,'saledate']].copy()</span></pre><p id="cce8" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">现在是时候创建我们的验证集了。我们通过从训练集中切掉一块最近的条目来做到这一点。街区应该有多大？嗯，和测试集一样大。让我们看看代码:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="9c6a" class="od kz it ny b gy oe of l og oh"># Look at the time period of test set, make sure it's more recent<br/>test_df['saledate'].min(), test_df['saledate'].max()</span><span id="0d43" class="od kz it ny b gy ol of l og oh"># Calculate where we should cut the validation set. We pick the most recent 'n' records in training set where n is the number of entries in test set. <br/>cut = train_df['saledate'][(train_df['saledate'] == train_df['saledate'][len(test_df)])].index.max()<br/>cut</span><span id="112b" class="od kz it ny b gy ol of l og oh">12621</span><span id="f4cd" class="od kz it ny b gy ol of l og oh"># specify the valid_idx variable as the cut out range.<br/>valid_idx = range(cut)</span></pre><p id="87e2" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">我们首先查看测试集的时间段，并确保它比我们所有的训练集更近。然后我们计算需要剪下多少记录。</p><p id="7aa9" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">最后，让我们使用 fast.ai 的 datablock API 构建我们的 DataBunch 进行训练:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="51db" class="od kz it ny b gy oe of l og oh"># Use fast.ai datablock api to put our training data into the DataBunch, getting ready for training<br/>data = (TabularList.from_df(df, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=procs)<br/>                   .split_by_idx(valid_idx)<br/>                   .label_from_df(cols=dep_var, label_cls=FloatList)<br/>                   .databunch())</span></pre></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="0f2b" class="ky kz it bd la lb np ld le lf nq lh li jz nr ka lk kc ns kd lm kf nt kg lo lp bi translated">构建模型</h1><p id="ad82" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们将从刚刚创建的数据集中启动一个 fast.ai <code class="fe nv nw nx ny b">tabular.learner</code>。我们希望将预测的价格范围限制在历史销售价格范围内，因此我们需要计算<code class="fe nv nw nx ny b">y_range</code>。请注意，我们将<code class="fe nv nw nx ny b">SalePrice</code>的最大值乘以 1.2，因此当我们应用 sigmoid 时，上限也将被覆盖。这是从模型中挤出更多性能的一个小技巧。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="4787" class="od kz it ny b gy oe of l og oh">max_y = np.max(train_df['SalePrice'])*1.2<br/>y_range = torch.tensor([0, max_y], device=defaults.device)<br/>y_range</span><span id="6438" class="od kz it ny b gy ol of l og oh">tensor([ 0.0000, 14.2363], device='cuda:0')</span></pre><p id="bced" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">现在我们可以创建我们的学习者:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="ed35" class="od kz it ny b gy oe of l og oh"># Create our tabular learner. The dense layer is 1000 and 500 two layer NN. We used dropout, hai <br/>learn = tabular_learner(data, layers=[1000,500], ps=[0.001,0.01], emb_drop=0.04, y_range=y_range, metrics=rmse)</span></pre><p id="5f92" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">关于 fast.ai <code class="fe nv nw nx ny b">tabular_learner</code>最重要的一点是为分类数据使用嵌入层。这是使深度学习在处理表格数据方面具有竞争力的'<strong class="ls iu">秘方</strong>'。由于每个分类变量都有一个嵌入层，我们为分类变量引入了良好的交互，并利用了深度学习的最大优势:自动特征提取。为了更好的正则化，我们还对密集层和嵌入层使用了 Drop Out。学习者的指标是 RMSE，因为我们已经记录了销售价格。我们来看看模型。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="b7dd" class="od kz it ny b gy oe of l og oh">TabularModel(<br/>  (embeds): ModuleList(<br/>    (0): Embedding(388505, 600)<br/>    (1): Embedding(72, 18)<br/>    (2): Embedding(331868, 600)<br/>    (3): Embedding(5155, 192)<br/>   ...<br/>    (60): Embedding(3, 3)<br/>    (61): Embedding(2, 2)<br/>    (62): Embedding(3, 3)<br/>  )<br/>  (emb_drop): Dropout(p=0.04, inplace=False)<br/>  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>  (layers): Sequential(<br/>    (0): Linear(in_features=2102, out_features=1000, bias=True)<br/>    (1): ReLU(inplace=True)<br/>    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    (3): Dropout(p=0.001, inplace=False)<br/>    (4): Linear(in_features=1000, out_features=500, bias=True)<br/>    (5): ReLU(inplace=True)<br/>    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    (7): Dropout(p=0.01, inplace=False)<br/>    (8): Linear(in_features=500, out_features=1, bias=True)<br/>  )<br/>)</span></pre><p id="9681" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">从上面可以看出，我们有分类列的嵌入层，然后是删除层。对于连续列，我们有一个批处理范数层，然后我们将所有这些列(分类嵌入+连续变量)连接在一起，并将其放入两个完全连接的层中，这两个层分别有 1000 和 500 个节点，中间有 Relu、batch norm 和 Dropout。很标准的东西。</p><p id="0d08" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">现在我们有了模型，让我们使用 fast.ai 的学习率查找器来查找一个好的学习率:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="a6b0" class="od kz it ny b gy oe of l og oh">learn.lr_find()<br/>learn.recorder.plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/ef55d784d921d1c0f800cb89d30c4493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*V3leQPn16_RoGHmS-GJp3A.png"/></div></figure><p id="11cd" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">我们将挑选学习率曲线斜率最大的一端的学习率:<code class="fe nv nw nx ny b">le-02</code></p><p id="dc90" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">让我们使用 fast.ai 的单周期训练方法进行一些训练。注意，我们为正则化添加了一些权重衰减(0.2)。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="56c7" class="od kz it ny b gy oe of l og oh">learn.fit_one_cycle(2, 1e-2, wd=0.2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/a5c80cf11c352746d44e47ef31f0c30b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*iTSVogV--iXyWqMtz7Gf6Q.png"/></div></figure><p id="71ac" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">我们可以用较小的学习率训练更多的周期:</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="23c7" class="od kz it ny b gy oe of l og oh">learn.fit_one_cycle(5, 3e-4, wd=0.2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/882813d008b5a95a58e68eaae4b5131c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpG8gJ4UoD_n74QyzJML3w.png"/></div></div></figure><p id="b91e" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">在我们的验证集上，我们已经达到了 0.223<strong class="ls iu">的分数。由于竞赛不接受提交材料，我们只能通过查看排行榜来大致了解该模型的表现:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/d8e8dd01a68bdfb8b75006ea713489d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IuacQ30L1265EdtwImuMtw.png"/></div></div></figure><p id="9112" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">排名第一的是<strong class="ls iu"> 0.229 </strong>。对比这款车型的<strong class="ls iu"> 0.223 </strong>。我们不知道它在测试集上的表现如何，但总的来说，我认为我们得到的结果一点也不差。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="2eb6" class="ky kz it bd la lb np ld le lf nq lh li jz nr ka lk kc ns kd lm kf nt kg lo lp bi translated">关于嵌入层的更多内容</h1><p id="a96d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated"><span class="l mn mo mp bm mq mr ms mt mu di"> W </span>让一切点击这里的是嵌入层。嵌入只是一个把某物映射到一个向量的花哨说法。就像 NLP 中越来越流行的单词嵌入一样，它意味着使用一个向量(大小是任意的，取决于任务)来表示单词，这些向量是权重，可以通过反向支持来训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/1371423a5a805016b3a69a605435bfcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9dWEOVdmzHOgrFj5"/></div></div></figure><p id="9761" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">类似地，对于我们的例子，我们在分类变量上使用了嵌入。每一列都有一个可以训练的嵌入矩阵。每个唯一的列值都有一个映射到它的特定向量。这方面的美妙之处在于:<strong class="ls iu">通过嵌入，我们现在可以开发变量</strong>的“语义”，这种“语义”以权重的形式影响我们的销售价格，可以通过我们的深度神经网络提取和训练。该模型将具有“T2”深度，它需要很好地适应大数据集。</p><p id="09c0" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">但是不要把我的话当真，还是只看我这个不起眼的小项目的成果吧。在一个更荣耀的例子中，有<a class="ae nh" href="https://arxiv.org/abs/1604.06737" rel="noopener ugc nofollow" target="_blank">这篇论文</a>，作者是在一个名为<a class="ae nh" href="https://www.kaggle.com/c/rossmann-store-sales/overview" rel="noopener ugc nofollow" target="_blank"> Rossman </a>(预测未来销售)的 Kaggle 竞赛中获得第三名的人。在排行榜上的顶级团队中，其他人都使用了某种重型功能工程，但通过使用嵌入层，他们以较少的功能工程获得了第三名。</p><p id="aee7" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">更有趣的是，有了嵌入层，你实际上可以在嵌入矩阵空间中可视化变量投影。以罗斯曼项目为例。他们对德国各州的嵌入矩阵进行了二维投影。</p><blockquote class="mv mw mx"><p id="4d89" class="lq lr my ls b lt mz ju lv lw na jx ly nb nc mb mc nd ne mf mg nf ng mj mk ml im bi translated">如果你在嵌入空间上圈出一些州，在实际地图上圈出相同的州。你会发现它们惊人的相似。嵌入层实际上发现了地理。</p></blockquote></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="3a48" class="pw-post-body-paragraph lq lr it ls b lt mz ju lv lw na jx ly lz nc mb mc md ne mf mg mh ng mj mk ml im bi translated">觉得这篇文章有用？在 Medium 上关注我(<a class="ae nh" href="https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------" rel="noopener">李立伟</a>)或者你可以在 Twitter <a class="ae nh" href="https://twitter.com/lymenlee" rel="noopener ugc nofollow" target="_blank"> @lymenlee </a>或者我的博客网站<a class="ae nh" href="https://wayofnumbers.com/" rel="noopener ugc nofollow" target="_blank">wayofnumbers.com</a>上找到我。你也可以看看我下面最受欢迎的文章！</p><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">“这是 CS50”:开始数据科学教育的愉快方式</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">为什么 CS50 特别适合巩固你的软件工程基础</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">一枚硬币的两面:杰瑞米·霍华德的 fast.ai vs 吴恩达的 deeplearning.ai</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">如何不通过同时参加 fast.ai 和 deeplearning.ai 课程来“过度适应”你的人工智能学习</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">你需要了解网飞的“朱庇特黑仔”:冰穴📖</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">是时候让 Jupyter 笔记本有个有价值的竞争对手了</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pk l pf pg ph pd pi ks ou"/></div></div></a></div></div></div>    
</body>
</html>