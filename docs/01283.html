<html>
<head>
<title>Markov Chain Monte Carlo</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马尔可夫链蒙特卡罗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/markov-chain-monte-carlo-291d8a5975ae?source=collection_archive---------6-----------------------#2019-02-28">https://towardsdatascience.com/markov-chain-monte-carlo-291d8a5975ae?source=collection_archive---------6-----------------------#2019-02-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1a49" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">将您对 MCMC 的理解提升到中级水平</h2></div><p id="8864" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我学习马尔可夫链蒙特卡罗(MCMC)时，我的导师告诉我们有三种方法来解释 MCMC。</p><ul class=""><li id="ba20" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">基本知识:MCMC 允许我们利用计算机来做贝叶斯统计。</li><li id="d646" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated"><strong class="kh ir">中级</strong> : MCMC 是一种可以找到我们感兴趣的参数的后验分布的方法。具体来说，这种类型的算法以一种依赖于马尔可夫属性的方式生成蒙特卡罗模拟，然后以一定的速率接受这些模拟以获得后验分布。"</li><li id="71de" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated"><strong class="kh ir">进阶</strong>:一堂完整的统计学课。</li></ul><p id="b6db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我写这篇博客的目的是让你达到中级水平。</p><p id="4d83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">先从基础的开始吧。</strong></p><p id="a475" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MCMC 到底是什么？要回答这个问题，我们首先需要复习一下贝叶斯统计。贝叶斯统计是建立在这样一个理念上的，即一件事情发生的概率受事先假设的概率和数据显示的某件事情发生的可能性的影响。在贝叶斯统计中，概率用分布来表示。</p><p id="9889" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果先验和似然概率分布是正态分布，我们就能够用一个函数来描述后验分布。这被称为封闭解。这种类型的贝叶斯如下所示。正如你所看到的，后验分布是由先验分布和似然分布共同形成的，并在中间的某处结束。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/017d685b0afa55d776580b9f7cd29728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*0pod8SWHXRH2hTr9W5PrKA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Created in Matplotlib inspired by Matt Brems</figcaption></figure><p id="edc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是当概率不是很大的时候呢？当概率看起来更像这样时会发生什么？</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mb"><img src="../Images/f9e8d98fab050837cebf7d54c2818b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nbLfUm6yBCEYRwVo6N-rbA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Rbb [CC BY-SA 3.0 (<a class="ae mg" href="https://creativecommons.org/licenses/by-sa/3.0" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/licenses/by-sa/3.0</a>)], from Wikimedia Commons</figcaption></figure><p id="dbdf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下，可能性没有正态分布，所以我们最终得到一个右偏后验分布。因为我们不能用公式来表达，我们必须使用马尔可夫链蒙特卡罗。</p><h1 id="b878" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">马尔可夫链蒙特卡罗的三个部分</h1><h1 id="6b1a" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">一:蒙特卡洛</strong></h1><ul class=""><li id="9402" class="lb lc iq kh b ki mz kl na ko nb ks nc kw nd la lg lh li lj bi translated">蒙特卡罗模拟通过生成随机数来模拟复杂系统。</li><li id="d879" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">在下面的 gif 的情况下，蒙特卡洛生成一个参数为(0-1，0-1)的随机点，通过确定曲线下结束的点的数量，我们能够近似整个圆的面积，并从π开始。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/719e999ef391988055e33061b0647f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*6wlFqiGF35WPRWjlgwDneg.gif"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">nicoguaro [CC BY 3.0 (<a class="ae mg" href="https://creativecommons.org/licenses/by/3.0" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/licenses/by/3.0</a>)], from Wikimedia Commons</figcaption></figure><h1 id="caab" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">二:马尔可夫链</strong></h1><ul class=""><li id="4421" class="lb lc iq kh b ki mz kl na ko nb ks nc kw nd la lg lh li lj bi translated">马尔可夫链本质上是一个变量如何在图中“行走”的表示，或者一个随机变量如何随时间从一种状态改变到另一种状态。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/45979b2b6faef99a6f4535186f65beea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/0*kAIT2tNGI01-8Z_a.gif"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">image source <a class="ae mg" href="http://www.mathcs.emory.edu/~cheung/" rel="noopener ugc nofollow" target="_blank">http://www.mathcs.emory.edu/~cheung/</a></figcaption></figure><ul class=""><li id="4342" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">上图展示了情绪状态的马尔可夫链。在这个链条中，如果你很快乐，有 20%的几率你会把情绪状态变成一般，20%的几率你会变得悲伤，60%的几率你会保持快乐。</li></ul><p id="d5ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">马尔可夫链由马尔可夫属性</strong>决定</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="1fc1" class="nl mi iq nh b gy nm nn l no np">F(Xt+1|Xt) = f(Xt+1|Xt,Xt-1,Xt-2,….)</span></pre><p id="0d66" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我知道现在正在发生什么，知道发生了什么让我们走到这一步或前一步，等等。没给我提供更多信息。</p><p id="9116" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这方面例子有:</p><ul class=""><li id="6fae" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">孟德尔遗传学。在下面的例子中，子豆的颜色完全受父豆的颜色影响。第一代的豆子颜色受到前一代的影响，但在确定第二代的颜色时不需要考虑这一点。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/addd8504aab87d992d130e2a21e83e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*zWZdPNwowgcc91wQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Pbroks13 [CC BY-SA 3.0 (<a class="ae mg" href="https://creativecommons.org/licenses/by-sa/3.0" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/licenses/by-sa/3.0</a>)]</figcaption></figure><ul class=""><li id="cd6b" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">棋盘游戏:当玩大富翁游戏并试图确定玩家去某个空间的概率时，你需要的唯一信息是玩家目前在哪里。玩家之前的回合在哪里并不影响它接下来的走向，除了它决定了这一回合在哪里。</li></ul><h1 id="4fef" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">三:接受-拒绝抽样</h1><p id="4557" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated">MCMC 的第三部分是接受-拒绝抽样。当我们对新的观察进行采样时，我们决定它是否在正确的方向上，然后决定我们是保留它还是丢弃它。</p><p id="601a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">两种常见的接受-拒绝算法是 Metropolis-Hasting 算法和不掉头采样器。不准掉头的数学比我在这篇中等文章中解释的要复杂，但是如果你想深入研究，可以看看这篇<a class="ae mg" href="https://arxiv.org/abs/1111.4246" rel="noopener ugc nofollow" target="_blank">文章。</a></p><p id="fdae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我对大都市生活的高层次解释</p><ul class=""><li id="4ff9" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">我们在 x 点。</li><li id="2abe" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">我们对下一步做一个猜测。我们称之为 x*</li><li id="4278" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">然后，我们计算 x*/x 的概率比。这是使用似然性和先验分布的乘积计算的。</li><li id="8579" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">如果 p(x*)/p(x)的比值(也称为接受概率)大于 1，我们接受 x*作为新位置。</li><li id="5a5b" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">即使接受概率小于 1，我们也不自动拒绝 x*。我们通过从均匀(0，1)分布中选择一个随机数来抛硬币。如果数字小于接受概率，我们接受 x*,如果数字大于接受概率，我们拒绝 x*,并重新开始这个过程。</li></ul><h1 id="3028" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">把所有的放在一起</h1><ul class=""><li id="9fc4" class="lb lc iq kh b ki mz kl na ko nb ks nc kw nd la lg lh li lj bi translated">我们随机生成数字:这是蒙特卡罗部分</li><li id="895b" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">我们允许我们生成的数字影响下一个生成的数字:这就是马尔可夫链</li><li id="8a56" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">然后我们决定生成的新数字是否“朝着正确的方向前进”:接受-拒绝算法</li><li id="88a0" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">然后我们检查收敛性:我们确定我们的数据何时收敛到一个合理的分布。收敛点之后随机生成的值成为我们的后验分布</li></ul><p id="d14d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这有助于您在中级水平上理解 MCMC。</p><p id="b500" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1.(经允许)直接从<a class="ae mg" href="https://medium.com/@matthew.w.brems" rel="noopener">马特·布莱姆斯</a>的演讲中借用。<br/> 2。一个很棒但是很数学的 MCMC 移植:<a class="ae mg" href="https://blog.stata.com/2016/11/15/introduction-to-bayesian-statistics-part-2-mcmc-and-the-metropolis-hastings-algorithm/" rel="noopener ugc nofollow" target="_blank">https://blog . stata . com/2016/11/15/Bayesian-statistics-introduction-to-part-2-MCMC-and-the-metropolis-Hastings-algorithm/</a></p></div></div>    
</body>
</html>