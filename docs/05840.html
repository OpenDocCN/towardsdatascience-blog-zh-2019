<html>
<head>
<title>Selecting the Correct Predictive Modeling Technique</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">选择正确的预测建模技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/selecting-the-correct-predictive-modeling-technique-ba459c370d59?source=collection_archive---------1-----------------------#2019-08-26">https://towardsdatascience.com/selecting-the-correct-predictive-modeling-technique-ba459c370d59?source=collection_archive---------1-----------------------#2019-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3f81" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用统计、概率和数据挖掘来预测未来的结果。</h2></div><h1 id="6588" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">什么是预测建模？</h1><p id="106e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">预测建模是获取已知结果并开发一个可以预测新事件值的模型的过程。它使用历史数据来预测未来事件。有许多不同类型的预测建模技术，包括方差分析、线性回归(普通最小二乘法)、逻辑回归、岭回归、时间序列、决策树、神经网络等等。在项目开始时选择正确的预测建模技术可以节省大量时间。选择不正确的建模技术会导致不准确的预测和经历非恒定方差和/或均值的残差图。</p><h1 id="4076" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">回归分析</h1><p id="7e29" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">回归分析用于从一个或多个独立变量预测一个连续的目标变量。通常，回归分析用于自然发生的变量，而不是通过实验操纵的变量。如上所述，有许多不同类型的回归，所以一旦我们决定了应该使用回归分析，<strong class="lc iu">我们如何选择应该应用哪种回归技术？</strong></p><p id="61af" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">方差分析</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/0b0df92afd1b4b1868babe25a9355edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*nzBBVGh50h4wk0cE-GSnaQ.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">A scatterplot for data that may be best modeled by an ANOVA model looks as so</figcaption></figure><p id="8849" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">当目标变量是连续的且因变量是分类的时，使用 ANOVA 或方差分析。该分析中的无效假设是不同组之间没有显著差异。总体应呈正态分布，样本病例应相互独立，且组间方差应大致相等。</p><p id="66a6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">线性回归</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/3b3827f2356721b6b87154c98b86dde4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rJnaEVvakiqKUrwVs_CI2Q.png"/></div></div></figure><p id="812a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">当目标变量是连续的，因变量是连续的或者是连续变量和分类变量的混合，并且自变量和因变量之间的关系是线性的时，将使用线性回归。此外，所有预测变量应正态分布，具有恒定的方差，并且彼此之间应很少或没有多重共线性或自相关。</p><p id="0954" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">逻辑回归</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/ceddf2075e06e7a6eefdcc6d301a5bf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*yqZhZ-Fus22_b4T65n7N0A.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk"><a class="ae mt" href="https://www.researchgate.net/figure/Linear-Probability-Versus-Logistic-Regression-6_fig2_224127022" rel="noopener ugc nofollow" target="_blank">https://www.researchgate.net/figure/Linear-Probability-Versus-Logistic-Regression-6_fig2_224127022</a></figcaption></figure><p id="a52e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">逻辑回归不需要目标和因变量之间的线性关系。目标变量是二元的(假设值为 0 或 1)或二元的。逻辑回归的误差/残差不需要是正态分布的，并且残差的方差不需要是常数。但是，因变量是二元的，观察值必须相互独立，数据中必须很少或没有多重共线性或自相关，并且样本量应该很大。最后，虽然该分析不要求自变量和因变量线性相关，但自变量必须与对数概率线性相关。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mu"><img src="../Images/309db790bc44b99ff1ef9e8bea77fc69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKbAycq1VV9OvKGw_hBTmw.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">If the scatter plot between the independent variable(s) and the dependent variable looks like the plot above, a logistic model might be the best model to represent that data.</figcaption></figure><p id="3ba0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">岭回归</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mv"><img src="../Images/8fab8c41515018db9aafb193ef281ee7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D6wgl2OQP8DnhE75NxQs9Q.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">For variables that experience high multicollinearity, such as X1 and X2 in this case, a ridge regression may be the best choice in order to normalize the variance of the residuals with an error term.</figcaption></figure><p id="30f1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">岭回归是一种分析经历多重共线性的多重回归变量的技术。岭回归采用普通的最小二乘法，并通过向回归估计值添加一定程度的偏差来减少标准误差，从而承认残差经历了较高的方差。假设遵循多元回归的假设，散点图必须是线性的，必须有不含异常值的恒定方差，并且因变量必须表现出独立性。</p><p id="7513" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">时间序列</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mw"><img src="../Images/07efe34010b8b29547b102d340c18bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*FOh_LjIjNuy9mqaxNQ3HCw.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk"><a class="ae mt" href="https://simplystatistics.org/2016/05/05/timeseries-biomedical/" rel="noopener ugc nofollow" target="_blank">https://simplystatistics.org/2016/05/05/timeseries-biomedical/</a></figcaption></figure><p id="f1a7" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">时间序列回归分析是一种基于响应历史预测未来响应的方法。时间序列的数据应该是变量在不同时间点的一组观察值。数据是二元的，<strong class="lc iu">自变量是时间</strong>。序列必须是稳定的，这意味着它们是正态分布的:序列的均值和方差在很长一段时间内是恒定的。此外，残差还应在长时间内呈均值和方差恒定的正态分布，并且不相关。该系列不应包含任何异常值。如果随机冲击是存在的，它们确实应该随机分布，平均值为 0，方差为常数。</p><h1 id="56d8" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">分类分析</h1><h2 id="3897" class="mx kj it bd kk my mz dn ko na nb dp ks lj nc nd ku ln ne nf kw lr ng nh ky ni bi translated">决策树</h2><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/00bf1180cc69869db1555c9f8d31365a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*fC6PIrm6Fx7CvoKYFSipjQ.jpeg"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk"><a class="ae mt" href="https://hackernoon.com/what-is-a-decision-tree-in-machine-learning-15ce51dc445d" rel="noopener ugc nofollow" target="_blank">https://hackernoon.com/what-is-a-decision-tree-in-machine-learning-15ce51dc445d</a></figcaption></figure><p id="9151" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">决策树是一种监督学习算法，它基于关于样本的某些问题重复分割样本。这些对于分类问题非常有用。它们相对容易理解并且非常有效。决策树表示几个决策，后面跟着不同的发生几率。这项技术帮助我们定义最重要的变量以及两个或更多变量之间的关系。</p><h2 id="65f0" class="mx kj it bd kk my mz dn ko na nb dp ks lj nc nd ku ln ne nf kw lr ng nh ky ni bi translated">神经网络</h2><p id="a5e8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">神经网络有助于对数据进行聚类和分类。这些算法大致模仿人脑，旨在识别模式。神经网络往往非常复杂，因为它们由一组算法组成。这种类型的分析可能非常有用，但是，如果你试图确定<em class="nk">为什么</em>发生了什么，这可能不是最好的模型。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nl"><img src="../Images/2fe27f4b5f1bd5d4cc608ccefe6e4a0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gti7eSVECQaCeo6eUAOxdg.jpeg"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk"><a class="ae mt" href="http://www.asimovinstitute.org/neural-network-zoo/" rel="noopener ugc nofollow" target="_blank">http://www.asimovinstitute.org/neural-network-zoo/</a></figcaption></figure><p id="cd36" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">总之，这些只是可用于数据建模的不同预测技术的一小部分选项。需要注意的是，在使用预测分析技术时，在变量之间建立因果关系是非常危险的。在预测分析中，我们不能说一个变量<em class="nk">导致了另一个</em>，相反，我们可以说一个变量对另一个变量有影响，以及这种影响是什么。</p><p id="9baa" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们来连线:</p><p id="9fe1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://www.linkedin.com/in/mackenzie-mitchell-635378101/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/mackenzie-mitchell-635378101/</a></p><div class="nm nn gp gr no np"><a href="https://github.com/mackenziemitchell6" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">麦肯齐米切尔 6 -概述</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">在 GitHub 上注册您自己的个人资料，这是托管代码、管理项目和与 40…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od mh np"/></div></div></a></div><p id="7c3e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">资源:</p><p id="6476" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://www.statisticssolutions.com/manova-analysis-anova/" rel="noopener ugc nofollow" target="_blank">https://www.statisticssolutions.com/manova-analysis-anova/</a></p><p id="2409" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://dss.princeton.edu/online_help/analysis/regression_intro.htm#targetText=Regression%20analysis%20is%20used%20when,logistic%20regression%20should%20be%20used." rel="noopener ugc nofollow" target="_blank">https://DSS . Princeton . edu/online _ help/analysis/Regression _ intro . htm # target text = Regression % 20 analysis % 20 is % 20 used % 20 when，logistic % 20 Regression % 20 should % 20 be % 20 used。</a></p><p id="237c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://www.statisticssolutions.com/assumptions-of-logistic-regression/#targetText=Third%2C%20logistic%20regression%20requires%20there,independent%20variables%20and%20log%20odds." rel="noopener ugc nofollow" target="_blank">https://www . statistics solutions . com/assumptions-of-logistic-regression/# target text = Third % 2C % 20 logistic % 20 regression % 20 需要% 20 这里，独立% 20 变量% 20 和%20log%20odds。</a></p><p id="b483" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://www.microstrategy.com/us/resources/introductory-guides/predictive-modeling-the-only-guide-you-need" rel="noopener ugc nofollow" target="_blank">https://www . microstrategy . com/us/resources/introductive-guides/predictive-modeling-the-only-guide-you-need</a></p><p id="08b6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://skymind.ai/wiki/neural-network" rel="noopener ugc nofollow" target="_blank">https://skymind.ai/wiki/neural-network</a></p><p id="d2ed" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Ridge_Regression.pdf" rel="noopener ugc nofollow" target="_blank">https://NCSs-wpengine . net DNA-SSL . com/WP-content/themes/NCSs/pdf/Procedures/NCSS/Ridge _ regression . pdf</a></p><p id="6a6b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mt" href="https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/2/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2015/01/decision-tree-simplified/2/</a></p></div></div>    
</body>
</html>