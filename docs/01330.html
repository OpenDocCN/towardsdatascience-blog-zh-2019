<html>
<head>
<title>Building Blocks: Text Pre-Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建块:文本预处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-blocks-text-pre-processing-641cae8ba3bf?source=collection_archive---------7-----------------------#2019-03-03">https://towardsdatascience.com/building-blocks-text-pre-processing-641cae8ba3bf?source=collection_archive---------7-----------------------#2019-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0293" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们系列的上一篇文章中，我们介绍了自然语言处理的概念，你可以<a class="ae kl" href="https://medium.com/@shashank.kapadia/introduction-to-natural-language-processing-nlp-2a8fae09ed03" rel="noopener">在这里</a>阅读，现在你大概也想自己尝试一下吧？太好了！事不宜迟，让我们深入研究统计自然语言处理的构建模块。</p><p id="4f1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将介绍关键概念、Python 中的实际实现以及应用时要记住的挑战。完整的代码可以在 GitHub 的<a class="ae kl" href="https://github.com/kapadias/mediumposts/blob/master/nlp/Building%20Blocks%20Text%20Pre-Processing.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本上获得。</a></p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/c266c8a7481f180cb461b0210b57cd1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HFmaIJiZ7BehRryMgLDvxQ.jpeg"/></div></div></figure><h1 id="324f" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">文字规范化</strong></h1><p id="bb4e" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">规范化文本意味着在将文本转换为更高级建模的特征之前，将其转换为更方便的标准形式。把这一步想象成把人类可读的语言转换成机器可读的形式。</p><p id="9008" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标准化文本的标准框架包括:</p><ol class=""><li id="c445" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated">标记化</li><li id="d69a" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">停止单词删除</li><li id="5b9b" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">形态标准化</li><li id="66fc" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">配置</li></ol><blockquote class="mw mx my"><p id="0e4f" class="jn jo mz jp b jq jr js jt ju jv jw jx na jz ka kb nb kd ke kf nc kh ki kj kk ij bi translated"><em class="iq">数据预处理由许多步骤组成，任何数量的步骤可能适用于也可能不适用于给定的任务。更一般地说，在本文中，我们将讨论一些预先确定的文本主体，并执行一些基本的转换分析，这些分析可用于执行更进一步的、更有意义的自然语言处理[1] </em></p></blockquote></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="94d9" class="lf lg iq bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated"><strong class="ak">标记化</strong></h1><p id="33d5" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">给定一个字符序列和一个已定义的文档单元(文本的简介)，<em class="mz">标记化</em>的任务是将它分割成小块，称为<strong class="jp ir"> <em class="mz">标记</em> </strong>，可能同时丢弃某些字符/单词，如标点符号【2】。通常，有两种类型的标记化:</p><ol class=""><li id="0a7b" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">单词标记化:</strong>用于通过唯一的<em class="mz">空格字符分隔单词。</em>根据应用程序的不同，单词标记化也可以标记多单词表达式，如<em class="mz"> New York </em>。这往往与一个叫做<em class="mz">命名实体识别</em>的过程紧密相关。在本教程的后面，我们将看看<em class="mz">搭配(短语)建模</em>，这有助于解决这个挑战的一部分</li><li id="8431" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">句子分词和单词分词一样，是文本处理中至关重要的一步。这通常是基于标点符号，如“.”, "?", "!"因为它们倾向于标记句子的边界</li></ol><p id="cbbf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">挑战:</strong></p><ul class=""><li id="907e" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk ni mo mp mq bi translated">缩写的使用可以促使标记器检测没有边界的句子边界。</li><li id="647c" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk ni mo mp mq bi translated">数字、特殊字符、连字符和大写。在“不要”、“我愿意”、“约翰的”这些表达中，我们有一个、两个还是三个代币？</li></ul><p id="332a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实现示例:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="ff59" class="no lg iq nk b gy np nq l nr ns">from nltk.tokenize import sent_tokenize, word_tokenize</span><span id="3935" class="no lg iq nk b gy nt nq l nr ns">#Sentence Tokenization<br/>print ('Following is the list of sentences tokenized from the sample review\n')</span><span id="a1e0" class="no lg iq nk b gy nt nq l nr ns">sample_text = """The first time I ate here I honestly was not that impressed. I decided to wait a bit and give it another chance. <br/>I have recently eaten there a couple of times and although I am not convinced that the pricing is particularly on point the two mushroom and <br/>swiss burgers I had were honestly very good. The shakes were also tasty. Although Mad Mikes is still my favorite burger around, <br/>you can do a heck of a lot worse than Smashburger if you get a craving"""</span><span id="e06d" class="no lg iq nk b gy nt nq l nr ns">tokenize_sentence = sent_tokenize(sample_text)</span><span id="42c1" class="no lg iq nk b gy nt nq l nr ns">print (tokenize_sentence)<br/>print ('---------------------------------------------------------\n')<br/>print ('Following is the list of words tokenized from the sample review sentence\n')<br/>tokenize_words = word_tokenize(tokenize_sentence[1])<br/>print (tokenize_words)</span></pre><p id="1fbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="7223" class="no lg iq nk b gy np nq l nr ns">Following is the list of sentences tokenized from the sample review<br/><br/>['The first time I ate here I honestly was not that impressed.', 'I decided to wait a bit and give it another chance.', 'I have recently eaten there a couple of times and although I am not convinced that the pricing is particularly on point the two mushroom and \nswiss burgers I had were honestly very good.', 'The shakes were also tasty.', 'Although Mad Mikes is still my favorite burger around, \nyou can do a heck of a lot worse than Smashburger if you get a craving']<br/>---------------------------------------------------------<br/><br/>Following is the list of words tokenized from the sample review sentence<br/><br/>['I', 'decided', 'to', 'wait', 'a', 'bit', 'and', 'give', 'it', 'another', 'chance', '.']</span></pre></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="b248" class="lf lg iq bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">停止单词删除</h1><p id="7e62" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">通常，作为停用词移除过程的一部分，有几个普遍存在的词被完全从词汇表中排除，这些词看起来对帮助分析的目的没有什么价值，但是增加了特征集的维度。通常有两个原因促使这种移除。</p><ol class=""><li id="1edf" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">不相关:</strong>只允许对有内容的单词进行分析。停用词，也称为空词，因为它们通常没有太多意义，会在分析/建模过程中引入噪声</li><li id="af3c" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><strong class="jp ir">维数:</strong>去除停用词还可以显著减少文档中的标记，从而降低特征维数</li></ol><p id="373e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">挑战:</strong></p><p id="131b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在停用字词删除过程之前将所有字符转换为小写字母会在文本中引入歧义，有时会完全改变文本的含义。例如，“美国公民”将被视为“美国公民”，或者“it 科学家”将被视为“IT 科学家”。由于*us*和*it*通常都被认为是停用词，这将导致不准确的结果。因此，通过<em class="mz">词性</em>标记步骤，通过识别“us”和“IT”不是上述示例中的代词，可以改进关于停用词处理的策略。</p><p id="e3ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实施例:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="41f9" class="no lg iq nk b gy np nq l nr ns">from nltk.corpus import stopwords<br/>from nltk.tokenize import word_tokenize</span><span id="6bd3" class="no lg iq nk b gy nt nq l nr ns"># define the language for stopwords removal<br/>stopwords = set(stopwords.words("english"))<br/>print ("""{0} stop words""".format(len(stopwords)))</span><span id="45fa" class="no lg iq nk b gy nt nq l nr ns">tokenize_words = word_tokenize(sample_text)<br/>filtered_sample_text = [w for w in tokenize_words if not w in stopwords]</span><span id="3b8c" class="no lg iq nk b gy nt nq l nr ns">print ('\nOriginal Text:')<br/>print ('------------------\n')<br/>print (sample_text)<br/>print ('\n Filtered Text:')<br/>print ('------------------\n')<br/>print (' '.join(str(token) for token in filtered_sample_text))</span></pre><p id="40be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="01fa" class="no lg iq nk b gy np nq l nr ns">179 stop words<br/><br/>Original Text:<br/>------------------<br/><br/>The first time I ate here I honestly was not that impressed. I decided to wait a bit and give it another chance. <br/>I have recently eaten there a couple of times and although I am not convinced that the pricing is particularly on point the two mushroom and <br/>swiss burgers I had were honestly very good. The shakes were also tasty. Although Mad Mikes is still my favorite burger around, <br/>you can do a heck of a lot worse than Smashburger if you get a craving<br/><br/> Filtered Text:<br/>------------------<br/><br/>The first time I ate I honestly impressed . I decided wait bit give another chance . I recently eaten couple times although I convinced pricing particularly point two mushroom swiss burgers I honestly good . The shakes also tasty . Although Mad Mikes still favorite burger around , heck lot worse Smashburger get craving</span></pre></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="ab0b" class="lf lg iq bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">形态标准化</h1><p id="6b2b" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">一般来说，形态学是研究单词是如何由更小的有意义的单位组成的，<em class="mz">词素。</em>比如<em class="mz">狗</em>由两个语素组成:<strong class="jp ir"> <em class="mz">狗</em> </strong>和<strong class="jp ir"> <em class="mz"> s </em> </strong></p><p id="5c95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">两种常用的文本规范化技术是:</p><ol class=""><li id="e7e1" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">词干化:</strong>该过程旨在识别单词的词干，并用它来代替单词本身。提取英语词干最流行的算法是波特算法，这种算法已经被反复证明是非常有效的。整个算法太长太复杂，无法在这里呈现[3]，但是你可以在这里找到细节<a class="ae kl" href="http://people.scs.carleton.ca/~armyunis/projects/KAPI/porter.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="6031" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><strong class="jp ir">词汇化:</strong>这个过程指的是使用词汇和词形分析来正确地做事情，通常旨在仅移除<em class="mz">屈折</em>词尾，并返回单词的基本或词典形式，这被称为<strong class="jp ir"> <em class="mz">词汇</em> </strong>。</li></ol><blockquote class="mw mx my"><p id="d07f" class="jn jo mz jp b jq jr js jt ju jv jw jx na jz ka kb nb kd ke kf nc kh ki kj kk ij bi translated"><em class="iq">如果遇到令牌</em> <strong class="jp ir"> saw </strong> <em class="iq">，词干可能只返回</em> <strong class="jp ir"> s </strong> <em class="iq">，而词汇化将根据令牌是用作动词还是名词【4】</em>来尝试返回 <strong class="jp ir"> see </strong> <em class="iq">或</em> <strong class="jp ir"> saw </strong> <em class="iq"/></p></blockquote><p id="f700" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实施例:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="2609" class="no lg iq nk b gy np nq l nr ns">from nltk.stem import PorterStemmer<br/>from nltk.stem import WordNetLemmatizer<br/>from nltk.tokenize import word_tokenize</span><span id="798f" class="no lg iq nk b gy nt nq l nr ns">ps = PorterStemmer()<br/>lemmatizer = WordNetLemmatizer()</span><span id="56f8" class="no lg iq nk b gy nt nq l nr ns">tokenize_words = word_tokenize(sample_text)</span><span id="341b" class="no lg iq nk b gy nt nq l nr ns">stemmed_sample_text = []<br/>for token in tokenize_words:<br/>    stemmed_sample_text.append(ps.stem(token))</span><span id="c68a" class="no lg iq nk b gy nt nq l nr ns">lemma_sample_text = []<br/>for token in tokenize_words:<br/>    lemma_sample_text.append(lemmatizer.lemmatize(token))<br/>    <br/>print ('\nOriginal Text:')<br/>print ('------------------\n')<br/>print (sample_text)</span><span id="b6f7" class="no lg iq nk b gy nt nq l nr ns">print ('\nFiltered Text: Stemming')<br/>print ('------------------\n')<br/>print (' '.join(str(token) for token in stemmed_sample_text))</span><span id="d43a" class="no lg iq nk b gy nt nq l nr ns">print ('\nFiltered Text: Lemmatization')<br/>print ('--------------------------------\n')<br/>print (' '.join(str(token) for token in lemma_sample_text))</span></pre><p id="ed87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="bd6a" class="no lg iq nk b gy np nq l nr ns">Original Text:<br/>------------------<br/><br/>The first time I ate here I <strong class="nk ir"><em class="mz">honestly</em></strong> was not that impressed. I decided to wait a bit and give it <strong class="nk ir"><em class="mz">another</em></strong> <strong class="nk ir"><em class="mz">chance</em></strong>. I have recently eaten there a <strong class="nk ir"><em class="mz">couple</em></strong> of times and although I am not convinced that the pricing is particularly on point the two mushroom and swiss burgers I had were honestly very good. The shakes were also tasty. Although Mad Mikes is still my favorite burger around, you can do a heck of a lot worse than <strong class="nk ir"><em class="mz">Smashburger</em></strong> if you get a <strong class="nk ir"><em class="mz">craving</em></strong>.<br/><br/><br/>Filtered Text: Stemming:<br/>------------------<br/><br/>the first time I ate here I <strong class="nk ir"><em class="mz">honestli</em></strong> wa not that impress . I decid to wait a bit and give it <strong class="nk ir"><em class="mz">anoth</em></strong> <strong class="nk ir"><em class="mz">chanc</em></strong> . I have recent eaten there a <strong class="nk ir"><em class="mz">coupl</em></strong> of time and although I am not convinc that the price is particularli on point the two mushroom and swiss burger I had were honestli veri good . the shake were also tasti . although mad mike is still my favorit burger around , you can do a heck of a lot wors than <strong class="nk ir"><em class="mz">smashburg</em></strong> if you get a <strong class="nk ir"><em class="mz">crave</em></strong> .</span><span id="ec1d" class="no lg iq nk b gy nt nq l nr ns">Filtered Text: Lemmatization<br/>--------------------------------<br/><br/>The first time I ate here I <strong class="nk ir"><em class="mz">honestly</em></strong> wa not that impressed . I decided to wait a bit and give it <strong class="nk ir"><em class="mz">another</em></strong> <strong class="nk ir"><em class="mz">chance</em></strong> . I have recently eaten there a <strong class="nk ir"><em class="mz">couple</em></strong> of time and although I am not convinced that the pricing is particularly on point the two mushroom and swiss burger I had were honestly very good . The shake were also tasty . Although Mad Mikes is still my favorite burger around , you can do a heck of a lot worse than <strong class="nk ir"><em class="mz">Smashburger</em></strong> if you get a <strong class="nk ir"><em class="mz">craving</em></strong> .</span></pre><p id="81b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">挑战:</strong></p><p id="6124" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，完整的形态学分析至多产生非常有限的分析益处。从相关性和维度缩减的角度来看，两种形式的标准化都不能提高语言信息的总体性能，至少在以下情况下是这样:</p><p id="817e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实施例:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="5acb" class="no lg iq nk b gy np nq l nr ns">from nltk.stem import PorterStemmer<br/>words = ["operate", "operating", "operates", "operation", "operative", "operatives", "operational"]</span><span id="f8c1" class="no lg iq nk b gy nt nq l nr ns">ps = PorterStemmer()</span><span id="1ae8" class="no lg iq nk b gy nt nq l nr ns">for token in words:<br/>    print (ps.stem(token))</span></pre><p id="4acd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输出:</strong></p><pre class="ku kv kw kx gt nj nk nl nm aw nn bi"><span id="81cd" class="no lg iq nk b gy np nq l nr ns">oper<br/>oper<br/>oper<br/>oper<br/>oper<br/>oper<br/>oper</span></pre><blockquote class="mw mx my"><p id="cfe2" class="jn jo mz jp b jq jr js jt ju jv jw jx na jz ka kb nb kd ke kf nc kh ki kj kk ij bi translated">作为可能出错的一个例子，请注意，波特词干分析器将以下所有单词的词干转换为<strong class="jp ir"> <em class="iq"> oper </em> </strong></p></blockquote><p id="f80c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，由于<em class="mz">以各种形式操作</em>是一个常见的动词，我们预计会失去相当的精确性[4]:</p><ul class=""><li id="164f" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk ni mo mp mq bi translated">运营和研究</li><li id="ceda" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk ni mo mp mq bi translated">操作和系统</li><li id="fe17" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk ni mo mp mq bi translated">手术和牙科</li></ul><p id="5d6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于这种情况，使用词汇归类器并不能完全解决问题，因为在特定的搭配中使用了特定的屈折形式。从术语规范化中获得更好的价值更多地取决于单词使用的语用问题，而不是语言形态学的形式问题[4]</p><p id="84b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于所有用于生成上述结果的代码，点击<a class="ae kl" href="https://github.com/kapadias/mediumposts/blob/master/nlp/Building%20Blocks%20Text%20Pre-Processing.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="c4f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！现在你知道梯度下降，线性回归和逻辑回归。"</p><h1 id="681e" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">即将到来..</h1><p id="5f63" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">在下一篇文章中，我们将详细讨论搭配(短语)建模的概念，并一起演练它的实现。敬请关注，继续学习！</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="679c" class="lf lg iq bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated"><strong class="ak">参考文献:</strong></h1><p id="6f16" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">[1]预处理文本数据的一般方法— KDnuggets。<a class="ae kl" href="https://www.kdnuggets.com/2017/12/general-approach-preprocessing-text-data.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2017/12/general-approach-预处理-text-data.html </a></p><p id="af9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]记号化—斯坦福 NLP 组。<a class="ae kl" href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/token ization-1 . html</a></p><p id="0d66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]牛疾病中的文本挖掘—ijcaonline.org。<a class="ae kl" href="https://www.ijcaonline.org/volume6/number10/pxc3871454.pdf" rel="noopener ugc nofollow" target="_blank">https://www.ijcaonline.org/volume6/number10/pxc3871454.pdf</a></p><p id="d3db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]词干化和词汇化—斯坦福大学 NLP 组。<a class="ae kl" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/stemming-and-lemma tization-1 . html</a></p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="55d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mz">如果你有任何反馈，请在本文中发表评论，在</em> <a class="ae kl" href="https://www.linkedin.com/in/shashankkapadia/" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> LinkedIn </em> </a> <em class="mz">上给我发消息，或者给我发邮件(shmkapadia[at]gmail.com) </em></p></div></div>    
</body>
</html>