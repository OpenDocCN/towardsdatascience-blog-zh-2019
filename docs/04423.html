<html>
<head>
<title>Handling Imbalanced data using re-sampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用重采样处理不平衡数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/handling-imbalanced-data-using-re-sampling-872b6db4fe67?source=collection_archive---------48-----------------------#2019-07-08">https://towardsdatascience.com/handling-imbalanced-data-using-re-sampling-872b6db4fe67?source=collection_archive---------48-----------------------#2019-07-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4f7c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">不平衡数据是高级分析解决方案中普遍存在的问题。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d1aef5e4417878bbd5dac8636d334c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*npmnvP-L9LdfBf9THcKWNQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo By <a class="ae kv" href="https://pixabay.com/users/lauraljstc-4119307/" rel="noopener ugc nofollow" target="_blank">Lauraljstc </a>from <a class="ae kv" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><h1 id="f83d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="0b3c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">不平衡类数据是机器学习中常见的问题。除非以适当的方式处理，否则它可能会导致一个假装为最佳执行模型的模型，同时偏向于特定的类。</p><p id="915c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">例如，考虑以下包含 10 个类的数据集，但是每个类的出现是不均匀分布的。使用此数据集训练的模型偏向于 C1、C2、C4 和 C5，但很少预测 C7、C8、C9 和 C10 类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/37578dd44fd1441ceea742a3455d3f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*QUL-Uw2M36eZbLcJTg3ydA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Imbalanced classes— Image by Author</figcaption></figure><h1 id="9537" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">重新取样</h1><h2 id="806a" class="mq kx iq bd ky mr ms dn lc mt mu dp lg lx mv mw li mb mx my lk mf mz na lm nb bi translated">合成少数过采样技术(SMOTE) [1]</h2><p id="4ff5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是一种流行且成功的方法，它创造了少数民族阶层的新样本，而不仅仅是复制样本。考虑前面的场景，其中我们只有 C10 的 3 个样本(C10_D_1、C10_D_2 和 C10_D_3)(因为我们只有 3 个样本，所以这三个样本都被视为邻居)，SMOTE 在 3 个数据点之间创建线，并从线中选取合成数据点(C10_S_1 和 C10_S_2)。下图说明了我们所讨论内容的图形解释。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/239b08d1b3a83e804ab10dc39d858f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*00jEHVFW9vTHwPHD8ezxgg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Features Space— Image by Author</figcaption></figure><p id="51ed" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这可以使用名为“<em class="nd"> scikit-learn-contrib </em>的<em class="nd"> scikit-learn </em>的扩展版本来执行，下面的代码段显示了使用<em class="nd"> scikit-learn-contrib </em>使用 SMOTE。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="6264" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">SMOTE 算法有一些属性值需要优化；不幸的是，由于 SMOTE 的评分和转换方法的不变性，流水线和随机化搜索 CV 不能用于执行自动优化。因此，我们需要手动阻止和播放属性值来进行优化。有关 SMOTE 和属性的更多详细信息，请参考[2]。</p><h2 id="cfec" class="mq kx iq bd ky mr ms dn lc mt mu dp lg lx mv mw li mb mx my lk mf mz na lm nb bi translated">过采样[3]、[4]</h2><p id="627c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这种方法为少数民族班级复制一个样本以平衡班级。这里我们逐步讨论如何实现过采样。</p><p id="e970" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">步骤 1 </strong>:识别数据中优势类的频率(<em class="nd">frequency _ of _ majority _ class</em>)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="dbc3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">第二步</strong>:将数据集一分为二(数据集包含优势类(DF_FOR_MAJORITY)和次要类(DF_FOR_MINORITY))。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="6976" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">第三步</strong>:获取辅修课列表。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="611c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">步骤 4 </strong>:使用重采样方法复制少数类样本。</p><p id="1a91" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里我们使用<em class="nd">n _ samples</em>=<em class="nd">frequency _ of _ majority _ class</em>来指定要生成的样本数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="5b89" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">步骤 5 </strong>:连接 DF_FOR_MAJORITY 和过采样数据(DF_FOR_MINORITY_OVERSAMPLED)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="a1b5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下表是由于过采样而产生的输出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c42af4ffd02b24fa7ab05c019ad2fa21.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*q1OD84VLjsX3FiXim2vflw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Balanced classes — Image by Author</figcaption></figure><h2 id="4c07" class="mq kx iq bd ky mr ms dn lc mt mu dp lg lx mv mw li mb mx my lk mf mz na lm nb bi translated">欠采样[3]</h2><p id="5d8d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这种方法移除多数类的样本，并尝试与少数类的样本数量相匹配。</p><p id="2585" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">不同之处在于，在步骤 1 中，考虑次要类别的频率，而不是识别主要类别的频率。</p><p id="1f98" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="nd">注意:</em> </strong> <em class="nd">这种方法通常不被推荐，因为它会丢失大多数类的有用行为。</em></p><h2 id="666d" class="mq kx iq bd ky mr ms dn lc mt mu dp lg lx mv mw li mb mx my lk mf mz na lm nb bi translated">最后的想法</h2><p id="2d4c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们讨论了解决不平衡数据问题的三种方法，根据问题的背景，我们应该选择正确的方法。它确保高级分析解决方案是有意义的，而不是有偏见的特定行为。</p><h1 id="53dc" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="3504" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1] N. V. Chawla，K. W .鲍耶，L. O.Hall，W. P. Kegelmeyer，“SMOTE:合成少数过采样技术”，人工智能研究杂志，321–357，2002 年。</p><p id="f964" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[2]勒迈特 g .，诺盖拉 f .，和阿迪达斯 C. (2016)。“不平衡学习:一个 Python 工具箱来解决机器学习中不平衡数据集的诅咒”。更正 abs/1609.06570。</p><p id="4170" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[3]m .库巴特和 s .马特温(1997 年)。解决不平衡训练集的诅咒:单边选择。收录于:第十四届机器学习国际会议论文集，第 179-186 页，田纳西州纳什维尔。摩根·考夫曼。</p><p id="ce56" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[4]凌和李(1998 年)。直接营销中的数据挖掘问题及解决方案。《第四届知识发现和数据挖掘国际会议(KDD-98)会议录》。AAAI 出版社。</p></div></div>    
</body>
</html>