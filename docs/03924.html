<html>
<head>
<title>Beating State of the Art by Tuning Baselines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过调整基线超越最先进水平</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beating-state-of-the-art-by-tuning-baselines-74ec6ad2cd59?source=collection_archive---------11-----------------------#2019-06-20">https://towardsdatascience.com/beating-state-of-the-art-by-tuning-baselines-74ec6ad2cd59?source=collection_archive---------11-----------------------#2019-06-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="df40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你如何知道一个新的机器学习模型是否是对以前模型的改进？一种方法是将其与为相同任务开发的基线模型进行比较。但这回避了一个问题:你如何知道基线本身是否好？由 Rendle，Zhang &amp; Koren 撰写的一份新的预印本“<a class="ae kl" href="https://arxiv.org/abs/1905.01395?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank">关于评估基线的难度:关于推荐系统的研究</a>”表明，衡量一个基线模型对一个具体问题的效果并不像它初看起来那样简单。事实上，<strong class="jp ir">的作者仅仅通过调整基线并将它们与简单的、众所周知的方法结合起来</strong>，就能够在<a class="ae kl" href="https://grouplens.org/datasets/movielens/10m/?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank"> Movielens 10M 基准</a> <strong class="jp ir">上击败当前最先进的</strong>的推荐。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/9d79d170d792184105964e59a7cd6878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSLovzy9FJ6SMyVA8adN1A.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Blue x’s are the results reported by authors for their newly-proposed method, black/grey triangles are the baselines those authors run… and red are the tuned baselines. Down is better and, as you can see, after additional turning (<a class="ae kl" href="https://arxiv.org/abs/1905.01395" rel="noopener ugc nofollow" target="_blank">as outlined in the paper</a>) the tuned baselines are the most down (i.e. best performing).</figcaption></figure><h1 id="b871" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">我们如何评价机器学习模型？</h1><p id="3c18" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们先退一步。我们目前如何评估模型？</p><p id="37e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你曾经参加过<a class="ae kl" href="https://www.kaggle.com/competitions?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank"> Kaggle 竞赛</a>，你可能已经知道它们是如何工作的:你被给予训练数据来建立一个模型，为一个特定的指标进行优化。然后，根据不同的数据集对您的模型以及其他所有人的模型进行评估，并根据目标指标进行排名。提交结束后，每个人的模型都会在第三个看不见的数据集上排名，表现最好的模型胜出！(当然，前提是他们遵守了特定比赛的规则。)</p><p id="408c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，对于机器学习的学术研究来说，事情有点不同。一般来说，研究人员使用特定任务的数据为该任务建立新的模型。一些例子:</p><ul class=""><li id="279a" class="mf mg iq jp b jq jr ju jv jy mh kc mi kg mj kk mk ml mm mn bi translated">使用<a class="ae kl" href="https://www.kaggle.com/netflix-inc/netflix-prize-data?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank"> Netflix 奖项数据集的推荐系统</a></li><li id="bbe1" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">使用<a class="ae kl" href="http://cocodataset.org/?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank">微软 COCO 数据集</a>进行对象分割</li><li id="2f92" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">使用<a class="ae kl" href="https://catalog.ldc.upenn.edu/LDC93S1?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank"> TIMIT 语料库</a>进行语音识别</li><li id="2dd3" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">自然语言理解使用<a class="ae kl" href="https://gluebenchmark.com/?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank">胶水基准</a></li></ul><p id="d4e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，他们将算法的性能与在同一数据集上运行的基线进行比较。如果这是一项已经存在一段时间的任务，通常会将你的系统与另一篇论文中报告的结果进行比较，但对于较新的任务，研究人员通常自己运行基线。</p><blockquote class="mt mu mv"><p id="4417" class="jn jo mw jp b jq jr js jt ju jv jw jx mx jz ka kb my kd ke kf mz kh ki kj kk ij bi translated">一个<strong class="jp ir">基准</strong>是一个包括数据集和评估性能的方法的任务。一个<strong class="jp ir">基线</strong>是一个众所周知的算法，可以应用于基准问题。</p></blockquote><p id="1461" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在研究中没有“获胜”的模式，但是提出一种新方法，然后证明它比以前建立的方法有所改进的论文往往会被发表。(对于研究人员来说，雇佣和晋升是基于发表论文的数量和质量，所以让你的论文发表是一件好事！)</p><p id="2bfb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这两个社区之间最大的不同可能是研究人员面临着关注新型模型的压力。如果一个老型号在 Kaggle 比赛中真的有效，竞争者没有理由不使用它…但是<strong class="jp ir">如果主要发现是“我们已经做了十年的东西实际上仍然非常好”</strong>，就很难让论文发表。</p><h1 id="5b9c" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">为什么基线一开始就不太好？</h1><blockquote class="mt mu mv"><p id="1ad0" class="jn jo mw jp b jq jr js jt ju jv jw jx mx jz ka kb my kd ke kf mz kh ki kj kk ij bi translated">进行实验是困难的，需要大量的实验努力才能获得可靠的结果。(伦德尔等人，第 9 页)</p></blockquote><p id="ec3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">重申一下:运行机器学习实验很难。Rendle 和合著者指出了调优可能出错的两个地方:</p><p id="5435" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1) <strong class="jp ir">在调整超参数</strong>时，您很容易错过最佳时机。您的搜索空间的边界可能太靠近，或者在一个方向上移动得太远。您可能没有使用正确的搜索网格。你在小模型上得到的结果实际上可能不会放大。简而言之:很难很好地调优模型，而且很容易搞砸。</p><p id="5c61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2) <strong class="jp ir">在预处理或学习过程中，你可能会遗漏一些小而重要的步骤</strong>。你打乱了你的训练数据吗？做 z 变换？你使用提前停车吗？所有这些选择都会影响你的模型结果。尤其是如果你试图复制别人的结果，这些步骤可能很难做对。(特别是如果它们没有被报告，并且原作者没有发布它们的代码！)</p><p id="83b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">即使您做了所有您应该做的事情，并且有一个非常坚实的基线，基线算法可能会在额外的调整下表现得更好——特别是由非常熟悉该方法并且知道所有提示和技巧的人来调整。了解什么最适合特定的模式需要大量的试验和错误；这也是调整基线如此困难的部分原因。即使一篇论文的作者真的尽了最大努力来调整基线，有更多经验或稍微不同的方法的人可能会得到更好的结果。(有点像 Kaggle 比赛；与只使用过几次的人相比，非常熟悉 XGBoost 模型调优的人可能会得到更好的结果。)</p><p id="b2e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">而且，虽然在 Kaggle 式的竞争中有投入大量时间调优模型的动机，包括您的基线(如果它表现良好，您使用什么工具并不重要！)，<strong class="jp ir">研究场所一般不会奖励花费大量时间调基线</strong>。事实上，如果调整显示基线优于你想出的方法，这实际上可能会让<em class="mw">更难</em>发表一篇描述你的新模型的论文。这类似于<a class="ae kl" href="https://www.psychfiledrawer.org/TheFiledrawerProblem.php?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank">“文件抽屉问题”</a>，研究人员不太可能报告负面结果。</p><h1 id="eba0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">那么我们能做些什么呢？</h1><p id="ffb0" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">Rendle 等人提出了两件事可以在这里有所帮助:标准化基准和激励机器学习社区投入时间调整这些基准。</p><h2 id="3009" class="na ld iq bd le nb nc dn li nd ne dp lm jy nf ng lq kc nh ni lu kg nj nk ly nl bi translated">不要多此一举</h2><p id="9445" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">“重新发明轮子”意味着重新做已经做过的工作。<strong class="jp ir">如果某个特定任务有一个已经很好调整过的既定基准，那么你应该与那个基准进行比较！</strong>(额外的好处是，如果您正在进行一项既定的任务，并且可以使用报告的结果而不是重新运行它们，那么您可以节省时间和计算。🤑)</p><h2 id="6de6" class="na ld iq bd le nb nc dn li nd ne dp lm jy nf ng lq kc nh ni lu kg nj nk ly nl bi translated">激励跑步(和调音！)基线</h2><p id="addc" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">这个有点棘手:要改变一个已建立的社区的激励结构或价值体系极其困难。作者指出，机器学习竞赛，无论是在像<a class="ae kl" href="https://www.kaggle.com/competitions?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=baselines-blog" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>这样的平台上，还是在研究社区内组织，都是这样做的一种方式。我还要补充一点，如果你评论机器学习的论文，既要考虑新颖性(这种方法是新的吗？)和效用(这篇论文对整个社区有好处吗？)写评论的时候。</p><h1 id="5a4a" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="ae2a" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">仅仅因为最近提出了一种建模技术，并不意味着它一定会优于一种更老的方法(即使论文中的结果表明它可以)。调整模型需要时间和专业知识，但通过仔细调整，已建立的基线可以表现得非常好，甚至超过最先进的水平。依靠具有良好调整的基线的标准化基准可以帮助减少重复工作，还可以获得更可靠的结果。而且，如果您只是在为一个特定的项目寻找最佳方法，那么从更好理解的模型开始可能会更好。</p><p id="63d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你有兴趣阅读整篇文章，特别是关于不同推荐系统的基线调整的细节，你可以<a class="ae kl" href="https://arxiv.org/pdf/1905.01395.pdf" rel="noopener ugc nofollow" target="_blank">在 Arxiv </a>上查看。</p></div></div>    
</body>
</html>