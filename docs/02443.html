<html>
<head>
<title>Review: SqueezeNet (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:挤压网(图像分类)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-squeezenet-image-classification-e7414825581a?source=collection_archive---------4-----------------------#2019-04-22">https://towardsdatascience.com/review-squeezenet-image-classification-e7414825581a?source=collection_archive---------4-----------------------#2019-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2717" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">AlexNet 级精度，参数减少 50 倍</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/5c42cbc41a79b352fd8124d5aeba3600.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8EYvkfd0YSPiKPkW"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://unsplash.com/@jeisblack" rel="noopener ugc nofollow" target="_blank"><strong class="bd kw">Jason Blackeye @jeisblack</strong></a><strong class="bd kw"> (Unsplash)</strong></figcaption></figure><p id="d360" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi lt translated"><span class="l lu lv lw bm lx ly lz ma mb di">在</span>这个故事里，<strong class="kz ir"> SqueezeNet </strong>，由<strong class="kz ir"> DeepScale </strong>、<strong class="kz ir"> UC Berkeley </strong>和<strong class="kz ir"> Stanford University </strong>进行回顾。在精度相当的情况下，较小的 CNN 架构至少有三个优势</p><ol class=""><li id="2c02" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls mh mi mj mk bi translated">较小的卷积神经网络(CNN)在分布式训练中需要<strong class="kz ir">较少的跨服务器通信</strong>。</li><li id="e428" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls mh mi mj mk bi translated">更小的 CNN 需要更少的带宽来从云端向自动驾驶汽车输出新的模型。</li><li id="d4ac" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls mh mi mj mk bi translated">较小的 CNN 更适合部署在 FPGAs 和其他内存有限的硬件上。</li></ol><p id="dbfd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是 2016 年关于<strong class="kz ir"> arXiv </strong>的技术报告，引用超过<strong class="kz ir"> 1100 次</strong>。(<a class="mq mr ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----e7414825581a--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="a9c7" class="mz na iq bd nb nc nd ne nf ng nh ni nj jw nk jx nl jz nm ka nn kc no kd np nq bi translated">概述</h1><ol class=""><li id="c282" class="mc md iq kz b la nr ld ns lg nt lk nu lo nv ls mh mi mj mk bi translated"><strong class="kz ir">建筑设计策略</strong></li><li id="4664" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls mh mi mj mk bi translated"><strong class="kz ir">消防模块</strong></li><li id="e291" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls mh mi mj mk bi translated"><strong class="kz ir"> SqueezeNet 架构</strong></li><li id="fcaf" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls mh mi mj mk bi translated"><strong class="kz ir">对 SqueezeNet 的评估</strong></li></ol></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="8ba7" class="mz na iq bd nb nc nd ne nf ng nh ni nj jw nk jx nl jz nm ka nn kc no kd np nq bi translated"><strong class="ak"> 1。建筑设计策略</strong></h1><h2 id="5356" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">策略一。用 1×1 过滤器替换 3×3 过滤器</h2><ul class=""><li id="fd09" class="mc md iq kz b la nr ld ns lg nt lk nu lo nv ls oi mi mj mk bi translated">给定一定数量卷积滤波器的预算，我们可以选择将大多数滤波器设为 1×1，<strong class="kz ir">，因为 1×1 滤波器的参数比 3×3 滤波器少 9 倍</strong>。</li></ul><h2 id="3505" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">策略二。将输入通道的数量减少到 3 个<strong class="ak">×3 个滤波器</strong></h2><ul class=""><li id="43cd" class="mc md iq kz b la nr ld ns lg nt lk nu lo nv ls oi mi mj mk bi translated">考虑一个完全由 3 个<strong class="kz ir">×3 个滤镜组成的卷积层。该层中的参数总数为:</strong></li><li id="edf6" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">(输入通道数)<strong class="kz ir"> × </strong>(滤波器数)<strong class="kz ir"> × </strong> (3 <strong class="kz ir"> × </strong> 3)</li><li id="0c0c" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">我们可以<strong class="kz ir">使用挤压层</strong>将输入通道的数量减少到 3×3 滤波器，这将在下一节中提到。</li></ul><h2 id="8723" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">策略三。在网络后期进行下采样，以便卷积图层具有较大的激活图</h2><ul class=""><li id="9aa8" class="mc md iq kz b la nr ld ns lg nt lk nu lo nv ls oi mi mj mk bi translated">直觉是<strong class="kz ir">大的激活图(由于延迟的下采样)可以导致更高的分类精度</strong>。</li></ul><h2 id="49fd" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">摘要</h2><ul class=""><li id="e190" class="mc md iq kz b la nr ld ns lg nt lk nu lo nv ls oi mi mj mk bi translated">策略 1 和 2 是关于明智地减少 CNN 中的参数数量，同时试图保持准确性。</li><li id="236d" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">策略 3 是在有限的参数预算下最大限度地提高精度。</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="f16c" class="mz na iq bd nb nc nd ne nf ng nh ni nj jw nk jx nl jz nm ka nn kc no kd np nq bi translated"><strong class="ak"> 2。消防模块</strong></h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/42fb508f831474843b744d53557fe9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*ONk0HfLLjDcUhUjuu8iq1w.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">Fire Module with hyperparameters: s1x1 = 3, e1x1 = 4, and e3x3 = 4</strong></figcaption></figure><ul class=""><li id="42b0" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls oi mi mj mk bi translated">Fire 模块包括:<strong class="kz ir">一个挤压卷积层(只有 1×1 个滤波器)，进入一个扩展层，该层混合了 1×1 和 3×3 个卷积滤波器</strong>。</li><li id="3674" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">Fire 模块中有三个可调维度(超参数):s1×1、e1×1 和 e3×3。</li><li id="8fb5" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">s1×1:挤压层中 1×1 的个数。</li><li id="415d" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">e1×1 和 e3×3:膨胀层中 1×1 和 3×3 的数量。</li><li id="fe9b" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">当我们使用 Fire 模块时，我们将 s1×1 设置为小于(e1×1 + e3×3)，因此挤压层有助于限制 3×3 滤波器的输入通道数量，如前一节中的策略 2 所示。</li><li id="f784" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">对我来说，这很像《T2》的《盗梦空间》模块。</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="d185" class="mz na iq bd nb nc nd ne nf ng nh ni nj jw nk jx nl jz nm ka nn kc no kd np nq bi translated">3.<strong class="ak"> SqueezeNet 架构</strong></h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ok"><img src="../Images/7d2c43679aa1e6303c03e63aa3974721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y87bqk95D-IndWdHM_K9-g.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">SqueezeNet (Left), SqueezeNet with simple bypass (Middle), SqueezeNet with complex bypass (Right)</strong></figcaption></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ol"><img src="../Images/bbc5f897e77f02f257d4041a835333ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQGAKZb8kjoF_1lSXeIQxg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">Details of SqueezeNet Architecture</strong></figcaption></figure><ul class=""><li id="2852" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls oi mi mj mk bi translated"><strong class="kz ir"> SqueezeNet(左)</strong>:从一个独立的卷积层(conv1)开始，接着是 8 个 Fire 模块(Fire 2–9)，最后是一个 conv 层(conv10)。</li><li id="84e6" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">从网络的起点到终点，每个消防模块的过滤器数量逐渐增加。</li><li id="7fe1" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">跨距为 2 的最大池在层 conv1、fire4、fire8 和 conv10 之后执行。</li><li id="8d1e" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated"><strong class="kz ir">带简单旁路的 SqueezeNet(中)和带复杂旁路的 SqueezeNet(右)</strong>:旁路的使用灵感来自<a class="ae kf" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>。</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="851d" class="mz na iq bd nb nc nd ne nf ng nh ni nj jw nk jx nl jz nm ka nn kc no kd np nq bi translated">4.<strong class="ak">对 SqueezeNet 的评估</strong></h1><h2 id="e94f" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">4.1.SqueezeNet 与模型压缩方法的比较</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi om"><img src="../Images/21aee9fb034790309b3172a786b1f61c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFFDT-Wj_clqwzZ4rpuQKA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">Comparing SqueezeNet to model compression approaches</strong></figcaption></figure><ul class=""><li id="b145" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls oi mi mj mk bi translated"><strong class="kz ir">与</strong><a class="ae kf" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"><strong class="kz ir">Alex net</strong></a><strong class="kz ir">相比，使用 SqueezeNet，我们实现了 50 倍的模型尺寸缩减，同时满足或超过了</strong><a class="ae kf" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"><strong class="kz ir">Alex net</strong></a><strong class="kz ir">的前 1 和前 5 精度。</strong></li><li id="a04b" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">并且模型规模缩减远高于 SVD、网络剪枝和深度压缩。</li><li id="73ca" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">应用 8 位量化的深度压缩，SqueezeNet 产生了一个 0.66 MB 的模型(比 32 位的 Alex net 小 363 倍)，其精度与 T2 的 Alex net 相当。此外，在 SqueezeNet 上应用 6 位量化和 33%稀疏度的深度压缩，这是一个 0.47MB 的模型(比 32 位<a class="ae kf" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"> AlexNet </a>小 510 倍)，具有同等的精度。SqueezeNet 确实经得起压缩。</li></ul><h2 id="1ca9" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">4.2.超参数</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi on"><img src="../Images/418caf331857cbb479ed34f0363efd7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WpPVR0uRit5B_GTGtm7K3Q.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">Different Hyperparameter Values for SqueezeNet</strong></figcaption></figure><ul class=""><li id="0f7e" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls oi mi mj mk bi translated"><strong class="kz ir">挤压比(SR)(左)</strong>:挤压层中的过滤器数量与膨胀层中的过滤器数量之比。</li><li id="cf75" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated"><strong class="kz ir">将 SR 提高到 0.125 以上，可以进一步将 ImageNet top-5 的准确率从 4.8MB 模型的 80.3%(即</strong><a class="ae kf" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"><strong class="kz ir">Alex net</strong></a><strong class="kz ir">-级)提高到 19MB 模型的 86.0%。</strong>精度稳定在 86.0%，SR = 0.75(19MB 模型)，设置 SR=1.0 会进一步增加模型大小，但不会提高精度。</li><li id="dc98" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated"><strong class="kz ir">3×3 过滤器的百分比(右)</strong>:使用 50%的 3×3 过滤器时，前 5 名的精确度稳定在 85.6%，进一步增加 3×3 过滤器的百分比会导致更大的模型尺寸，但不会提高 ImageNet 的精确度。</li></ul><h2 id="6c18" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">4.3.挤压网变体</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2d4619eeed44d4464e3cfbcfeee86915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*o6piFt-s4undSo2itG9eSA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><strong class="bd kw">SqueezeNet accuracy and model size using different macroarchitecture configurations</strong></figcaption></figure><ul class=""><li id="446d" class="mc md iq kz b la lb ld le lg me lk mf lo mg ls oi mi mj mk bi translated">复杂和简单的旁路连接都比普通的 SqueezeNet 架构有了更高的精度。</li><li id="6def" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated"><strong class="kz ir">有趣的是，简单旁路比复杂旁路能够实现更高的准确度。</strong></li><li id="46dc" class="mc md iq kz b la ml ld mm lg mn lk mo lo mp ls oi mi mj mk bi translated">在不增加模型尺寸的情况下，增加简单的旁路连接使前 1 名精度提高了 2.9 个百分点，前 5 名精度提高了 2.2 个百分点。</li></ul></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><p id="271a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用 Fire 模块，可以在保持预测精度的同时减小模型尺寸。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h2 id="7b01" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">参考</h2><p id="73b8" class="pw-post-body-paragraph kx ky iq kz b la nr jr lc ld ns ju lf lg op li lj lk oq lm ln lo or lq lr ls ij bi translated">【2016 arXiv】【SqueezeNet】<br/><a class="ae kf" href="https://arxiv.org/abs/1602.07360" rel="noopener ugc nofollow" target="_blank">SqueezeNet:Alex net 级别的精度，参数少 50 倍，&lt; 0.5MB 模型大小</a></p><h2 id="0393" class="nw na iq bd nb nx ny dn nf nz oa dp nj lg ob oc nl lk od oe nn lo of og np oh bi translated">我以前的评论</h2><p id="4da9" class="pw-post-body-paragraph kx ky iq kz b la nr jr lc ld ns ju lf lg op li lj lk oq lm ln lo or lq lr ls ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(就)(想)(到)(了)(这)(些)(人)(们)(,)(我)(们)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(到)(这)(里)(去)(。 )(他)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(呢)(?)(她)(们)(都)(不)(在)(这)(些)(情)(况)(下)(,)(她)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(吗)(?)(她)(们)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(没)(有)(什)(么)(好)(的)(情)(情)(感)(。</p><p id="8b77" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">物体检测<br/></strong><a class="ae kf" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae kf" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae kf" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-mr-cnn-s-cnn-multi-region-semantic-aware-cnns-object-detection-3bd4e5648fde">MR-CNN&amp;S-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-craft-cascade-region-proposal-network-and-fast-r-cnn-object-detection-2ce987361858">CRAFT</a><a class="ae kf" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae kf" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766"> [</a><a class="ae kf" rel="noopener" target="_blank" href="/review-g-rmi-winner-in-2016-coco-detection-object-detection-af3f2eaf87e4">G-RMI</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-tdm-top-down-modulation-object-detection-3f0efe9e0151" rel="noopener">TDM</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11">SSD</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-dssd-deconvolutional-single-shot-detector-object-detection-d4821a2bbeb5">DSSD</a>][<a class="ae kf" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">约洛夫 1 </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65">约洛夫 2 /约洛 9000 </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6">约洛夫 3</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-fpn-feature-pyramid-network-object-detection-262fc7482610">FPN</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-retinanet-focal-loss-object-detection-38fba6afabe4">视网膜网</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44">DCN</a></p><p id="6582" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">语义切分<br/></strong><a class="ae kf" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplabv 1&amp;deeplabv 2</a><a class="ae kf" rel="noopener" target="_blank" href="/review-crf-rnn-conditional-random-fields-as-recurrent-neural-networks-semantic-segmentation-a11eb6e40c8c">CRF-RNN</a>】<a class="ae kf" rel="noopener" target="_blank" href="/review-segnet-semantic-segmentation-e66f2e30fb96">SegNet</a>】<a class="ae kf" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-drn-dilated-residual-networks-image-classification-semantic-segmentation-d527e1a8fb5">DRN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-refinenet-multi-path-refinement-network-semantic-segmentation-5763d9da47c1">RefineNet</a><a class="ae kf" rel="noopener" target="_blank" href="/review-refinenet-multi-path-refinement-network-semantic-segmentation-5763d9da47c1"/></p><p id="fc65" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">生物医学图像分割<br/></strong>[<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" rel="noopener">cumed vision 1</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" rel="noopener">cumed vision 2/DCAN</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760">U-Net</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cfs-fcn-biomedical-image-segmentation-ae4c9c75bea6" rel="noopener">CFS-FCN</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-u-net-resnet-the-importance-of-long-short-skip-connections-biomedical-image-ccbf8061ff43" rel="noopener">U-Net+ResNet</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-multichannel-segment-colon-histology-images-biomedical-image-segmentation-d7e57902fbfc">多通道</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-v-net-volumetric-convolution-biomedical-image-segmentation-aa15dbaea974">V-Net</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1">3D U-Net</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-m²fcn-multi-stage-multi-recursive-input-fully-convolutional-networks-biomedical-image-4f8d5e3f07f1">M FCN<br/></a></p><p id="3134" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">实例分割<br/> </strong> [ <a class="ae kf" href="https://medium.com/datadriveninvestor/review-sds-simultaneous-detection-and-segmentation-instance-segmentation-80b2a8ce842b" rel="noopener"> SDS </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-hypercolumn-instance-segmentation-367180495979">超列</a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度掩码</a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61">锐度掩码</a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径网络</a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92">实例中心</a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-fcis-winner-in-2016-coco-segmentation-instance-segmentation-ee2d61f465e2"> FCIS </a></p><p id="58de" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">)(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p><p id="f29d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"/><br/><a class="ae kf" rel="noopener" target="_blank" href="/review-deeppose-cascade-of-cnn-human-pose-estimation-cf3170103e36">【DeepPose】</a><a class="ae kf" rel="noopener" target="_blank" href="/review-tompson-nips14-joint-training-of-cnn-and-graphical-model-human-pose-estimation-95016bc510c">【汤普森 NIPS'14】</a><a class="ae kf" rel="noopener" target="_blank" href="/review-tompson-cvpr15-spatial-dropout-human-pose-estimation-c7d6a5cecd8c">【汤普森 CVPR'15】</a></p></div></div>    
</body>
</html>