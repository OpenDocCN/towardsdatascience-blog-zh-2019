<html>
<head>
<title>An Introduction to Naïve Bayes Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯分类器简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-na%C3%AFve-bayes-classifier-fa59e3e24aaf?source=collection_archive---------5-----------------------#2019-09-09">https://towardsdatascience.com/introduction-to-na%C3%AFve-bayes-classifier-fa59e3e24aaf?source=collection_archive---------5-----------------------#2019-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="47ba" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">机器学习和深度学习之旅</h2><div class=""/><div class=""><h2 id="9384" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">从理论到实践，学习朴素贝叶斯的基本原理</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/edb015a9a9bb8cebb8616d0f73c28362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*39U1Ln3tSdFqsfQy6ndxOA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Source: <a class="ae le" href="https://thatware.co/naive-bayes/" rel="noopener ugc nofollow" target="_blank">https://thatware.co/naive-bayes</a>/</figcaption></figure><p id="274f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">本博客将涵盖以下问题和主题:</p><p id="f122" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1.什么是朴素贝叶斯分类器？</p><p id="69d5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2.如何在朴素贝叶斯分类器中计算参数并进行预测？</p><p id="382f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">3.拉普拉斯平滑</p><p id="c0c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">4.python 中的应用</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><ol class=""><li id="f439" class="mi mj iq lh b li lj ll lm lo mk ls ml lw mm ma mn mo mp mq bi translated">什么是朴素贝叶斯分类器？</li></ol><p id="573b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">朴素贝叶斯分类器属于概率分类器家族，使用贝叶斯定理。之所以称之为‘幼稚’，是因为它要求输入变量之间刚性的独立性假设。因此，称之为简单贝叶斯或独立贝叶斯更为恰当。自 20 世纪 60 年代以来，该算法得到了广泛的研究。尽管简单，朴素贝叶斯分类器仍然是解决文本分类问题的流行方法之一，即判断文档属于一个类别或另一个类别的问题，如垃圾邮件检测。</p><p id="e0f5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">朴素贝叶斯分类器的目标是计算条件概率:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mr"><img src="../Images/e455ff42ae1ab0ff006bd71d071e9541.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/1*UG8szmHK8Ke91JrDuCNs1A.gif"/></div></div></figure><p id="e50d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于每个<em class="ms"> K </em>可能的结果或类别<em class="ms"> Ck。</em></p><p id="fc61" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">设<em class="ms"> x=(x1，x2，…，xn) </em>。利用贝叶斯定理，我们可以得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/af0f2697821d4eef66c51f53b82beb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/1*7Zehd5J6ouCiBDAiHXd5Zw.gif"/></div></figure><p id="b299" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">联合概率可以写成:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/4de82adaa59f3e2605efa14818950b39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/1*_bOCibnYisPKvm750_xWww.gif"/></div></figure><p id="d3ac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设所有特征<em class="ms"> x </em>相互独立，我们可以得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/9980e424cb223790e22413d39747bdd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/1*A5eZ_R-9QLtJE76TBTTdLA.gif"/></div></figure><p id="26d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，公式可以写成:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/a9918a8b380e0e7bc39f0196c596948e.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/1*YqmJk4S8fKGT28sDDQnPIw.gif"/></div></figure><p id="709c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，这是朴素贝叶斯分类器的最终公式。</p><p id="9fef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 2。</strong> <strong class="lh ja">如何在朴素贝叶斯分类器中计算参数并进行预测？</strong></p><p id="b1f2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最大似然估计(MLE)用于估计参数——先验概率和条件概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0b26b6aaef8ab5426aaac65b7acb2645.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/1*kAwCWT_uBiPZLFlfw4aOrw.gif"/></div></figure><p id="0b7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">先验概率等于 y 发生的某些情况的数量除以记录总数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/afee5993761d05e5aa3185aa487155e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/1*y9d2B7bbitu_lPWjicI2VA.gif"/></div></figure><p id="dcdb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="ms"> p(x1=a1|y=C1) </em>的条件概率等于 x1 等于 a1 <strong class="lh ja">和</strong> y 等于 C1 的情况数除以 y 等于 C1 的情况数。</p><p id="12b0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">朴素贝叶斯分类器使用以下公式进行预测:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/f85432b9a84215735a6d3796d97bea12.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/1*H3HGRc39_cO3ByUePdanXQ.gif"/></div></figure><p id="f53f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，下表中的 15 条记录用于训练朴素贝叶斯模型，然后对新记录<em class="ms"> X(B，S)进行预测。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/47ea0b5598a23f804ac442ddbb2cda1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*I6X2h2D_NcAggoPFiDGMgQ.png"/></div></figure><p id="7214" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用上面的公式来估计先验概率和条件概率，我们可以得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/c86a3179c3505b87b1638395bfb3b85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*t-Jd4AHdgiUPozbtVskR4w.png"/></div></figure><p id="ebfb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，截止到<em class="ms"> X(B，S)</em>我们可以得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/0b9a08fa46b90c27741d7654e313003f.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*TUyMqjhXCIJ1aDeYzXPhrw.png"/></div></figure><p id="df79" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="ms">P(Y = 0)P(X1 = B | Y = 0)P(X2 = S | Y = 0)&gt;P(Y = 1)P(X1 = B | Y = 1)P(X2 = S | Y = 1)</em>所以<em class="ms"> y=0。</em></p><p id="b6d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 3。拉普拉斯平滑</strong></p><p id="292c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在统计学中，拉普拉斯平滑是一种平滑分类数据的技术。引入拉普拉斯平滑来解决零概率问题。应用这种方法，先验概率和条件概率可以写成:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/7db587ec16c19ba6a7b4d4cbe3c06082.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/1*aYWu1Hu6gKE84vJZTc4QDg.gif"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ne"><img src="../Images/7ec532161c18f4f1835046b8c002a77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/1*3La5dY6mBTcRYB9kRgEU8A.gif"/></div></div></figure><p id="58b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="ms"> K </em>表示<em class="ms"> y </em>中不同值的个数，<em class="ms"> A </em>表示<em class="ms"> aj 中不同值的个数。</em>通常公式中的λ等于 1。</p><p id="cf6f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过应用拉普拉斯平滑，先前示例中的先验概率和条件概率可以写成:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/046c29edd1f4e8858e08232fcd9fe64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*iDN36TBFfDd8g7k1Y8rtKw.png"/></div></figure><p id="b228" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 4。python 中的应用</strong></p><p id="2d16" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤 1:创建数据集。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="fa88" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">步骤 2:通过计算先验和条件概率来训练朴素贝叶斯模型。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="71f9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三步:做一个预测。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="320e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">概要:</strong></p><p id="1ec7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">朴素贝叶斯分类器易于快速训练，可作为基准模型。当变量选择适当时，朴素贝叶斯可以表现得和其他统计模型一样好，甚至更好，如逻辑回归和 SVM。朴素贝叶斯需要对独立预测器的强假设，因此当模型表现不佳时，导致这种情况的原因可能是预测器之间的相关性。</p><p id="f970" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以点击以下链接阅读更多博客:</p><div class="ni nj gp gr nk nl"><a href="https://medium.com/@songyangdetang_41589/table-of-contents-689c8af0c731" rel="noopener follow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ja gy z fp nq fr fs nr fu fw iz bi translated">机器学习和深度学习之旅</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">这一系列博客将从理论和实现两个方面对深度学习进行介绍。</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">medium.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz ky nl"/></div></div></a></div><p id="4eb6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">参考:</strong></p><p id="9964" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[1] Christopher M. Bishop，(2009)，<em class="ms">模式识别和机器学习</em></p><p id="20e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Naive_Bayes_classifier</a></p><p id="6ba4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/Additive_smoothing" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Additive_smoothing</a></p></div></div>    
</body>
</html>