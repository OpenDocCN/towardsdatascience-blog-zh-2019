<html>
<head>
<title>Generalized Linear Models — Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">广义线性模型—简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generalized-linear-models-introduction-1b4af2a11759?source=collection_archive---------23-----------------------#2019-11-17">https://towardsdatascience.com/generalized-linear-models-introduction-1b4af2a11759?source=collection_archive---------23-----------------------#2019-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="faab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本文探讨了线性模型的背景，它们的局限性和广义线性模型背后的思想，以及是什么使它们广义化。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c37a7c8e76ad5480173554696cdb741d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4707mjoFsJIdgPq9"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="kw kx ky"><p id="37c5" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ir">什么是机器学习中的线性模型？</strong></p></blockquote><p id="d867" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">为了举例说明这个主题，我采用了这个数据集的<a class="ae kv" href="https://people.sc.fsu.edu/~jburkardt/datasets/regression/x01.txt" rel="noopener ugc nofollow" target="_blank">，它有一个预测器/特征/自变量/解释变量，即<code class="fe lz ma mb mc b">Brain Weight</code>和一个响应/目标/因变量，即<code class="fe lz ma mb mc b">Body Weight</code>。</a></p><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="9acc" class="mh mi iq mc b gy mj mk l ml mm">Index Brain Weight Body Weight<br/> 1          3.385     44.500<br/> 2          0.480     15.500<br/> 3          1.350      8.100<br/> 4        465.000    423.000<br/> 5         36.330    119.500<br/> 6         27.660    115.000<br/>...</span></pre><p id="a8ec" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">响应变量<code class="fe lz ma mb mc b">Body Wight </code>具有连续分布。我们可以将该分布建模为预测值的线性组合— <code class="fe lz ma mb mc b">Brain Weight,</code>(在该数据集中仅有一个)和截距项。这里，模型本质上是试图学习与每个特征相关联的权重/参数。在数学上，我们必须建立以下线性方程的模型—</p><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="8e30" class="mh mi iq mc b gy mj mk l ml mm">y = Body Weight [Response]<br/>X = Brain Weight [Predictor]<br/>We are interested to model the following equation <strong class="mc ir"><em class="lb">y_hat</em></strong><br/><strong class="mc ir">     y_hat = W1*X1 + W0<br/>     y = y_hat + e</strong></span></pre><p id="ac82" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">上式中，<code class="fe lz ma mb mc b"><strong class="lc ir">W1</strong></code><strong class="lc ir"/><code class="fe lz ma mb mc b"><strong class="lc ir">W0</strong></code><strong class="lc ir"/>统称为模型参数。在线性模型的上下文中，<code class="fe lz ma mb mc b"><strong class="lc ir">W1</strong></code>和<code class="fe lz ma mb mc b"><strong class="lc ir">W0</strong></code> <strong class="lc ir"> </strong>分别称为系数和截距。<code class="fe lz ma mb mc b"><strong class="lc ir">W0</strong></code> <strong class="lc ir"> </strong>代表所有<code class="fe lz ma mb mc b"><strong class="lc ir">X1</strong></code>预测值为零的情况，<code class="fe lz ma mb mc b"><strong class="lc ir">W0</strong></code>是我们的模型将预测的值。</p><p id="9ae6" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe lz ma mb mc b"><strong class="lc ir">e</strong></code>称为误差项。这是不能从预测者的知识中预测的误差。这是观察到的结果(即<code class="fe lz ma mb mc b"><strong class="lc ir">y</strong></code>)与我们的模型预测的结果(即<code class="fe lz ma mb mc b"><strong class="lc ir">W1*X1 + W0</strong></code>)之间的差异。</p><p id="22cb" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">回归函数告诉我们，对于<code class="fe lz ma mb mc b">X1</code>值的单位变化(增加或减少),响应变量<code class="fe lz ma mb mc b">y</code>平均变化<em class="lb">多少。</em></p><p id="c7bd" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">下面的图是符合数据的超平面(在这种情况下是直线)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/e523b008b1322ada6ba842f0fef704ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KtPSs1Btl2zHEfPaHvHO4A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 1: Linear Regression Example</strong></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/87b1a375bcfad3095471ebb843016ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*11H_EcRWYJvemwqyHgLF5A.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 2: Learned Parameter of the Linear Model</strong></figcaption></figure><p id="3d63" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们将再举一个例子来更具体地说明线性模型的思想。<br/>在这个例子中，我们有<a class="ae kv" href="https://people.sc.fsu.edu/~jburkardt/datasets/regression/x06.txt" rel="noopener ugc nofollow" target="_blank">这个数据集</a>，它包含两个预测值和一个连续响应变量。在这种情况下，我们有以下情况—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/f96794e4e864771b1fc3fec11703932e.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*RVrz3NTz6CQGHArgWVIEvg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 3: Fish Length Data</strong></figcaption></figure><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="27b6" class="mh mi iq mc b gy mj mk l ml mm">y = Fish Length [Response]<br/>X1 = Age [Predictor]<br/>X2 = Water Temperature[Predictor]</span><span id="655b" class="mh mi iq mc b gy mr mk l ml mm">We are interested to model the following equation <strong class="mc ir"><em class="lb">y_hat</em></strong><br/><strong class="mc ir">     y_hat = W1*X1 + W2*X2 + W0<br/></strong>     <strong class="mc ir">y = y_hat + e</strong></span></pre><p id="96b2" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">下面的超平面(在这种情况下是平面)是使用模型学习的参数，即<code class="fe lz ma mb mc b">W1, W2, W0</code>绘制的。虽然它不是数据的最佳拟合，但我们的重点是线性模型的基本概念，而不是模型的预测能力。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/cc294a515ec18c6648deb0c6db477244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*lWkn8BByYfpyn6OSDe4idQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 5: Linear Model with two Predictors</strong></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/f07abd60624bdb153865167f5627cc72.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*yjiG6i8jJUmS1YTf9EnqZQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 5: Learned Parameter of the Linear Model</strong></figcaption></figure><p id="10d5" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们可以通过将学习到的参数放入方程<code class="fe lz ma mb mc b">y_hat = W1*X1 + W2*X2 + W0</code>来比较和交叉检查方程<code class="fe lz ma mb mc b">y = y_hat + e</code>。为了简洁起见，我取了数据集的前十行。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/e61833877b7bda206b40478ba145c5b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1KSHgyf5pGnz5BRPsWAdeQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 6: Error which cannot be predicted by the model</strong></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/98058b781791602dcb7cdd8738257187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jdHHRHiSZ959QTGabVv4zQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 7: Comparison between y and y_hat</strong></figcaption></figure><p id="3d5d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们可以清楚地看到，<code class="fe lz ma mb mc b">y</code>非常接近等于<code class="fe lz ma mb mc b">y_hat</code>和误差项<code class="fe lz ma mb mc b">e</code>的总和。</p><p id="a6b9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">根据上述讨论，我们可以得出结论，线性模型意味着随机变量的分布被建模为特征/预测值的<em class="lb">线性</em>组合。</p><blockquote class="kw kx ky"><p id="a667" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ir">线性模型中的‘线性’是什么？</strong></p></blockquote><p id="9e6f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">当我们说“特征的线性组合”时，意思是模型参数<code class="fe lz ma mb mc b">Wi</code>是线性的，阶数为 1，而不是特征。我们估计线性参数，而不是在线性模型中估计类似于<code class="fe lz ma mb mc b">W1², W1*W2</code>的东西。此外，特性可以有不同种类的术语，如— <code class="fe lz ma mb mc b">X1, X1*X2, X2²</code>等。</p><p id="f659" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">现在我们可以为线性模型写一个通用方程如下—</p><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="0d96" class="mh mi iq mc b gy mj mk l ml mm">y = W0 + W1*X1 + W2*X2 + W3*X3 + ... + Wn*Xn + e</span></pre><p id="4e40" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">但是，当我们进行线性回归时，我们做出某些假设，例如:1。响应变量的<strong class="lc ir">分布</strong>为正态分布，即<code class="fe lz ma mb mc b"><em class="lb">Y_i ~ N(</em></code> <em class="lb"> μ_i，σ </em> <code class="fe lz ma mb mc b"><em class="lb">)<br/></em></code> 2。<strong class="lc ir">预测因子/解释变量<code class="fe lz ma mb mc b">Xi</code>的功能</strong>是<code class="fe lz ma mb mc b">W0 + Wi*Xi</code>3。<strong class="lc ir">解释变量和<code class="fe lz ma mb mc b">Yi </code>分布之间的连接/联系</strong>是响应变量的平均值。<br/>每个数据点的预测值将以方差<em class="lb"> σ分布在平均值周围。</em></p><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="95e5" class="mh mi iq mc b gy mj mk l ml mm"><em class="lb">                      </em><strong class="mc ir"><em class="lb">μ_i = E(Y_i) = W0 + Wi*Xi</em></strong></span></pre><p id="ef19" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">线性模型的局限性- <br/> 1。常态假设并不总是成立的，我们可能有自己的分类特征，如性别、职业类型等。或者我们可能有非正态分布的时间序列数据。<br/> 2。线性模型无法拟合具有分类响应变量的数据，如鸢尾花数据集、MNIST 数据集等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/878860d5eee47899ab709419f48526b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*VhNkM2B-U3DVQyZFAOR3vg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 8: Distribution of Categorical Target Variable</strong></figcaption></figure><p id="9e49" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">3.即使响应变量是连续的随机变量，但是其取值在诸如 0 和 1 之间的概率的范围内。<br/>传统的线性模型将无法预测 0 到 1 之间的值，因为我们的特征可以取范围(-∞，∞)内的任何值。</p><p id="665d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">现在我们已经知道，线性模型并不总是正确的选择，因为它与连续响应数据不同，可能会提供相当奇怪的结果。现在我们要做的是推广这个模型来克服这样的问题。这就产生了 GLMs，它提供了一个统一的框架，用于对源自概率分布指数族(如正态分布、二项式分布、泊松分布等)的数据进行建模。</p><p id="a177" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">GLM 有三个组成部分。</p><ol class=""><li id="027b" class="mx my iq lc b ld le lg lh lw mz lx na ly nb lv nc nd ne nf bi translated"><strong class="lc ir">随机分量— </strong>定义响应变量 y 及其概率分布。一个重要的假设是从<code class="fe lz ma mb mc b">y1 </code>到<code class="fe lz ma mb mc b">yn</code>的响应是相互独立的。</li><li id="5c78" class="mx my iq lc b ld ng lg nh lw ni lx nj ly nk lv nc nd ne nf bi translated"><strong class="lc ir">系统组件— </strong>定义我们希望在模型中包含哪些解释变量。它还允许解释变量之间的相互作用，例如— <code class="fe lz ma mb mc b">X1*X2</code>、<code class="fe lz ma mb mc b">X1² etc.</code>这是我们建模的部分。它也被称为协变量的线性预测器，即<code class="fe lz ma mb mc b">X1, X2, … , Xn</code>和系数的线性预测器，即<code class="fe lz ma mb mc b">W1, W2, … , Wn.</code></li><li id="7803" class="mx my iq lc b ld ng lg nh lw ni lx nj ly nk lv nc nd ne nf bi translated"><strong class="lc ir">链接组件— </strong>连接随机组件和系统组件。响应变量期望值的函数，即<code class="fe lz ma mb mc b">E(Y)</code>，使参数呈线性，并允许<code class="fe lz ma mb mc b">E(Y)</code>与解释变量呈非线性关系。<strong class="lc ir">链接函数概括了线性模型。</strong></li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/596d8eb03e743c3f4230c2553bcdb35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*roJAYc7BCqBaBX-c4pt-ZA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 9: Components of GLM</strong></figcaption></figure><p id="2ece" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">注意，连接函数的选择与随机分量的选择是分开的。</p><p id="15f0" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">现在我们可以说，简单线性回归模型是 GLM 的一个特例，其中随机分量具有正态分布，并且取范围(-∞，∞)内的连续值。系统组件是<code class="fe lz ma mb mc b">X.</code>链接功能是标识功能。</p><pre class="kg kh ki kj gt md mc me mf aw mg bi"><span id="6759" class="mh mi iq mc b gy mj mk l ml mm"><em class="lb">                        Y ~ N(</em><em class="lb">μ, σ²</em><em class="lb">)<br/>                        E(Y) = μ<br/>                        g(E(Y)) = μ = W1*X1 + e</em></span></pre><blockquote class="kw kx ky"><p id="ac94" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ir">我们在 GLMs 中概括了什么？</strong></p></blockquote><ol class=""><li id="b9cf" class="mx my iq lc b ld le lg lh lw mz lx na ly nb lv nc nd ne nf bi translated">我们推广了响应变量的<strong class="lc ir">分布</strong>，即<code class="fe lz ma mb mc b">y</code>，可以取。</li><li id="8a41" class="mx my iq lc b ld ng lg nh lw ni lx nj ly nk lv nc nd ne nf bi translated">我们在解释变量<code class="fe lz ma mb mc b">Xi</code>和响应变量<code class="fe lz ma mb mc b">Yi</code>之间推广了<strong class="lc ir">链接函数</strong>。</li></ol><p id="7391" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">下表包含了常用的链接功能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4357b5a8e33ea88ff22e181a71dea8dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*d66NoyRv7QgA4HovMcxJBQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd mo">Figure 10: Types of Link Functions</strong></figcaption></figure><p id="e9e6" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">让我们总结一下到目前为止我们所讨论的内容——T4。线性模型适合于模拟连续响应变量，但它们有一定的局限性。<br/> 2。广义线性模型统一了许多不同类型的属于指数密度族的响应变量分布。<br/> 3。链接函数是 GLM 中实现参数线性的关键组件，并且是概括线性模型的组件。</p><p id="2a67" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><strong class="lc ir">参考文献:</strong><br/>【1】b . Caffo，<a class="ae kv" href="https://www.youtube.com/watch?v=xEwM1nzQckY" rel="noopener ugc nofollow" target="_blank"> 03 01 第 1 部分共 1 部分广义线性模型</a>(2015)<br/>【2】r . Cooksey，<a class="ae kv" href="https://www.youtube.com/watch?v=HXTeJfIQXUc" rel="noopener ugc nofollow" target="_blank">一般线性模型的逻辑(GLM)</a>(2013)<br/>【3】精算教育，<a class="ae kv" href="https://www.youtube.com/watch?v=vpKpFMUMaVw" rel="noopener ugc nofollow" target="_blank"> CT6 广义线性模型导论(GLMs) </a> (2012)</p></div></div>    
</body>
</html>