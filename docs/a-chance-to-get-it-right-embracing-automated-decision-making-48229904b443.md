# 做对的机会:拥抱自动化决策

> 原文：<https://towardsdatascience.com/a-chance-to-get-it-right-embracing-automated-decision-making-48229904b443?source=collection_archive---------39----------------------->

![](img/c8688defe7d62104fef3b1b17a39a800.png)

franki chamak for unsplash

## 用 ADM 减少偏差

几十年来，我们带着一种无可奈何的无奈目睹了不平衡的权力、财富、种族和性别动态扭曲了我们最基本的权利:自由、追求幸福、工作，甚至是我们头顶上的屋顶。经济差距、种族偏见和性别歧视如此根深蒂固，我们常常忘记看清它们的本质:源于几个世纪的不平等、种族主义和厌女症的系统性偏见决策的结果。

因此……在训练我们人类思维的“数据集”中积累了多年的错误数据。

上周在柏林举行的人工智能峰会上，伦理是一个热门话题。现在，自动化决策(ADM ),或者至少是对它的半知半解，无处不在，对有偏见的数据和歧视性决策的担忧十分猖獗。

**是时候了！**

政客们正在质疑预测性警务的公平性。伦理机构要求对雇佣算法进行问责。为计算信用分数而输入训练集的数据正在被剖析，以寻找偏见的痕迹。

**本质上，既然机器正在做出错误的决定，我们就要奋起反抗。**

这里的最终目标——为所有人的利益作出公正的决定——是最崇高的事业。但似乎我们对 ADM 的期望取代了我们对自己的期望，以及我们人类做出公正决定的能力，或者说缺乏这种能力。

这显然没有错！没有人希望机器延续我们人类的弱点。尤其是当两倍、三倍、四倍——质疑数据和决策的准确性和公平性可能意味着正确和不正确的医疗诊断、错误和合理的监禁以及适合我们特定体型的最好和最差牛仔裤之间的差异。好吧…划掉最后一个。

而且，如果我们对完美算法的厚望是由于新发现的不愿对非法监禁、雇佣歧视、偏袒和裙带关系视而不见的结果，那就更好了！健康的怀疑是一种受欢迎的批评和监管形式，如果它确实能防止我们偏离非歧视性(自动化)决策的正确道路。

但最近，对 ADM 的非理性焦虑表明了对人工超级智能和奇点的好莱坞先驱的天真信仰。反对 ADM 的声音越来越大，越来越无知，越来越具有煽动性，这似乎是因为害怕将我们最独特和最具决定性的人类能力，即思考和判断的能力交给机器。考虑到我们在运用这些技能时相对糟糕的记录，这有点荒谬…

如果你从这篇文章中只带走一件事，请让它成为这样:算法做出的任何有偏见和歧视性的自动化决策都是我们自己糟糕的决策能力的直接反映。

不要射杀信使！

有无数的机构、基金会和工作论文致力于道德 AI 和 ADM 的主题。他们阐述了问责制、可追溯性、补救和整体公平的重要性。它们阐明了多样化的团队和庞大的(无错误的)数据集将如何帮助我们做出公正的决策。这很有道理！我们的观点越多，数据越有代表性，判断或评估不公平的可能性就越小。当然，自动化决策和我们一样有缺陷。

因此，与其坚持认为它们是问题所在，不如承认我们确实是问题所在。承认我们历史上不可靠的决策性能可能是自动化决策正确的唯一方式。历史会重演。至少在模拟世界里是这样。在数字世界并非如此。机器与我们相比有一个明显的优势，那就是它们不会注定不断重复错误。他们比我们更好地学习和记忆。

如果训练得当，自动化决策可能会把我们从固有的偏见中拯救出来！

要跟踪关于伦理 ADM 和机器学习的讨论，请查看 WEF 的工作论文 [*如何防止机器学习中的歧视性结果*](http://www3.weforum.org/docs/WEF_40065_White_Paper_How_to_Prevent_Discriminatory_Outcomes_in_Machine_Learning.pdf) *。*