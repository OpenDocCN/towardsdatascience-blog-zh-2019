<html>
<head>
<title>Calculating R-squared from scratch (using python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始计算 R 平方(使用 python)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/r-squared-recipe-5814995fa39a?source=collection_archive---------1-----------------------#2019-06-18">https://towardsdatascience.com/r-squared-recipe-5814995fa39a?source=collection_archive---------1-----------------------#2019-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b18" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于 r 平方是什么的复习，以及如何计算的直观逐步指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3eb56a0073534b971a94e0fc0ce83541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Vt14wluaJHmDUe2Z"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Source of image: <a class="ae ky" href="https://unsplash.com/photos/38pqG4k6tnY" rel="noopener ugc nofollow" target="_blank">link</a>. Pine-cones have the <a class="ae ky" href="https://www.khanacademy.org/math/math-for-fun-and-glory/vi-hart/spirals-fibonacci/v/doodling-in-math-spirals-fibonacci-and-being-a-plant-1-of-3" rel="noopener ugc nofollow" target="_blank">Fibonacci Sequence</a> in them</figcaption></figure><p id="e04c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">R 的平方在概念上很难理解。我没有介绍其中涉及的数学公式，而是认为展示它是如何从零开始直观地计算的，并用简单的英语解释每一步可能会令人耳目一新。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="cbe2" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">什么是 R 平方？</h1><p id="56d9" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">这是一种介于 0 和 1 之间的统计方法，用于计算回归线与其拟合的数据的相似程度。如果是 1，模型 100%预测数据方差；如果它是 0，模型预测没有方差。</p><blockquote class="ni"><p id="93dd" class="nj nk it bd nl nm nn no np nq nr lu dk translated">r 平方=模型的解释方差/目标变量的总方差</p></blockquote><p id="7825" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">还是没有意义？别担心。让我们深入了解这意味着什么</p><ul class=""><li id="edc3" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">首先，解释什么是计算 r 平方的必要条件。</li><li id="90bc" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">第二，通过一个简单的数据集一步一步地计算这个统计指标。</li></ul><h1 id="4e6f" class="ml mm it bd mn mo ol mq mr ms om mu mv jz on ka mx kc oo kd mz kf op kg nb nc bi translated">我们需要什么:</h1><ul class=""><li id="8e66" class="nx ny it lb b lc nd lf ne li oq lm or lq os lu oc od oe of bi translated">包含至少一个自变量(X)和一个因变量(Y)的数据集</li><li id="3217" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">数据拟合的线性回归。</li><li id="87dd" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">数据上平均值 Y 的一条水平线(这个我一会儿再解释)。</li><li id="2473" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">Python(甚至只要一支笔一张纸就可以)。</li></ul></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="19f9" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">第一步:有一个数据集，并形成一个线性回归</h1><p id="761f" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">重要的是要记住，在这个例子中，我们使用的是任意数据。我们可以用任何数据集来做这个练习。x 是一个从 0 到 9 的整数数组。y 是由<a class="ae ky" href="https://en.wikipedia.org/wiki/Fibonacci_number" rel="noopener ugc nofollow" target="_blank">斐波纳契数列</a>的前 10 位数字组成的数组。绘制数据点后，我们将在顶部拟合普通最小二乘回归(OLS)线。</p><p id="943a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更多关于线性回归的信息可以在<a class="ae ky" rel="noopener" target="_blank" href="/linear-vs-polynomial-regression-walk-through-83ca4f2363a3">这里</a>找到。但是 OLS 背后的主要思想是，它试图预测每个 x 的 Y 在哪里</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0ad5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这条线看起来相当合身。蓝点离回归线不太远。点离线越近，我们的方差越低。方差越低，我们的模型越好！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/304baddf2b274386cdb943419b55dcf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VL1WRStBmAuOYn2CpFG04w.png"/></div></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="07b3" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">第二步:水平 Y.mean()线</h1><p id="d9be" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">接下来，我们将在数据上放置另一行。如果我们理论上只有 Y 数据(没有 X)，我们能够做出的最佳预测模型将是每次猜测 Y 的平均值。这是计算 r 平方的关键一步，你马上就会看到。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="7295" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与之前的绿色回归线相比，这条红线离圆点更远。这意味着它有更高的方差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/8da5629776fecae459c7a2b7f9e176e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*LYsbot7h_WmU5WRVrw7XHQ.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="c1ee" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 3:实际数据点和线性模型之间的方差</h1><p id="d1f5" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">如果我们测量数据的每个点和线性回归线之间的差异，平方每个差异并合计它们，我们将获得回归模型中存在的方差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/90f4edeec37d38e6d9061e35deb1d59e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wD6d4KRygokRoXlKm05H2Q.png"/></div></div></figure><p id="5557" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是下面计算的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/4cbcab6c31499daa035ba2198419b021.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*hAoJnBW2iHXJyg4_gVErsg.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5e97" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 4:实际数据点和 Y.mean()线之间的平方差。</h1><p id="a038" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">如果我们测量数据的每个点与水平线之间的差异，对每个差异进行平方并对它们求和，我们将获得只存在于 Y 数据集中的总方差。记住，这是我们将使用的独立于 X 数据存在的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/f4d86d4812bfad518e01585e7960664c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*d9rqLUmWVgcmiDkSbBYPpQ.png"/></div></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl pa"><img src="../Images/554d2faed29814102b638c8444b63447.png" data-original-src="https://miro.medium.com/v2/format:webp/1*UlJDYJaUJQjI9nrP14aKAQ.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="ead8" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 5:最后一步和检查工作</h1><p id="ee40" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">让我们后退一步，想想我们到目前为止的计算结果:</p><ol class=""><li id="d381" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu pb od oe of bi translated">我们的线性模型的方差:1753</li><li id="2472" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu pb od oe of bi translated">目标变量的总方差:7524</li></ol><p id="e8b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也提醒一下自己，r 平方的定义是什么:“模型的解释方差/目标变量的总方差”。</p><p id="a4ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的回归模型中，方差要小得多。这是因为我们考虑了分析 X 数据与 Y 数据的关系所获得的信息。总方差，另一方面，有较少的信息开始，因此它有一个较高的方差。如果我们想量化使用线性回归减少了多少方差，我们可以取总方差和回归线方差之差。这将给出“由模型解释的”方差。<strong class="lb iu">7524–1753 = 5771</strong></p><p id="023c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在要做的就是把模型解释的方差放在总方差上求 rsquared: <strong class="lb iu"> 5771/ 7524 = 0.767。</strong>这个数字可以解释为:Y 的变化有 76.7%可以用 x 的变化来解释。</p><p id="7e76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保我们做得正确，让我们用 sk learn“R2 _ score”函数来检查我们的答案:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/5626d58eef99833ba034285955720660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*2RwpPAldFJP-1LNjxP0aBg.png"/></div></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="d012" class="pd mm it bd mn pe pf dn mr pg ph dp mv li pi pj mx lm pk pl mz lq pm pn nb po bi translated">如果你喜欢我的内容，请查看其他几个项目:</h2><p id="3163" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/univariate-logistic-regression-example-in-python-acbefde8cc14"> <em class="pp">了解二元逻辑回归</em> </a></p><p id="c1ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/is-random-forest-better-than-logistic-regression-a-comparison-7a0f068963e4"> <em class="pp">随机森林是否优于 Logistic 回归？</em>(一比较)</a></p><p id="9512" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/excel-vs-sql-a-conceptual-comparison-dcfbee640c83"> <em class="pp"> Excel 与 SQL:概念上的比较</em> </a></p><p id="3a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/predicting-cancer-with-logistic-regression-in-python-7b203ace16bc"> <em class="pp">用 Python 中的逻辑回归预测癌症</em> </a></p><p id="e073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/portfolio-linear-optimization-breakdown-f519546ed1ff"> <em class="pp">利用数学和 Python 优化你的投资</em> </a></p><p id="2806" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/uber-reviews-text-analysis-11613675046d"> <em class="pp">优步评论文本分析</em> </a></p><p id="07cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/word-clouds-in-python-comprehensive-example-8aee4343c0bf"><em class="pp">Python 中的字云:综合示例</em> </a></p><p id="6abb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安德鲁</p></div></div>    
</body>
</html>