<html>
<head>
<title>Decision Trees — Introduction (ID3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树—简介(ID3)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-trees-introduction-id3-8447fd5213e9?source=collection_archive---------10-----------------------#2019-08-29">https://towardsdatascience.com/decision-trees-introduction-id3-8447fd5213e9?source=collection_archive---------10-----------------------#2019-08-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="700c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你有没有想过如何从过去的经验中学习？</h2></div><p id="e326" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你一生中会遇到不同类型的人，经过一些经历后，你会知道你喜欢什么样的人，对吗？我的意思是，在与许多人有过几次经历之后，当你遇到一个新的人时，大多数时候你会知道你是否喜欢他们。你是怎么做到的？有了<strong class="kh ir">‘经验’</strong>！对吗？但是你不会一直将多年的经验保存在大脑的顶部，而不是感觉到一些简单快速的决策机制在你的大脑中工作。</p><p id="2b01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，与其深入研究大脑的生物学，不如让我们尝试在更简单的层面上建立一个类似的机制。</p><p id="177a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设在你与几个人相遇后，你不想让吸血鬼成为你未来的朋友:P</p><p id="3884" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以你列出了你遇到的几个人，他们的特征，以及他们是否是吸血鬼。( "?"在阴影中属性是因为你只在黑暗的条件下遇到那些人，所以你无法验证他们是否投下阴影)</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/c00834a8d49667673cea04bf862c9dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*8vIdDVRoRXl2wBiGDfnF8A.png"/></div></figure><p id="1ae6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在观察了<strong class="kh ir">这个数据</strong>之后，我们可能会得出一个像这棵树一样的幼稚模型，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/41bafc08e9e2b2e32fc50a5d62600f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*bFIgXpswmqs9nh8sPhFBnA.png"/></div></figure><p id="d807" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为有了那棵树的帮助，我们可以做出决定，所以我们称之为“决策树”。这个树必须满足给定数据集中的所有数据，我们希望它也能满足未来的输入。</p><p id="e35a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们怎么能做出这样的树呢？上面给出的树只是通过对数据的一些随机观察…</p><p id="21b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据观察结果…</p><ul class=""><li id="2e7b" class="lk ll iq kh b ki kj kl km ko lm ks ln kw lo la lp lq lr ls bi translated">所有肤色苍白的人<strong class="kh ir">都不是吸血鬼</strong>。</li><li id="1901" class="lk ll iq kh b ki lt kl lu ko lv ks lw kw lx la lp lq lr ls bi translated">所有面色红润吃大蒜的人都不是吸血鬼，如果他们不吃大蒜，那么他们就是吸血鬼。</li><li id="59b7" class="lk ll iq kh b ki lt kl lu ko lv ks lw kw lx la lp lq lr ls bi translated">所有肤色普通的人，如果他们没有影子或者我们不知道他们是否有影子，那么他们<strong class="kh ir">是吸血鬼</strong>，或者如果他们有影子，那么他们<strong class="kh ir">不是吸血鬼</strong>。</li></ul><p id="0ec9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，这是建立决策树的正确方法吗？那棵树是我们能从给定的数据集中得到的最简单的树。</p><p id="051d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种对大型数据集的随机分析是不可行的。我们需要一些系统的方法来解决这个问题。</p><h2 id="36da" class="ly lz iq bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">让我们尝试用贪婪的方法来解决这个问题…</h2><p id="b9f6" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">首先，我们查看数据集并决定我们应该为树的根节点选择哪个属性…</p><p id="45a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个布尔分类，所以在决策树的末尾我们会有 2 个可能的结果(要么他们是吸血鬼，要么不是)，所以每个输入的例子会被分类为真(正面例子)和假(负面例子)。</p><p id="98b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里'<strong class="kh ir"> P' </strong>指阳性，表示一个人<strong class="kh ir">是吸血鬼，</strong>，‘N’指阴性，表示这个人<strong class="kh ir">不是吸血鬼。</strong></p><p id="b01f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望属性将更多的数据分成同质的集合，这意味着在这样的集合中，只有 P 或 N 存在，因为如果我们有，我们肯定可以回答关于吸血鬼或没有，因此这些将是树的叶节点。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/d0bdc0981c5e08defe8f63008816a845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkjgTCuNtA6_o1U6RmHJ0g.png"/></div></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/3860612b282cef07b2b591283547233f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*hTKbRm0maDtPo3zTJhaDbw.png"/></div></figure><p id="d3cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查每个属性，看哪一个属性在同构集中的元素数量最多。在这里，我们发现<strong class="kh ir">‘Shadow’</strong>属性在同质集合中具有最高的元素计数，所以我们选择这个属性。</p><p id="6301" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以到目前为止，我们有这么多的树…</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/38256d6cf5edeac97632d8c18ae7e261.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*Q3H8-PETRwvpSsnubvzmFA.png"/></div></figure><p id="1c83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于影子属性<strong class="kh ir">【是】</strong><strong class="kh ir">【否】</strong>，我们可以决定一个人是不是吸血鬼，但是万一<strong class="kh ir">【呢？”</strong>我们不知道，我们需要决定当<strong class="kh ir"> shadow = '？'时，哪个属性划分数据好</strong></p><p id="d3d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，让我们在阴影未知的情况下分析另一个属性…</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/6b8870805e634dd4bb4048786704aa76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*rtWVm7rMITzofn9mR20jWA.png"/></div></figure><p id="11ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们发现“大蒜？”属性划分最大元素，实际上是同质集合中的所有元素。</p><p id="2058" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，我们的树现在看起来像这样，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/29caa5cf8d3a534ba4349cba21c54fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*HL8rjfnNDteRmJaRw-MSBg.png"/></div></figure><p id="e983" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个树看起来比我们通过选择随机属性创建的树更简单，所以我们观察到贪婪方法帮助我们获得更好的结果。</p><p id="985c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，这是正确的做法吗？</p><p id="6ac3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不会，因为如果数据集很大，我们不需要将属性划分到同质集合中，我们可能会发现同质集合中的所有属性元素都是 0。</p><h2 id="de8c" class="ly lz iq bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">那么我们应该如何进行呢？</h2><p id="cdbe" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">所以现在让我们深入研究用于生成决策树的<strong class="kh ir"> ID3 算法</strong>，它使用了<strong class="kh ir">信息增益</strong>的概念，这是根据信息论中的基本量<strong class="kh ir">熵</strong>定义的。</p><p id="ca43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">想象一下某一属性的这两个部分…</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/1b55111784322c767e36e4fb3aad85fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*i5sA6iyjlDfi4KfGp6TjOw.png"/></div></figure><p id="0b2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们观察到左边的那个有相同数量的<strong class="kh ir"> P </strong> s 和<strong class="kh ir"> N </strong> s，所以这并没有给我们任何关于决定的暗示，但是右边的一个比<strong class="kh ir"> N </strong> s 有更多的<strong class="kh ir"> P </strong> s，所以它可能在某种程度上把我们引向<strong class="kh ir"> P </strong>，所以在这两个中我们可以考虑右边的一个。</p><p id="fab9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，现在不要马上给他们 0 分，让我们用另一种方法。比方说，<strong class="kh ir"> P </strong> s 和<strong class="kh ir"> N </strong> s 是相等数的一个熵最高(1)，只有<strong class="kh ir"> P </strong> s 或<strong class="kh ir"> N </strong> s 的一个熵最低(0)。我们可以有这样的东西，<strong class="kh ir"> P/(P+N) vs 熵</strong>图。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/e742fba70675046cecb878cce526ade1.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*Tz7WzNLhUYNLASTTGJ2VVQ.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">(Graph created on Desmos)</figcaption></figure><p id="a3bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，当<strong class="kh ir"> P=N </strong>，从而<strong class="kh ir"> P/(P+N) = 0.5 </strong>那么<strong class="kh ir">熵= 1 </strong>，<br/>如果<strong class="kh ir">P = k</strong>&amp;<strong class="kh ir">N = 0</strong>那么<strong class="kh ir">熵= 0 </strong>。</p><p id="3025" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这感觉像是一个非常合适的图表来实现我们想要的，那么有没有一些数学方法来得到这个图表…</p><p id="686d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，这条曲线可以通过下面的等式得到</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/84736299bb964052c210851c13632bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*poS_FX9CWBzfUEGcWjir9w.png"/></div></figure><p id="cac2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以写成<strong class="kh ir"> P/(P+N) </strong>和<strong class="kh ir">熵</strong>，<br/>替换<strong class="kh ir"> x= P/( P+N ) </strong>和<strong class="kh ir"> y =熵</strong>，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nm"><img src="../Images/191f17e55bb9b7a0eeb4f624c9394e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVy6VkRLcXV24n7wDWIsjw.png"/></div></div></figure><p id="ddc7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中 P 和 N 是我们正在寻找属性的属性的<strong class="kh ir"> P </strong> s 和<strong class="kh ir"> N </strong> s 的计数，</p><p id="8a4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们想从属性中找到信息增益，它被定义为，<br/> ( IG —来自某个属性的信息增益<strong class="kh ir"> A </strong>是熵的预期减少)</p><p id="f4e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> IG(Attribute) =属性熵—每个子集熵的加权平均值</strong></p><p id="f6d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">举个例子，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/34d156cf1c6c5e72930299855d35eb84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*uuoki4GBZXsds_AG4h1YGA.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">^ ( Example calculation of IG )</figcaption></figure><p id="f7cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然现在你已经了解了<strong class="kh ir">熵</strong>和<strong class="kh ir">信息增益</strong>的概念，让我们用这种新方法从头开始重新构建我们的决策树！</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi no"><img src="../Images/bec0b15e3deb2875aae62a8b13530670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*48tI09kUNhZwmnAKAYbHFw.png"/></div></figure><p id="08ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在这里观察到，我们从影子属性中获得了最大信息增益，选择它作为我们的根节点，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/38256d6cf5edeac97632d8c18ae7e261.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*Q3H8-PETRwvpSsnubvzmFA.png"/></div></figure><p id="c63a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要为<strong class="kh ir"> Shadow = '？'决定另一个属性</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi np"><img src="../Images/df6bf2eb37cbdf9da7f151a7fe59f16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6sk32bFeZdUJTvr9C3dnUA.png"/></div></div></figure><p id="b86b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们从大蒜中获得最大的信息增益，<br/>所以我们的树看起来像这样，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/29caa5cf8d3a534ba4349cba21c54fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*HL8rjfnNDteRmJaRw-MSBg.png"/></div></figure><p id="105e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这与前一种方法完全相同，因为幸运的是，在每一步中，我们都能够找到一些划分为同质集的属性，但是具有信息增益的方法更加健壮，可以应用于从大型数据集生成决策树。</p><p id="a5cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">参考:<br/> </strong> <a class="ae nq" href="https://www.youtube.com/watch?v=SXBG3RGr_Rc" rel="noopener ugc nofollow" target="_blank">识别树| MIT OCW </a></p></div></div>    
</body>
</html>