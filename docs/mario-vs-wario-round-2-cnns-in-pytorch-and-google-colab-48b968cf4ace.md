# 马里奥对瓦里奥——第二轮:CNN 在 PyTorch 和 Google Colab

> 原文：<https://towardsdatascience.com/mario-vs-wario-round-2-cnns-in-pytorch-and-google-colab-48b968cf4ace?source=collection_archive---------9----------------------->

![](img/b16380fec0435af0f72b7e4b677a302a.png)

## 在 PyTorch 中快速构建卷积神经网络对视频游戏截图进行分类

很长一段时间我都在玩 Google Colab(是的，免费访问 GPU…)。我认为这是一个非常棒的倡议，它使个人电脑上没有 GPU 的人能够玩深度学习和训练模型，否则他们将无法训练。基本上，我们有 12 个小时的时间来玩，然后虚拟机就死了。但是，我们当然可以开始一个新的会议，并且有办法继续以前会议的工作。

在这篇文章中，我想介绍我之前的[作品](/mario-vs-wario-image-classification-in-python-ae8d10ac6d63)的延伸。然而这一次，我将使用 PyTorch 构建一个 CNN，并在 Google Colab 上对其进行训练。最终，我希望取得比以前更好的成绩！开始吧:)

# **1。建立谷歌实验室**

Medium 上已经有一些关于如何开始使用 Google Colab、如何启用 GPU 等的好文章。我想展示几个有用的命令来检查我们实际上在做什么样的硬件/软件:

![](img/9bf9a0f44120f8286304ba1ca5fc4eff.png)![](img/e383182ee17d27f7c277a9aeaf9ad3d2.png)

我们看到我们正在开发 Tesla K80，并且已经安装了 Cuda 9.2。这样事情就简单多了！

找到如何有效处理存储在 Google Drive 上的大型数据集并不容易。许多课程和帖子使用 PyTorch 或其他库中的内置数据集。但是一开始，我发现使用我自己的一组图像有点棘手。所以我做了以下事情:

*   将数据集(带有训练/测试文件夹的压缩文件)上传到 Google Drive。

这可以通过驱动程序 UI 轻松完成。最初的目录树如下所示:

```
mario_vs_wario/
    training_set/
        mario/
            mario_1.jpg
            mario_2.jpg
            ...
        wario/
            wario_1.jpg
            wario_2.jpg
            ...
    test_set/
        mario/
            mario_1.jpg
            mario_2.jpg
            ...
        wario/
            wario_1.jpg
            wario_2.jpg
            ...
```

*   安装 Google Drive

使用 Colab 时，重要的是将文件存储在 Colab 目录中，而不是安装在 Google Drive 上。下面的单元格包含连接到 Google Drive 并安装该驱动器的代码，这样我们就可以访问存储在那里的所有文件。然而，用从 Google Drive 加载的数据训练神经网络(即使启用了 GPU)在大多数情况下会比在 CPU 上本地训练它慢得多。这是由于在 Colab 和 Drive 目录之间复制所有数据，这非常慢。

*   将 zip 文件从我的 Google Drive(通过可共享的链接)移动到在 Colab 环境中创建的目录中，然后解压缩。

为了解决上述问题，我分别压缩了训练集和测试集，并通过使用`gdown`和 Google Drive 的链接(当您在 Drive 的 UI 中单击 download shareable link)下载文件。然后，我将包含图像的文件夹解压到指定的目录。在最后一步，我删除了一个剩余的目录。

# 2.加载数据

在这一部分，我加载并预处理数据(图像)。我将一步一步地描述这个过程:

1.  首先，我定义了一些参数和我想在图像上执行的转换(调整到 128x128，转换成张量和归一化)。这也是我可以进行图像放大(随机裁剪，剪切，旋转等)的步骤。).然而，由于这个特殊的问题是关于视频游戏图像的分类，我认为应用这些转换没有意义，因为图像将不再类似于原始截图。但是，如果您正在构建一个猫/狗分类器，并且没有真正大的数据集(即使您有)，这将是应用转换的地方。
2.  我为训练/测试数据指定目录，并应用所选择的转换。
3.  我从训练集中随机选择了一个索引子集来使用它们进行验证。我还创建了从给定索引(不是整个数据集)中采样图像的`SubsetRandomSampler`。
4.  我通过组合数据集和采样器来创建`DataLoader`。在 GPU 上训练的情况下，我使用`pin_memory = True`(推荐设置)。对于`test_loader`,我也混洗数据集，否则，它将首先从一个类中取出所有观察值，然后从第二个类中取出所有观察值，而不进行任何混洗。在测试集的情况下，这实际上无关紧要。但是知道这个功能是很好的。

在下面的代码中，我检查了 10 张随机选择的图片。由于`DataLoaders`作为迭代器工作，我首先使用`iter()`，然后使用`next()`来获得随机选择的图像及其标签(来自第一批)。

![](img/e0441a8f9a6a7b21eb4e49d56fc8e5c1.png)

# 3.CNN 架构

我提出了两种定义神经网络结构的方法。第一种方法是构建一个继承自`nn.Module`的类。第二个更类似于 Keras，我们创建了一系列的层。这里没有对错，完全看个人喜好。

在这两种方法中，我使用了相同的架构，所以在培训之前应该只使用一种。

# 3.1.课堂教学方法

我定义了一个继承自`nn.Module`的类，它与`super().__init__()`结合创建了一个跟踪神经网络架构的类，并提供了各种方法和属性。需要注意的是，该类必须继承自`nn.Module`。

该类必须包含两个方法:`__init__`和`forward`。

我会对每一个必需的方法做更多的解释:

*   `__init__` -用于定义类的属性，并在初始化时填充指定的值。一个规则是总是调用`super()`方法来初始化父类。除此之外，我们可以定义所有的层，这些层具有一些要优化的参数(要调整的权重)。我们不需要定义激活函数，比如这里的`relu`，因为给定相同的输入，它们将总是返回相同的输出。定义的层的顺序并不重要，因为这些纯粹是定义，而不是指定层如何连接的架构。
*   `forward` -在这种方法中，我们定义了层之间的连接。我们指定它们连接的顺序，并最终返回网络的输出。另外，变量不一定要被称为`x`，重要的是它以正确的顺序通过各层。

# 3.2.顺序方法

对于那些使用过 Keras 的人来说,`Sequential`方法可能很熟悉。我创建了一个`OrderedDict`,按照执行的顺序指定了每一层。使用`OrderedDict`的原因是我可以给这些层起一个有意义的名字。如果不这样做，它们的名字将是整数。

开始时，我定义了一个`Flatten`类，它基本上将矩阵重新整形为一个长向量，就像 CNN 通常做的那样。`OrderedDict`放在`nn.Sequential`中，它定义了我们的模型。

# 4.损失函数和优化器

第一步是将模型转移到 Cuda，以防它将在 GPU 上训练。然后，我将二进制分类问题的损失函数和优化器指定为学习率为 0.01 的随机梯度下降。

# 5.训练网络

网上已经有很多关于训练神经网络所需步骤的资料。我将只概述这些步骤:

1.  正向通过网络(如`forward()`方法中所述)
2.  根据网络输出计算损耗
3.  用`loss.backward()`反向通过网络计算梯度
4.  通过使用优化器来更新权重

还有其他一些事情值得一提:

*   `optimizer.zero_grad()` -当使用相同的参数进行多次反向传递时，梯度在累积。这就是为什么我们需要在每次向前传递时将梯度归零。
*   训练时，我们可能会使用辍学来防止过度适应。然而，对于预测/验证，我们想要使用整个网络，因此我们需要通过使用`model.eval()`将丢失概率更改为 0(关闭它)。要返回训练模式，我们使用`model.train()`。
*   `torch.no_grad()` -关闭验证渐变，节省内存和计算

为了有一个可重用的框架来训练 CNN，我将逻辑封装在一个函数中。我假设网络将在训练和验证损失的情况下被训练。当然，它可以进一步参数化，只有当参数不是`None`时，才可以考虑验证集。不过对于这款笔记本的情况来说，相信这已经足够了。

那么训练模型就归结为:

![](img/66bafe03ebbd804b1862f78ada51b8ee.png)

我检查了显示培训/估价损失随时代演变的图表。我们的目标不仅是减少培训损失，也是减少验证损失。如果训练损失继续减少，而验证损失增加，我们将观察到过度拟合-模型将不能很好地概括训练期间没有看到的数据。在这种情况下，我们看到模型的损失在第 7 个历元之后(或者更早，取决于偏好)没有显著减少。

鉴于此，我将从第 7 纪元开始加载模型。通过保存所有的中间模型，我能够看到测试集的性能会是什么样子(以防万一，我想比较)。

# 6.评估测试集的结果

在这一部分，我在测试集上评估网络的结果，*即*网络在训练期间没有见过的那个。我编写了一个与验证脚本类似的脚本，不同之处在于我存储的用于评估的指标数量。

准确率 99%，甜！让我们来看一些更详细的统计数据:

*   99.2%的召回率——这意味着从数据集中的所有 Wario 截图来看，该模型正确预测了其中的 99.2%。
*   99.3%的精确度——这意味着在所有的 Wario 预测中，99.3%实际上都是 Wario。
*   99.25%的 F1 分数—没有明确的解释，因为 F1 分数是精确度和召回率的加权平均值。在类分布不均匀的情况下，F1 比精度更有用。就像在这种情况下，测试集中有相同数量的 Mario/Wario 类，准确度= F1 分数。

总的来说，该网络在图像分类方面做得非常出色。2000 张照片中只有 15 张分类错误。为了获得更多的洞察力，我们将在下面考察其中的一些。

![](img/ddcc6201eb1dbbecade14b768afc8864.png)

我不得不说，网络在这些图片上遇到麻烦并不奇怪。有些明显是来自游戏的过渡帧(地图和关卡之间或者屏幕之间加载屏幕)。没有办法从中推断出正确的游戏。其余的是地图或来自 Wario(第三张图片)的特定屏幕。这些游戏的地图非常相似，就像从等轴视图中看到的角色一样。

我不得不说，我对这个网络的表现和 PyTorch 总体上非常满意。它提供了很多可能性，并且非常具有 pythonic 风格。要了解更多关于 PyTorch 的基础知识，我会推荐你去 Udacity 的免费“PyTorch 深度学习简介”MOOC，你可以在这里找到。

如果你对这篇文章有任何反馈，请在评论中告诉我。一如既往，整个笔记本可以在我的 [GitHub repo](https://github.com/erykml/mario_vs_wario/blob/master/mario_vs_wario_pytorch.ipynb) 上找到。