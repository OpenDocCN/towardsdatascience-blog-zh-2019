<html>
<head>
<title>Identifying the right meaning of the words using BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 BERT 识别单词的正确含义</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-the-right-meaning-of-the-words-using-bert-817eef2ac1f0?source=collection_archive---------16-----------------------#2019-10-21">https://towardsdatascience.com/identifying-the-right-meaning-of-the-words-using-bert-817eef2ac1f0?source=collection_archive---------16-----------------------#2019-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3aaa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用语境化单词嵌入的一个重要原因是，标准嵌入为单词的每个含义分配一个向量，然而，存在多个含义的单词。假设上下文的使用可以解决将多个意思的单词(同音异义词和同形异义词)分类到同一个嵌入向量中的问题。在这个故事中，我们将分析伯特嵌入是否可以用来对一个词的不同含义进行分类，以证明语境化的词嵌入解决了这个问题。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/30f3ba2e5dddc37b48ba8a72ac3b36ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WIzfpwePs4LxDCZk4VvAQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Duck or duck — based on images from <a class="ae lb" href="https://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><h1 id="9dc9" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">构建数据集</h1><p id="033b" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">使用“鸭子”这个词的想法来自我今天早些时候看到的一条推文。由于单词有多种含义，这种误解比较常见。根据<a class="ae lb" href="https://www.merriam-webster.com/dictionary/duck" rel="noopener ugc nofollow" target="_blank">韦氏词典，</a>单词“duck”有 4 个意思。为了这个项目的简单，我把动词‘duck’和相应的名词归类为相同的意思:</p><ol class=""><li id="f990" class="mf mg iq jp b jq jr ju jv jy mh kc mi kg mj kk mk ml mm mn bi translated">a)各种游禽(鸭科，鸭科),颈和腿短，足有蹼，喙通常宽而平，雌雄之间的羽毛通常不同<br/>; b)这些鸟的肉可用作食物</li><li id="4527" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">突然低下头或身体</li><li id="141f" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">a)一种耐用的紧密编织的通常是棉布的纤维<br/> b)鸭子<em class="mt">T5】复数<em class="mt"> : </em> <strong class="jp ir"> </strong>轻便的衣服尤其是鸭子做的裤子</em></li></ol><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mu mv l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Misunderstanding the meaning of ‘duck’ — Tweet by <a class="ae lb" href="https://twitter.com/natsmama75" rel="noopener ugc nofollow" target="_blank">natsmama75 </a>on <a class="ae lb" href="https://twitter.com/natsmama75/status/1138878850832719878" rel="noopener ugc nofollow" target="_blank">Twitter</a></figcaption></figure><p id="725e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了建立一个数据集，我使用了<a class="ae lb" href="https://sentence.yourdictionary.com/duck" rel="noopener ugc nofollow" target="_blank">你的字典</a>的句子数据库，搜索包括‘duck’的句子。从给出的例子中，我排除了那些我不能区分含义的名字、长句和案例。</p><p id="84f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终数据集可在 GitHub 中获得。它包含 77 个句子，分布如下:50 个是指动物(类型 0)，17 个是动词的一种形式(类型 1)，10 个是指织物(类型 2)。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mw mv l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">The duck dataset</figcaption></figure><h1 id="bc3d" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">伯特嵌入</h1><p id="4ad6" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">对于这个故事的下一部分，我们将使用原始 BERT 基础无案例模型[1]中的 BERT 嵌入。这意味着使用最后一个隐藏层，我们为每个单词生成一个 768 大小的向量。</p><p id="5f70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们根据句子为每个单词生成上下文嵌入向量。然后，我们只保留“duck”单词标记的嵌入。这个故事的问题是，我们能否用这 768 个大小向量来对不同的意义进行分类。</p><h1 id="9c46" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">主成分分析</h1><p id="d7b5" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA </a>是一种正交变换，我们将使用它来降低向量[2，3]的维数。PCA 以最大化降维数据的方差的方式为投影找到特殊的基向量(特征向量)。使用 PCA 有两个重要的好处。一方面，我们可以将 768 维向量投影到 2D 子空间，在那里我们可以将其绘制成数据。另一方面，它保持最大可能的方差(投影丢失信息)，因此，它可能保持足够的方差，以便我们可以识别图片上的类别。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/272009d01a088883395bd618b093abce.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*50PommVPb2Drt7JG1a6Irg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Maximising variance for the first principal component — Equation from <a class="ae lb" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></figcaption></figure><p id="152c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用带有<code class="fe my mz na nb b"><a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank">sklearn.decomposition.PCA</a></code>的 PCA 是一行程序:<br/> <code class="fe my mz na nb b">duck_pca = PCA(n_components=2).fit_transform(duck_embs)</code></p><p id="028c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了使用前两个主成分的预测结果。这些类是手动注释的类型。正如我们所看到的，使用主成分分析，我们可以很容易地将动词类型与其他类型分开。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/290996a16f8cfaa0f8680ee10012be5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*sZnSl0_mz169wCV_fRUQzw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Duck meaning types. Projection using PCA</figcaption></figure><h1 id="8915" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">最近邻分类</h1><p id="7c48" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">由于数据集相对较小，我们将使用 k-NN 分类器，而不是神经网络[4]。k-NN 使用 k 个最接近的样本来预测新样本的类别。因为我们在第三类中只有 10 个样本，所以需要使用 k &lt;20 as the k-NN selects the most represented class from the neighbourhood.</p><p id="5532" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">For the validation, we will use LOOCV (Leave One Out Cross-Validation) [5]. This means that for every sample, we build a model based on the other 76 samples and validate it with the single sample. Then, we calculate the accuracy of these 77 successful or unsuccessful prediction.</p><p id="a043" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Using  【T2】 , these steps are well prepared and easy to execute:</p><p id="ba03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"> 【T3】 </p><p id="d01e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">The evaluation of the LOOCV states<strong class="jp ir">精度为 92.208% </strong>标准差为 26.805%。</p><h1 id="de6f" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">与谷歌翻译的比较</h1><p id="1c24" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我的母语匈牙利语用不同的词来表达“鸭子”的不同含义。因此，使用英匈翻译器，我们可以识别翻译器背后的神经网络(称为 GNMT [6]) <em class="mt">认为</em>，‘鸭子’是哪个意思。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/c16c43f4d099764eae9327cb9eb1c901.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*h30XKiTMfMocJ3jRFqGDZA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Google Translate English-Hungarian translation of the ‘duck’ sentences</figcaption></figure><p id="9312" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上表显示，所有鸟型“鸭”字都使用正确的类型进行翻译，17 个动词型字中有 8 个被翻译，但是，所有织物“鸭”字都被识别为鸟。这个结果显示了 75.641% 的准确率。</p><h1 id="6673" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">摘要</h1><p id="9c06" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在这个故事中，我们展示了使用语境化的单词嵌入可以成功地解决多义词的问题。实验支持假设，即当我们使用 k-NN 分类器重建类型时，BERT 嵌入存储单词的不同含义。</p><p id="4014" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lb" href="https://colab.research.google.com/drive/1rbhuZYjMGezLJmpzc9p8T38gXqILTHt_" rel="noopener ugc nofollow" target="_blank">所有对应的代码都可以在 Google Colab </a>上找到。</p><h1 id="e620" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">参考</h1><p id="293a" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">[1] Devlin，j .，Chang，M. W .，Lee，k .，&amp; Toutanova，K. (2018 年)。<a class="ae lb" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> Bert:语言理解深度双向转换器的预训练。</a> <em class="mt"> arXiv 预印本 arXiv:1810.04805 </em>。</p><p id="d571" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]皮尔逊，K. (1901 年)。<a class="ae lb" href="https://www.tandfonline.com/doi/pdf/10.1080/14786440109462720" rel="noopener ugc nofollow" target="_blank"> LIII。在最接近空间点系统的直线和平面上。</a> <em class="mt">《伦敦、爱丁堡和都柏林哲学杂志和科学杂志</em>，<em class="mt"> 2 </em> (11)，559–572 页。</p><p id="7f78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]h .霍特林(1933 年)。<a class="ae lb" href="https://psycnet.apa.org/record/1934-00645-001" rel="noopener ugc nofollow" target="_blank">将复杂的统计变量分析成主要成分。</a> <em class="mt">《教育心理学杂志》</em>，<em class="mt"> 24 </em> (6)，417 页。</p><p id="7f65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]盖，t .，&amp;哈特，P. (1967 年)。<a class="ae lb" href="https://ieeexplore.ieee.org/abstract/document/1053964/" rel="noopener ugc nofollow" target="_blank">最近邻模式分类。</a> <em class="mt"> IEEE 信息论汇刊</em>，<em class="mt"> 13 </em> (1)，21–27。</p><p id="74b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5]拉兴布鲁奇，P. A .，&amp;米基，M. R. (1968 年)。<a class="ae lb" href="https://amstat.tandfonline.com/doi/abs/10.1080/00401706.1968.10490530" rel="noopener ugc nofollow" target="_blank">判别分析中错误率的估计。</a> <em class="mt">技术计量学</em>，<em class="mt"> 10 </em> (1)，1–11。</p><p id="a0d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6]吴，m .舒斯特，陈，z .乐，Q. V .，m .马切里，w .，… &amp;克林纳，J. (2016)。<a class="ae lb" href="https://arxiv.org/abs/1609.08144" rel="noopener ugc nofollow" target="_blank">谷歌的神经机器翻译系统:弥合人类和机器翻译之间的鸿沟。</a> <em class="mt"> arXiv 预印本 arXiv:1609.08144 </em>。</p><h1 id="3c37" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">用伯特的故事学习 NMT</h1><ol class=""><li id="fa35" class="mf mg iq jp b jq ma ju mb jy ne kc nf kg ng kk mk ml mm mn bi translated"><a class="ae lb" href="https://medium.com/@neged.ng/bleu-bert-y-comparing-sentence-scores-307e0975994d" rel="noopener"> BLEU-BERT-y:比较句子得分</a></li><li id="faa5" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated"><a class="ae lb" href="https://medium.com/@neged.ng/visualisation-of-embedding-relations-word2vec-bert-64d695b7f36" rel="noopener">嵌入关系可视化(word2vec，BERT) </a></li><li id="0086" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">机器翻译:一个简短的概述</li><li id="a98b" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/identifying-the-right-meaning-of-the-words-using-bert-817eef2ac1f0">使用 BERT 识别单词的正确含义</a></li><li id="d2fc" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/machine-translation-compare-to-sota-6f71cb2cd784">机器翻译:对比 SOTA </a></li><li id="60a6" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/simple-bert-using-tensorflow-2-0-132cb19e9b22">使用 TensorFlow 2.0 的简单 BERT】</a></li></ol></div></div>    
</body>
</html>